{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import sys\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Basic Packages\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Modelling\\n# Classification\\nimport statsmodels.api as sm\\nfrom sklearn.linear_model import LogisticRegression\\nfrom modAL.models import ActiveLearner\\nfrom modAL.uncertainty import uncertainty_sampling\\n\\n# Balancing\\nfrom imblearn.over_sampling import SMOTE\\nfrom imblearn.under_sampling import RandomUnderSampler\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Metrics\\nfrom sklearn.metrics import f1_score, log_loss, matthews_corrcoef\\n\\n# Visualization\\nimport matplotlib.pyplot as plt\";\n",
       "                var nbb_formatted_code = \"import sys\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Basic Packages\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Modelling\\n# Classification\\nimport statsmodels.api as sm\\nfrom sklearn.linear_model import LogisticRegression\\nfrom modAL.models import ActiveLearner\\nfrom modAL.uncertainty import uncertainty_sampling\\n\\n# Balancing\\nfrom imblearn.over_sampling import SMOTE\\nfrom imblearn.under_sampling import RandomUnderSampler\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Metrics\\nfrom sklearn.metrics import f1_score, log_loss, matthews_corrcoef\\n\\n# Visualization\\nimport matplotlib.pyplot as plt\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Basic Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modelling\n",
    "# Classification\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from modAL.models import ActiveLearner\n",
    "from modAL.uncertainty import uncertainty_sampling\n",
    "\n",
    "# Balancing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import f1_score, log_loss, matthews_corrcoef\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, basic data preprocessing to obtain accepted and rejected training and test samples separately. Save rejected data in two versions: with and without lables. The rejected data without labels is needed for the semi-supervised model. The rejected data without labels is needed to perform evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"def data_preprocessing(df, accepted_flag, target, train_ratio):\\n    \\\"\\\"\\\"\\n    The goal of this function is to load the original dataset, split it into accepts and rejects,\\n    add ids, which can later be used for merging. For the rejects to further perform train / test split\\n\\n    Parameters\\n    ----------\\n\\n    df : name of the original dataset in quotation marks, csv format\\n    accepted_flag: name of the accepted flag; Binary: 1 if accepted, 0 if rejected\\n    target : name of the target column\\n    train_ratio : percentage used for training; Continuous (0,1)\\n\\n    Return\\n    ------\\n    a : accepted data\\n    r : rejected data\\n    r_dev : rejected trainining data without label\\n    r_test : rejected testing data without label\\n    dfr_dev_with_label: rejected training data with label\\n    dft_test_with_label: rejected training data with label\\n\\n    \\\"\\\"\\\"\\n    # Load data\\n    data = pd.read_csv(\\\"C:/Users/Asus/Desktop/Repo/MasterThesis_RI/Data_09_05/\\\" + df)\\n\\n    # Accepted\\n\\n    ## Create separate dataset with accepts\\n    dfa = data[data[accepted_flag] == 1]\\n    dfa = dfa.drop([accepted_flag], axis=1)\\n    ## Rename target variable as \\\"target\\\"\\n    dfa = dfa.rename(columns={target: \\\"target\\\"})\\n    ## Add id to the dataset, which can later be used for merging\\n    # dfa[\\\"id\\\"] = dfa.index.to_series().map(lambda x: uuid.uuid4())\\n\\n    # Rejected\\n\\n    ## Create separate dataset with accepts\\n    dfr = data[data[accepted_flag] == 0]\\n    dfr = dfr.drop([accepted_flag], axis=1)\\n    ## Add id to the dataset, which can later be used for merging\\n    #     dfr[\\\"id\\\"] = dfr.index.to_series().map(lambda x: uuid.uuid4())\\n    ## Train/Test Split (without labels)\\n    ### Shuffle the dataset\\n    shuffle_df = dfr.sample(frac=1, random_state=42)\\n    ### Define a size for the train set\\n    train_size = int(train_ratio * len(shuffle_df))\\n    ### Split the dataset\\n    dfr_dev = shuffle_df[:train_size]\\n    dfr_test = shuffle_df[train_size:]\\n    ## Save a copy of the rejected data with label\\n    dfr_dev_with_label = dfr_dev\\n    dfr_test_with_label = dfr_test\\n    ## Unlabel the rejects (i.e. drop the target) and save a copy of the rejeted data without label\\n    dfr_dev2 = dfr_dev_with_label.drop([target], axis=1)\\n    dfr_test2 = dfr_test_with_label.drop([target], axis=1)\\n    # Rename target variable\\n    dfr_dev_with_label = dfr_dev_with_label.rename(columns={target: \\\"target\\\"})\\n    dfr_test_with_label = dfr_test_with_label.rename(columns={target: \\\"target\\\"})\\n\\n    return dfr_dev_with_label, dfr_test_with_label, dfa, dfr, dfr_dev2, dfr_test2\";\n",
       "                var nbb_formatted_code = \"def data_preprocessing(df, accepted_flag, target, train_ratio):\\n    \\\"\\\"\\\"\\n    The goal of this function is to load the original dataset, split it into accepts and rejects,\\n    add ids, which can later be used for merging. For the rejects to further perform train / test split\\n\\n    Parameters\\n    ----------\\n\\n    df : name of the original dataset in quotation marks, csv format\\n    accepted_flag: name of the accepted flag; Binary: 1 if accepted, 0 if rejected\\n    target : name of the target column\\n    train_ratio : percentage used for training; Continuous (0,1)\\n\\n    Return\\n    ------\\n    a : accepted data\\n    r : rejected data\\n    r_dev : rejected trainining data without label\\n    r_test : rejected testing data without label\\n    dfr_dev_with_label: rejected training data with label\\n    dft_test_with_label: rejected training data with label\\n\\n    \\\"\\\"\\\"\\n    # Load data\\n    data = pd.read_csv(\\\"C:/Users/Asus/Desktop/Repo/MasterThesis_RI/Data_09_05/\\\" + df)\\n\\n    # Accepted\\n\\n    ## Create separate dataset with accepts\\n    dfa = data[data[accepted_flag] == 1]\\n    dfa = dfa.drop([accepted_flag], axis=1)\\n    ## Rename target variable as \\\"target\\\"\\n    dfa = dfa.rename(columns={target: \\\"target\\\"})\\n    ## Add id to the dataset, which can later be used for merging\\n    # dfa[\\\"id\\\"] = dfa.index.to_series().map(lambda x: uuid.uuid4())\\n\\n    # Rejected\\n\\n    ## Create separate dataset with accepts\\n    dfr = data[data[accepted_flag] == 0]\\n    dfr = dfr.drop([accepted_flag], axis=1)\\n    ## Add id to the dataset, which can later be used for merging\\n    #     dfr[\\\"id\\\"] = dfr.index.to_series().map(lambda x: uuid.uuid4())\\n    ## Train/Test Split (without labels)\\n    ### Shuffle the dataset\\n    shuffle_df = dfr.sample(frac=1, random_state=42)\\n    ### Define a size for the train set\\n    train_size = int(train_ratio * len(shuffle_df))\\n    ### Split the dataset\\n    dfr_dev = shuffle_df[:train_size]\\n    dfr_test = shuffle_df[train_size:]\\n    ## Save a copy of the rejected data with label\\n    dfr_dev_with_label = dfr_dev\\n    dfr_test_with_label = dfr_test\\n    ## Unlabel the rejects (i.e. drop the target) and save a copy of the rejeted data without label\\n    dfr_dev2 = dfr_dev_with_label.drop([target], axis=1)\\n    dfr_test2 = dfr_test_with_label.drop([target], axis=1)\\n    # Rename target variable\\n    dfr_dev_with_label = dfr_dev_with_label.rename(columns={target: \\\"target\\\"})\\n    dfr_test_with_label = dfr_test_with_label.rename(columns={target: \\\"target\\\"})\\n\\n    return dfr_dev_with_label, dfr_test_with_label, dfa, dfr, dfr_dev2, dfr_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def data_preprocessing(df, accepted_flag, target, train_ratio):\n",
    "    \"\"\"\n",
    "    The goal of this function is to load the original dataset, split it into accepts and rejects,\n",
    "    add ids, which can later be used for merging. For the rejects to further perform train / test split\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    df : name of the original dataset in quotation marks, csv format\n",
    "    accepted_flag: name of the accepted flag; Binary: 1 if accepted, 0 if rejected\n",
    "    target : name of the target column\n",
    "    train_ratio : percentage used for training; Continuous (0,1)\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    a : accepted data\n",
    "    r : rejected data\n",
    "    r_dev : rejected trainining data without label\n",
    "    r_test : rejected testing data without label\n",
    "    dfr_dev_with_label: rejected training data with label\n",
    "    dft_test_with_label: rejected training data with label\n",
    "\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    data = pd.read_csv(\"C:/Users/Asus/Desktop/Repo/MasterThesis_RI/Data_09_05/\" + df)\n",
    "\n",
    "    # Accepted\n",
    "\n",
    "    ## Create separate dataset with accepts\n",
    "    dfa = data[data[accepted_flag] == 1]\n",
    "    dfa = dfa.drop([accepted_flag], axis=1)\n",
    "    ## Rename target variable as \"target\"\n",
    "    dfa = dfa.rename(columns={target: \"target\"})\n",
    "    ## Add id to the dataset, which can later be used for merging\n",
    "    # dfa[\"id\"] = dfa.index.to_series().map(lambda x: uuid.uuid4())\n",
    "\n",
    "    # Rejected\n",
    "\n",
    "    ## Create separate dataset with accepts\n",
    "    dfr = data[data[accepted_flag] == 0]\n",
    "    dfr = dfr.drop([accepted_flag], axis=1)\n",
    "    ## Add id to the dataset, which can later be used for merging\n",
    "    #     dfr[\"id\"] = dfr.index.to_series().map(lambda x: uuid.uuid4())\n",
    "    ## Train/Test Split (without labels)\n",
    "    ### Shuffle the dataset\n",
    "    shuffle_df = dfr.sample(frac=1, random_state=42)\n",
    "    ### Define a size for the train set\n",
    "    train_size = int(train_ratio * len(shuffle_df))\n",
    "    ### Split the dataset\n",
    "    dfr_dev = shuffle_df[:train_size]\n",
    "    dfr_test = shuffle_df[train_size:]\n",
    "    ## Save a copy of the rejected data with label\n",
    "    dfr_dev_with_label = dfr_dev\n",
    "    dfr_test_with_label = dfr_test\n",
    "    ## Unlabel the rejects (i.e. drop the target) and save a copy of the rejeted data without label\n",
    "    dfr_dev2 = dfr_dev_with_label.drop([target], axis=1)\n",
    "    dfr_test2 = dfr_test_with_label.drop([target], axis=1)\n",
    "    # Rename target variable\n",
    "    dfr_dev_with_label = dfr_dev_with_label.rename(columns={target: \"target\"})\n",
    "    dfr_test_with_label = dfr_test_with_label.rename(columns={target: \"target\"})\n",
    "\n",
    "    return dfr_dev_with_label, dfr_test_with_label, dfa, dfr, dfr_dev2, dfr_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"dfr_dev_with_label, dfr_test_with_label, a, r, r_dev, r_test = data_preprocessing(\\n    \\\"cons_scen4_1.csv\\\", \\\"is_accepted\\\", \\\"y\\\", 0.8\\n)\";\n",
       "                var nbb_formatted_code = \"dfr_dev_with_label, dfr_test_with_label, a, r, r_dev, r_test = data_preprocessing(\\n    \\\"cons_scen4_1.csv\\\", \\\"is_accepted\\\", \\\"y\\\", 0.8\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfr_dev_with_label, dfr_test_with_label, a, r, r_dev, r_test = data_preprocessing(\n",
    "    \"cons_scen4_1.csv\", \"is_accepted\", \"y\", 0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below two functions continue the data preprocessing. Used to create feature and target data and to split into train and test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"def create_X_y(data):\\n    \\\"\\\"\\\"\\n    Undersample the data\\n\\n    Parameters\\n    ----------\\n    data : Dataframe\\n\\n    Return\\n    ------\\n    X_res : undersampled data; Dataframe\\n    y_res : undersampled labels; Dataframe\\n\\n    \\\"\\\"\\\"\\n    # Create X and y\\n    X = data.loc[:, data.columns != \\\"target\\\"]\\n    y = data.loc[:, data.columns == \\\"target\\\"]\\n\\n    return X, y\";\n",
       "                var nbb_formatted_code = \"def create_X_y(data):\\n    \\\"\\\"\\\"\\n    Undersample the data\\n\\n    Parameters\\n    ----------\\n    data : Dataframe\\n\\n    Return\\n    ------\\n    X_res : undersampled data; Dataframe\\n    y_res : undersampled labels; Dataframe\\n\\n    \\\"\\\"\\\"\\n    # Create X and y\\n    X = data.loc[:, data.columns != \\\"target\\\"]\\n    y = data.loc[:, data.columns == \\\"target\\\"]\\n\\n    return X, y\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_X_y(data):\n",
    "    \"\"\"\n",
    "    Undersample the data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Dataframe\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    X_res : undersampled data; Dataframe\n",
    "    y_res : undersampled labels; Dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    # Create X and y\n",
    "    X = data.loc[:, data.columns != \"target\"]\n",
    "    y = data.loc[:, data.columns == \"target\"]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"def split(X, y):\\n    \\\"\\\"\\\"\\n    Split the data into training and testing sample\\n\\n    Parameters\\n    ----------\\n    X : data\\n    y : labels\\n\\n    Return\\n    ------\\n    X_train : training modelling fields\\n    X_test : test modelling fields\\n    y_train : training labels\\n    y_test : testing labels\\n\\n    \\\"\\\"\\\"\\n    # Train-Test Split\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        X_res, y_res, test_size=0.2, random_state=7\\n    )\\n    columns = X_train.columns\\n\\n    # Columns\\n    X_train = pd.DataFrame(data=X_train, columns=columns)\\n    y_train = pd.DataFrame(data=y_train, columns=[\\\"target\\\"])\\n\\n    return X_train, X_test, y_train, y_test\";\n",
       "                var nbb_formatted_code = \"def split(X, y):\\n    \\\"\\\"\\\"\\n    Split the data into training and testing sample\\n\\n    Parameters\\n    ----------\\n    X : data\\n    y : labels\\n\\n    Return\\n    ------\\n    X_train : training modelling fields\\n    X_test : test modelling fields\\n    y_train : training labels\\n    y_test : testing labels\\n\\n    \\\"\\\"\\\"\\n    # Train-Test Split\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        X_res, y_res, test_size=0.2, random_state=7\\n    )\\n    columns = X_train.columns\\n\\n    # Columns\\n    X_train = pd.DataFrame(data=X_train, columns=columns)\\n    y_train = pd.DataFrame(data=y_train, columns=[\\\"target\\\"])\\n\\n    return X_train, X_test, y_train, y_test\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def split(X, y):\n",
    "    \"\"\"\n",
    "    Split the data into training and testing sample\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : data\n",
    "    y : labels\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    X_train : training modelling fields\n",
    "    X_test : test modelling fields\n",
    "    y_train : training labels\n",
    "    y_test : testing labels\n",
    "\n",
    "    \"\"\"\n",
    "    # Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_res, y_res, test_size=0.2, random_state=7\n",
    "    )\n",
    "    columns = X_train.columns\n",
    "\n",
    "    # Columns\n",
    "    X_train = pd.DataFrame(data=X_train, columns=columns)\n",
    "    y_train = pd.DataFrame(data=y_train, columns=[\"target\"])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"X_res, y_res = create_X_y(a)\\nX_train, X_test, y_train, y_test = split(X_res, y_res)\\ndfr_test_with_label_X = dfr_test_with_label.loc[:, dfr_test_with_label.columns != \\\"y\\\"]\\ndfr_test_with_label_y = dfr_test_with_label.loc[:, dfr_test_with_label.columns == \\\"y\\\"]\";\n",
       "                var nbb_formatted_code = \"X_res, y_res = create_X_y(a)\\nX_train, X_test, y_train, y_test = split(X_res, y_res)\\ndfr_test_with_label_X = dfr_test_with_label.loc[:, dfr_test_with_label.columns != \\\"y\\\"]\\ndfr_test_with_label_y = dfr_test_with_label.loc[:, dfr_test_with_label.columns == \\\"y\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_res, y_res = create_X_y(a)\n",
    "X_train, X_test, y_train, y_test = split(X_res, y_res)\n",
    "dfr_test_with_label_X = dfr_test_with_label.loc[:, dfr_test_with_label.columns != \"y\"]\n",
    "dfr_test_with_label_y = dfr_test_with_label.loc[:, dfr_test_with_label.columns == \"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we select the features that will end up in the model. The selection of columns below is subject to iteration based on the modelling outcomes from the logistic regression, i.e. significance (p-values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"significant_columns = [\\n    # \\\"known_col_0\\\",\\n    \\\"known_col_1\\\",\\n    \\\"known_col_3\\\",\\n    \\\"known_col_4\\\",\\n]\";\n",
       "                var nbb_formatted_code = \"significant_columns = [\\n    # \\\"known_col_0\\\",\\n    \\\"known_col_1\\\",\\n    \\\"known_col_3\\\",\\n    \\\"known_col_4\\\",\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "significant_columns = [\n",
    "    # \"known_col_0\",\n",
    "    \"known_col_1\",\n",
    "    \"known_col_3\",\n",
    "    \"known_col_4\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"X_train2 = X_train.copy()\\ny_train2 = y_train.copy()\\nX_test2 = X_test.copy()\\ny_test2 = y_test.copy()\\nr_dev2 = r_dev.copy()\\nr_test2 = r_test.copy()\";\n",
       "                var nbb_formatted_code = \"X_train2 = X_train.copy()\\ny_train2 = y_train.copy()\\nX_test2 = X_test.copy()\\ny_test2 = y_test.copy()\\nr_dev2 = r_dev.copy()\\nr_test2 = r_test.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train2 = X_train.copy()\n",
    "y_train2 = y_train.copy()\n",
    "X_test2 = X_test.copy()\n",
    "y_test2 = y_test.copy()\n",
    "r_dev2 = r_dev.copy()\n",
    "r_test2 = r_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"# Primary datasets\\nX_train = X_train[significant_columns]\\nX_test = X_test[significant_columns]\\nr_dev = r_dev[significant_columns]\\nr_test = r_test[significant_columns]\";\n",
       "                var nbb_formatted_code = \"# Primary datasets\\nX_train = X_train[significant_columns]\\nX_test = X_test[significant_columns]\\nr_dev = r_dev[significant_columns]\\nr_test = r_test[significant_columns]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Primary datasets\n",
    "X_train = X_train[significant_columns]\n",
    "X_test = X_test[significant_columns]\n",
    "r_dev = r_dev[significant_columns]\n",
    "r_test = r_test[significant_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.080708\n",
      "         Iterations 11\n",
      "                         Results: Logit\n",
      "================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.720    \n",
      "Dependent Variable: target           AIC:              2074.1157\n",
      "Date:               2021-05-23 21:31 BIC:              2103.9445\n",
      "No. Observations:   12800            Log-Likelihood:   -1033.1  \n",
      "Df Model:           3                LL-Null:          -3684.3  \n",
      "Df Residuals:       12796            LLR p-value:      0.0000   \n",
      "Converged:          1.0000           Scale:            1.0000   \n",
      "No. Iterations:     11.0000                                     \n",
      "----------------------------------------------------------------\n",
      "                 Coef.  Std.Err.    z     P>|z|   [0.025  0.975]\n",
      "----------------------------------------------------------------\n",
      "const           -8.2442   0.2502 -32.9530 0.0000 -8.7346 -7.7539\n",
      "known_col_1      5.5122   0.1784  30.8953 0.0000  5.1625  5.8619\n",
      "known_col_3     -1.9105   0.0830 -23.0117 0.0000 -2.0733 -1.7478\n",
      "known_col_4      1.8090   0.0949  19.0711 0.0000  1.6231  1.9949\n",
      "================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# Build Logistic regression\\n# Statmodels\\nX_in = sm.add_constant(X_train.astype(float))\\nlogit_model = sm.Logit(y_train, X_in)\\nresult3 = logit_model.fit()\\nprint(result3.summary2())\";\n",
       "                var nbb_formatted_code = \"# Build Logistic regression\\n# Statmodels\\nX_in = sm.add_constant(X_train.astype(float))\\nlogit_model = sm.Logit(y_train, X_in)\\nresult3 = logit_model.fit()\\nprint(result3.summary2())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build Logistic regression\n",
    "# Statmodels\n",
    "X_in = sm.add_constant(X_train.astype(float))\n",
    "logit_model = sm.Logit(y_train, X_in)\n",
    "result3 = logit_model.fit()\n",
    "print(result3.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"# Calculate Default Rates\\ndr = len(y_test[y_test[\\\"target\\\"] == 1]) / (\\n    len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0])\\n)\\nconservative_dr = (\\n    1.1\\n    * len(y_test[y_test[\\\"target\\\"] == 1])\\n    / (len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0]))\\n)\";\n",
       "                var nbb_formatted_code = \"# Calculate Default Rates\\ndr = len(y_test[y_test[\\\"target\\\"] == 1]) / (\\n    len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0])\\n)\\nconservative_dr = (\\n    1.1\\n    * len(y_test[y_test[\\\"target\\\"] == 1])\\n    / (len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0]))\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate Default Rates\n",
    "dr = len(y_test[y_test[\"target\"] == 1]) / (\n",
    "    len(y_test[y_test[\"target\"] == 1]) + len(y_test[y_test[\"target\"] == 0])\n",
    ")\n",
    "conservative_dr = (\n",
    "    1.1\n",
    "    * len(y_test[y_test[\"target\"] == 1])\n",
    "    / (len(y_test[y_test[\"target\"] == 1]) + len(y_test[y_test[\"target\"] == 0]))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For rejects, another step of data preporcessing is applied via Isolation Forest model. The goal is to remove outliers. The isolation forest is trained on all accepts and is used to evaluate the similarity of the rejects. Then the rejects that are found to be the most and least similar to the accepts are dropped. The contaimination parameter determines how many observations are excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# def isolation_forest(X_train, r_dev, r_test):\\n#     \\\"\\\"\\\"\\n#     The goal of this function is to filter the outliers from the rejected sample.\\n\\n#     Parameters\\n#     ----------\\n#     X_train: accepts training data; Dataframe\\n#     r_dev_mod: rejects modelling data prior outlier treatment; Dataframe\\n#     r_test_mod: rejects testinf data prior outlier treatment; Dataframe\\n\\n#     Return\\n#     ------\\n#     r_dev_mod: rejects modelling data post outlier treatment; Dataframe\\n#     r_test_mod: rejects training data prior outlier treatment; Dataframe\\n\\n#     \\\"\\\"\\\"\\n\\n#     # Build Isolation forest model\\n#     isf = IsolationForest(\\n#         n_estimators=50,\\n#         max_samples=\\\"auto\\\",\\n#         contamination=float(0.005),\\n#         max_features=1.0,\\n#     )\\n#     isf.fit(X_train)\\n#     rej_isf = isf.predict(r_dev)\\n#     # Add scores and anomaly columns to rejected train\\n#     r_dev[\\\"scores\\\"] = isf.decision_function(r_dev)\\n#     r_dev[\\\"anomaly\\\"] = isf.predict(r_dev[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Train. Number of non-outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Train. Number of outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_dev = r_dev[r_dev.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_dev = r_dev[significant_columns]\\n\\n#     # Add scores and anomaly columns to rejected test\\n#     r_test[\\\"scores\\\"] = isf.decision_function(r_test)\\n#     r_test[\\\"anomaly\\\"] = isf.predict(r_test[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Test. Number of non-outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Test. Number of outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_test = r_test[r_test.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_test = r_test[significant_columns]\\n\\n#     return r_dev, r_test\";\n",
       "                var nbb_formatted_code = \"# def isolation_forest(X_train, r_dev, r_test):\\n#     \\\"\\\"\\\"\\n#     The goal of this function is to filter the outliers from the rejected sample.\\n\\n#     Parameters\\n#     ----------\\n#     X_train: accepts training data; Dataframe\\n#     r_dev_mod: rejects modelling data prior outlier treatment; Dataframe\\n#     r_test_mod: rejects testinf data prior outlier treatment; Dataframe\\n\\n#     Return\\n#     ------\\n#     r_dev_mod: rejects modelling data post outlier treatment; Dataframe\\n#     r_test_mod: rejects training data prior outlier treatment; Dataframe\\n\\n#     \\\"\\\"\\\"\\n\\n#     # Build Isolation forest model\\n#     isf = IsolationForest(\\n#         n_estimators=50,\\n#         max_samples=\\\"auto\\\",\\n#         contamination=float(0.005),\\n#         max_features=1.0,\\n#     )\\n#     isf.fit(X_train)\\n#     rej_isf = isf.predict(r_dev)\\n#     # Add scores and anomaly columns to rejected train\\n#     r_dev[\\\"scores\\\"] = isf.decision_function(r_dev)\\n#     r_dev[\\\"anomaly\\\"] = isf.predict(r_dev[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Train. Number of non-outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Train. Number of outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_dev = r_dev[r_dev.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_dev = r_dev[significant_columns]\\n\\n#     # Add scores and anomaly columns to rejected test\\n#     r_test[\\\"scores\\\"] = isf.decision_function(r_test)\\n#     r_test[\\\"anomaly\\\"] = isf.predict(r_test[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Test. Number of non-outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Test. Number of outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_test = r_test[r_test.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_test = r_test[significant_columns]\\n\\n#     return r_dev, r_test\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def isolation_forest(X_train, r_dev, r_test):\n",
    "#     \"\"\"\n",
    "#     The goal of this function is to filter the outliers from the rejected sample.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     X_train: accepts training data; Dataframe\n",
    "#     r_dev_mod: rejects modelling data prior outlier treatment; Dataframe\n",
    "#     r_test_mod: rejects testinf data prior outlier treatment; Dataframe\n",
    "\n",
    "#     Return\n",
    "#     ------\n",
    "#     r_dev_mod: rejects modelling data post outlier treatment; Dataframe\n",
    "#     r_test_mod: rejects training data prior outlier treatment; Dataframe\n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Build Isolation forest model\n",
    "#     isf = IsolationForest(\n",
    "#         n_estimators=50,\n",
    "#         max_samples=\"auto\",\n",
    "#         contamination=float(0.005),\n",
    "#         max_features=1.0,\n",
    "#     )\n",
    "#     isf.fit(X_train)\n",
    "#     rej_isf = isf.predict(r_dev)\n",
    "#     # Add scores and anomaly columns to rejected train\n",
    "#     r_dev[\"scores\"] = isf.decision_function(r_dev)\n",
    "#     r_dev[\"anomaly\"] = isf.predict(r_dev[significant_columns])\n",
    "#     # Print number of non-outliers and outliers\n",
    "#     print(\"Rejected Train. Number of non-outliers is:\", np.sum(r_dev[\"anomaly\"] == 1))\n",
    "#     print(\"Rejected Train. Number of outliers is:\", np.sum(r_dev[\"anomaly\"] == -1))\n",
    "#     # Drop all outliers\n",
    "#     r_dev = r_dev[r_dev.anomaly != -1]\n",
    "#     # Delete columns related to the outliers\n",
    "#     r_dev = r_dev[significant_columns]\n",
    "\n",
    "#     # Add scores and anomaly columns to rejected test\n",
    "#     r_test[\"scores\"] = isf.decision_function(r_test)\n",
    "#     r_test[\"anomaly\"] = isf.predict(r_test[significant_columns])\n",
    "#     # Print number of non-outliers and outliers\n",
    "#     print(\"Rejected Test. Number of non-outliers is:\", np.sum(r_test[\"anomaly\"] == 1))\n",
    "#     print(\"Rejected Test. Number of outliers is:\", np.sum(r_test[\"anomaly\"] == -1))\n",
    "#     # Drop all outliers\n",
    "#     r_test = r_test[r_test.anomaly != -1]\n",
    "#     # Delete columns related to the outliers\n",
    "#     r_test = r_test[significant_columns]\n",
    "\n",
    "#     return r_dev, r_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"# r_dev, r_test = isolation_forest(X_train, r_dev, r_test)\";\n",
       "                var nbb_formatted_code = \"# r_dev, r_test = isolation_forest(X_train, r_dev, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# r_dev, r_test = isolation_forest(X_train, r_dev, r_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Training for the Most Certain examples with Max F1 score as stopping criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"# Create copies of the data that can be overwritten in the function below\\nX_train_iter = X_train.copy()\\ny_train_iter = y_train.copy()\\nr_dev_iter = r_dev.copy()\";\n",
       "                var nbb_formatted_code = \"# Create copies of the data that can be overwritten in the function below\\nX_train_iter = X_train.copy()\\ny_train_iter = y_train.copy()\\nr_dev_iter = r_dev.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create copies of the data that can be overwritten in the function below\n",
    "X_train_iter = X_train.copy()\n",
    "y_train_iter = y_train.copy()\n",
    "r_dev_iter = r_dev.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"# f1_scores = []\\n# iterations = []\\n# # log_losses = []\\n\\n# for iteration in range(1, 25):  # Change to how many iterrations you like\\n#     print(\\\"Iteration Nr {}\\\".format(iteration))\\n#     # Build logistic regression\\n#     #     KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n#     #         X_train_iter, y_train_iter\\n#     #     )\\n#     # KGB1 = RandomForestClassifier().fit(X_train_iter, y_train_iter)\\n\\n#     # Active Learning\\n#     n_initial = len(X_train_iter)\\n#     initial_idx = np.random.choice(\\n#         range(len(X_train_iter)), size=n_initial, replace=False\\n#     )\\n#     X_training, y_training = (\\n#         X_train_iter.iloc[initial_idx],\\n#         y_train_iter.iloc[initial_idx],\\n#     )\\n\\n#     KGB1 = ActiveLearner(\\n#         estimator=LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n#             X_train_iter, y_train_iter\\n#         ),\\n#         query_strategy=uncertainty_sampling,\\n#         X_training=X_training,\\n#         y_training=y_training,\\n#     )\\n#     query_idx, query_inst = KGB1.query(X_training)\\n#     # active learning\\n#     for idx in range(5):\\n#         query_idx, query_instance = KGB1.query(X_train_iter)\\n#         KGB1.teach(X_train_iter.iloc[query_idx], y_train.iloc[query_idx])\\n\\n#     f1_stat = f1_score(KGB1.predict(X_test), y_test, average=\\\"weighted\\\")\\n#     f1_scores.append(f1_stat)\\n#     print(\\\"F1: \\\", f1_stat)\\n\\n#     #     logloss = log_loss(KGB1.predict(X_test), y_test, eps=1e-15)\\n#     #     log_losses.append(log_losses)\\n#     # print(\\\"Log Loss: \\\", logloss)\\n#     # Make predictions on the rejected data\\n#     pred = KGB1.predict_proba(r_dev_iter)[:, 1]\\n#     pred = pd.DataFrame(\\n#         data=pred,\\n#         columns=[\\\"target\\\"],\\n#         index=r_dev_iter.index.copy(),\\n#     )\\n\\n#     # Choose the most certain predictions\\n#     lq = pred[\\\"target\\\"].quantile(q=0.05)\\n#     uq = pred[\\\"target\\\"].quantile(q=0.95)\\n#     pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n#     # If PD is high, apply default status\\n#     pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n#     # Pick only the certain predictions and concatenate them to the dev set\\n#     # Y TRAIN\\n#     certain = pred[pred[\\\"certain\\\"] == 1]\\n#     certain2 = certain[\\\"target\\\"].to_frame()\\n#     y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n#     # Get significant columns of the rejects based on index\\n#     certain_features = pd.merge(\\n#         certain[\\\"target\\\"],\\n#         r_dev_iter[significant_columns],\\n#         how=\\\"inner\\\",\\n#         left_index=True,\\n#         right_index=True,\\n#     )\\n\\n#     # X TRAIN\\n#     certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n#     X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n#     # Remove certain columns from rejected data\\n#     rows = certain_features.index\\n#     r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\";\n",
       "                var nbb_formatted_code = \"# f1_scores = []\\n# iterations = []\\n# # log_losses = []\\n\\n# for iteration in range(1, 25):  # Change to how many iterrations you like\\n#     print(\\\"Iteration Nr {}\\\".format(iteration))\\n#     # Build logistic regression\\n#     #     KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n#     #         X_train_iter, y_train_iter\\n#     #     )\\n#     # KGB1 = RandomForestClassifier().fit(X_train_iter, y_train_iter)\\n\\n#     # Active Learning\\n#     n_initial = len(X_train_iter)\\n#     initial_idx = np.random.choice(\\n#         range(len(X_train_iter)), size=n_initial, replace=False\\n#     )\\n#     X_training, y_training = (\\n#         X_train_iter.iloc[initial_idx],\\n#         y_train_iter.iloc[initial_idx],\\n#     )\\n\\n#     KGB1 = ActiveLearner(\\n#         estimator=LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n#             X_train_iter, y_train_iter\\n#         ),\\n#         query_strategy=uncertainty_sampling,\\n#         X_training=X_training,\\n#         y_training=y_training,\\n#     )\\n#     query_idx, query_inst = KGB1.query(X_training)\\n#     # active learning\\n#     for idx in range(5):\\n#         query_idx, query_instance = KGB1.query(X_train_iter)\\n#         KGB1.teach(X_train_iter.iloc[query_idx], y_train.iloc[query_idx])\\n\\n#     f1_stat = f1_score(KGB1.predict(X_test), y_test, average=\\\"weighted\\\")\\n#     f1_scores.append(f1_stat)\\n#     print(\\\"F1: \\\", f1_stat)\\n\\n#     #     logloss = log_loss(KGB1.predict(X_test), y_test, eps=1e-15)\\n#     #     log_losses.append(log_losses)\\n#     # print(\\\"Log Loss: \\\", logloss)\\n#     # Make predictions on the rejected data\\n#     pred = KGB1.predict_proba(r_dev_iter)[:, 1]\\n#     pred = pd.DataFrame(\\n#         data=pred,\\n#         columns=[\\\"target\\\"],\\n#         index=r_dev_iter.index.copy(),\\n#     )\\n\\n#     # Choose the most certain predictions\\n#     lq = pred[\\\"target\\\"].quantile(q=0.05)\\n#     uq = pred[\\\"target\\\"].quantile(q=0.95)\\n#     pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n#     # If PD is high, apply default status\\n#     pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n#     # Pick only the certain predictions and concatenate them to the dev set\\n#     # Y TRAIN\\n#     certain = pred[pred[\\\"certain\\\"] == 1]\\n#     certain2 = certain[\\\"target\\\"].to_frame()\\n#     y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n#     # Get significant columns of the rejects based on index\\n#     certain_features = pd.merge(\\n#         certain[\\\"target\\\"],\\n#         r_dev_iter[significant_columns],\\n#         how=\\\"inner\\\",\\n#         left_index=True,\\n#         right_index=True,\\n#     )\\n\\n#     # X TRAIN\\n#     certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n#     X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n#     # Remove certain columns from rejected data\\n#     rows = certain_features.index\\n#     r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# f1_scores = []\n",
    "# iterations = []\n",
    "# # log_losses = []\n",
    "\n",
    "# for iteration in range(1, 25):  # Change to how many iterrations you like\n",
    "#     print(\"Iteration Nr {}\".format(iteration))\n",
    "#     # Build logistic regression\n",
    "#     #     KGB1 = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(\n",
    "#     #         X_train_iter, y_train_iter\n",
    "#     #     )\n",
    "#     # KGB1 = RandomForestClassifier().fit(X_train_iter, y_train_iter)\n",
    "\n",
    "#     # Active Learning\n",
    "#     n_initial = len(X_train_iter)\n",
    "#     initial_idx = np.random.choice(\n",
    "#         range(len(X_train_iter)), size=n_initial, replace=False\n",
    "#     )\n",
    "#     X_training, y_training = (\n",
    "#         X_train_iter.iloc[initial_idx],\n",
    "#         y_train_iter.iloc[initial_idx],\n",
    "#     )\n",
    "\n",
    "#     KGB1 = ActiveLearner(\n",
    "#         estimator=LogisticRegression(fit_intercept=False, penalty=\"none\").fit(\n",
    "#             X_train_iter, y_train_iter\n",
    "#         ),\n",
    "#         query_strategy=uncertainty_sampling,\n",
    "#         X_training=X_training,\n",
    "#         y_training=y_training,\n",
    "#     )\n",
    "#     query_idx, query_inst = KGB1.query(X_training)\n",
    "#     # active learning\n",
    "#     for idx in range(5):\n",
    "#         query_idx, query_instance = KGB1.query(X_train_iter)\n",
    "#         KGB1.teach(X_train_iter.iloc[query_idx], y_train.iloc[query_idx])\n",
    "\n",
    "#     f1_stat = f1_score(KGB1.predict(X_test), y_test, average=\"weighted\")\n",
    "#     f1_scores.append(f1_stat)\n",
    "#     print(\"F1: \", f1_stat)\n",
    "\n",
    "#     #     logloss = log_loss(KGB1.predict(X_test), y_test, eps=1e-15)\n",
    "#     #     log_losses.append(log_losses)\n",
    "#     # print(\"Log Loss: \", logloss)\n",
    "#     # Make predictions on the rejected data\n",
    "#     pred = KGB1.predict_proba(r_dev_iter)[:, 1]\n",
    "#     pred = pd.DataFrame(\n",
    "#         data=pred,\n",
    "#         columns=[\"target\"],\n",
    "#         index=r_dev_iter.index.copy(),\n",
    "#     )\n",
    "\n",
    "#     # Choose the most certain predictions\n",
    "#     lq = pred[\"target\"].quantile(q=0.05)\n",
    "#     uq = pred[\"target\"].quantile(q=0.95)\n",
    "#     pred[\"certain\"] = pred[\"target\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\n",
    "\n",
    "#     # If PD is high, apply default status\n",
    "#     pred[\"target\"] = pred[\"target\"].apply(lambda x: 1 if (x > uq) else 0)\n",
    "\n",
    "#     # Pick only the certain predictions and concatenate them to the dev set\n",
    "#     # Y TRAIN\n",
    "#     certain = pred[pred[\"certain\"] == 1]\n",
    "#     certain2 = certain[\"target\"].to_frame()\n",
    "#     y_train_iter = pd.concat((y_train_iter, certain2))\n",
    "\n",
    "#     # Get significant columns of the rejects based on index\n",
    "#     certain_features = pd.merge(\n",
    "#         certain[\"target\"],\n",
    "#         r_dev_iter[significant_columns],\n",
    "#         how=\"inner\",\n",
    "#         left_index=True,\n",
    "#         right_index=True,\n",
    "#     )\n",
    "\n",
    "#     # X TRAIN\n",
    "#     certain_features = certain_features.loc[:, certain_features.columns != \"target\"]\n",
    "#     X_train_iter = pd.concat((X_train_iter, certain_features))\n",
    "\n",
    "#     # Remove certain columns from rejected data\n",
    "#     rows = certain_features.index\n",
    "#     r_dev_iter = r_dev_iter.drop(rows, axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Nr 1\n",
      "MCC:  0.3163564161895653\n",
      "Iteration Nr 2\n",
      "MCC:  0.33494179519768463\n",
      "Iteration Nr 3\n",
      "MCC:  0.34478303312148695\n",
      "Iteration Nr 4\n",
      "MCC:  0.3563297917229042\n",
      "Iteration Nr 5\n",
      "MCC:  0.3603054839723956\n",
      "Iteration Nr 6\n",
      "MCC:  0.3615797460033729\n",
      "Iteration Nr 7\n",
      "MCC:  0.360848457356094\n",
      "Iteration Nr 8\n",
      "MCC:  0.3596341940122227\n",
      "Iteration Nr 9\n",
      "MCC:  0.36498499456095573\n",
      "Iteration Nr 10\n",
      "MCC:  0.3651627525044242\n",
      "Iteration Nr 11\n",
      "MCC:  0.3632495735350181\n",
      "Iteration Nr 12\n",
      "MCC:  0.36158702909575424\n",
      "Iteration Nr 13\n",
      "MCC:  0.3601704011538562\n",
      "Iteration Nr 14\n",
      "MCC:  0.3587614353620926\n",
      "Iteration Nr 15\n",
      "MCC:  0.3580597962777427\n",
      "Iteration Nr 16\n",
      "MCC:  0.3575930822285857\n",
      "Iteration Nr 17\n",
      "MCC:  0.3573600375196327\n",
      "Iteration Nr 18\n",
      "MCC:  0.3573600375196327\n",
      "Iteration Nr 19\n",
      "MCC:  0.3561979200987489\n",
      "Iteration Nr 20\n",
      "MCC:  0.3555031193239494\n",
      "Iteration Nr 21\n",
      "MCC:  0.35596611487585106\n",
      "Iteration Nr 22\n",
      "MCC:  0.3548101569612283\n",
      "Iteration Nr 23\n",
      "MCC:  0.35411902178264953\n",
      "Iteration Nr 24\n",
      "MCC:  0.35411902178264953\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"f1_scores = []\\nlog_losses = []\\nmccs = []\\niterations = []\\n\\nfor iteration in range(1, 25):\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    # Build logistic regression\\n    KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n        X_train_iter, y_train_iter\\n    )\\n    # KGB1 = RandomForestClassifier().fit(X_train_iter, y_train_iter)\\n\\n    # Scores\\n    #     f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\\\"weighted\\\")\\n    #     f1_scores.append(f1_stat)\\n\\n    #     logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\\n    #     log_losses.append(logloss)\\n\\n    mcc = matthews_corrcoef(y_test, KGB1.predict(X_test))\\n    mccs.append(mcc)\\n\\n    print(\\\"MCC: \\\", mcc)\\n\\n    # Make predictions on the rejected data\\n    pred = KGB1.predict_proba(r_dev_iter)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev_iter.index.copy(),\\n    )\\n\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.05)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev_iter[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\";\n",
       "                var nbb_formatted_code = \"f1_scores = []\\nlog_losses = []\\nmccs = []\\niterations = []\\n\\nfor iteration in range(1, 25):\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    # Build logistic regression\\n    KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n        X_train_iter, y_train_iter\\n    )\\n    # KGB1 = RandomForestClassifier().fit(X_train_iter, y_train_iter)\\n\\n    # Scores\\n    #     f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\\\"weighted\\\")\\n    #     f1_scores.append(f1_stat)\\n\\n    #     logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\\n    #     log_losses.append(logloss)\\n\\n    mcc = matthews_corrcoef(y_test, KGB1.predict(X_test))\\n    mccs.append(mcc)\\n\\n    print(\\\"MCC: \\\", mcc)\\n\\n    # Make predictions on the rejected data\\n    pred = KGB1.predict_proba(r_dev_iter)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev_iter.index.copy(),\\n    )\\n\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.05)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev_iter[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1_scores = []\n",
    "log_losses = []\n",
    "mccs = []\n",
    "iterations = []\n",
    "\n",
    "for iteration in range(1, 25):\n",
    "    print(\"Iteration Nr {}\".format(iteration))\n",
    "    # Build logistic regression\n",
    "    KGB1 = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(\n",
    "        X_train_iter, y_train_iter\n",
    "    )\n",
    "    # KGB1 = RandomForestClassifier().fit(X_train_iter, y_train_iter)\n",
    "\n",
    "    # Scores\n",
    "    #     f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\"weighted\")\n",
    "    #     f1_scores.append(f1_stat)\n",
    "\n",
    "    #     logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\n",
    "    #     log_losses.append(logloss)\n",
    "\n",
    "    mcc = matthews_corrcoef(y_test, KGB1.predict(X_test))\n",
    "    mccs.append(mcc)\n",
    "\n",
    "    print(\"MCC: \", mcc)\n",
    "\n",
    "    # Make predictions on the rejected data\n",
    "    pred = KGB1.predict_proba(r_dev_iter)[:, 1]\n",
    "    pred = pd.DataFrame(\n",
    "        data=pred,\n",
    "        columns=[\"target\"],\n",
    "        index=r_dev_iter.index.copy(),\n",
    "    )\n",
    "\n",
    "    # Choose the most certain predictions\n",
    "    lq = pred[\"target\"].quantile(q=0.05)\n",
    "    uq = pred[\"target\"].quantile(q=0.95)\n",
    "    pred[\"certain\"] = pred[\"target\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\n",
    "\n",
    "    # If PD is high, apply default status\n",
    "    pred[\"target\"] = pred[\"target\"].apply(lambda x: 1 if (x > uq) else 0)\n",
    "\n",
    "    # Pick only the certain predictions and concatenate them to the dev set\n",
    "    # Y TRAIN\n",
    "    certain = pred[pred[\"certain\"] == 1]\n",
    "    certain2 = certain[\"target\"].to_frame()\n",
    "    y_train_iter = pd.concat((y_train_iter, certain2))\n",
    "\n",
    "    # Get significant columns of the rejects based on index\n",
    "    certain_features = pd.merge(\n",
    "        certain[\"target\"],\n",
    "        r_dev_iter[significant_columns],\n",
    "        how=\"inner\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    # X TRAIN\n",
    "    certain_features = certain_features.loc[:, certain_features.columns != \"target\"]\n",
    "    X_train_iter = pd.concat((X_train_iter, certain_features))\n",
    "\n",
    "    # Remove certain columns from rejected data\n",
    "    rows = certain_features.index\n",
    "    r_dev_iter = r_dev_iter.drop(rows, axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1af31ac0f70>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3SV9Z3v8fc3d3IjQAKBJBDkIqLIVVrFC6O14qWC1VbtTG11daw9tdOe1Vk9dqZzpjOuWa1nTjud0+MZta3VakfH0WptRbFjBayCcpdrkFtIIIEACUnIPft7/thbDRAgkMveeZ7Pa62s7OeSvb/7WZvPfvg9v+f3M3dHRESCKyneBYiISP9S0IuIBJyCXkQk4BT0IiIBp6AXEQm4lHgX0J38/HwvLS2NdxkiIoPGmjVrDrl7QXfbEjLoS0tLWb16dbzLEBEZNMys/FTb1HQjIhJwCnoRkYBT0IuIBJyCXkQk4BT0IiIBp6AXEQk4Bb2ISMAlZD96CZdIxGlq76SxpYPG1nYaWjpobO2gsaWDhtjvY60dzB43jMsm5se7XJFBR0EvA6qxtYO/fm4DO2oaY8Ee/empT08dxfdunMrYEZn9WKVIsCjoZUD9639tZ8mWaq6bWkjukBSy01PJzkghJz2F7IwUsmO/uy7npKeSmmI88c4e/u8fd/Cpf1nGV688j6/Nn0Bmmj7CImdiiTjD1Jw5c1xDIATP1qp6bvrpn/j8nBJ+8Nlp5/Qc1Udb+OGrW3lp/X5GD83guzdcwGcuHo2Z9XG1IoOLma1x9zndbdPFWBkQkYjzvZc2MXRIKt+57vxzfp7CoRn85I6ZPH/fpQzPSuOvnlnH7Y+uZMv++j6sViRYFPQyIJ5fW8ma8loeuH4Kw7LSev18c0qH8/L9l/ODz05jR00jN/30Lb730kZqj7X1QbUiwaKgl35Xe6yNHyzeyiWlw7htVnGfPW9yknHn3LG8+e353HVpKc+8V8H8/72Up1bsoaMz0mevIzLYKeil3/2vJduob+ngwUUXkZTU923pQzNT+f7NF7L4r65g6uhc/u63m7npp39ixc7Dff5aIoORgl761dq9tTzzXgX3zCtlSmFuv77W+YU5/PtffoJ/+/NZNLR0cOfPVvK1p9fwwYGGfn1dkUSnvmnSbzo6I/zti5sozM3gW5+aPCCvaWZcP200888fyaPLd/Kz5bt4bXM1N08fw19dM4kJBdkDUodIItEZvfSbX60oZ2tVPX//malkpQ/sOcWQtGS+9anJvPU/rubeK8/j9c0HuPbHy/j2cxsoP3xsQGsRiTf1o5d+caC+hWt+tIzZ44bxxN2XxL2fe01DK48u28lTK8vpiDi3zSrm/qsnUjJcd9hKMKgfvQy4B3+/hbbOCP+48MK4hzxAQU4637tpKm9958/44ifH8eK6fVz9o6X87Ysb2V/XHO/yRPqVgl763Fsf1PD796v4+vyJjBuRFe9yjjMyN4Pv33why74zn9svKeG51RXM/+el/P1vN3GgviXe5Yn0CzXdSJ9q7ehkwU/ewt157VtXkpGaHO+STqviSBMPv7mD/1xTSUqS8RefHMd9V02gICc93qWJnJXTNd2o102AVB1t5vnVlTy/tpLW9ggzx+Yxa+wwZo0bxkVFuaSn9H/oPrpsF7sPHeNX98xN+JAHKBmeyQ9vvZivzZ/AT/+4g1++vZtfv1vOLTOLuHveeCaPyol3iSK9pjP6Qa69M8IbWw/y3OoKlpYdJOJw2YQR5Gens3ZvLZW10fbntOQkLizKZXYs+GeNHUbh0Iw+raX88DGu/ZflXDt1FA9/YVafPvdA2VXTyGPLd/Hiun20dkSYN3EEd182nqunjOyXm71E+srpzugV9IPUrppG/mN1BS+s2cehxlZG5qTzuTnFfH5OyXHt4gcbWlhbXsfavbWsLa/l/X1HaeuIDg8wZmjGR6E/a9wwpo7OJS3l3C7buDv3PLGK93Yf4Y1vz+/zL5GBduRYG8+8t5enVpRTXd/CuBGZfOnSUj43p5icjNR4lydyEgV9QDS3dfLqpiqeXVXBe7uPkJxkXD1lJHdcUsJVkwtIST5zSLd1RNhSVc/a8lrW7K1lXXkt+49GL0LmZKRw08VjuG12EbPGDjur3jKvbarivqfX8r0bL+ArV5x3zu8x0bR3RnhtUzW/fHs3a/fWkZ2ewm2zi/nyZaWU5ifWhWYJt14HvZktAP4VSAZ+7u4/PGH7QuBBIAJ0AN9y9z/FtuUBPwcuAhy4x91XnO71FPTH27TvKP+xqoKX1u+joaWD0hGZfP6SEm6bVczI3N6fOVcfbWFNeS1vbDvAqxuraW7vZHx+Fp+dWcQts4ooHnb6vubHWjv41I+XMXRIKr//xuU9+sIZjDZU1PHLt3fzysYqOiLO1eeP5O5545k3cURCdCGVcOtV0JtZMrAduBaoBFYBd7r7li77ZAPH3N3N7GLgOXefEtv2JPCWu//czNKATHevO91rKuijjja385UnV7FqTy3pKUncMG00t19SwifGD++3YGls7eDVjVW8sLaSlbuOAHDpeSO4dXYx119U2O0drj9YvJVHl+/iha9dyuxxw/ulrkRysL6Fp1eW8+t393L4WBuTR2Xz5cvGc8vMIoakJf4FaAmm3gb9pcD33f262PJ3Adz9B6fZ/3F3v8DMcoENwHl+Fm1ECnrojETbvN/ZeYjvXn8Bt84qZmjmwLYNVxxp4jdr9/GbdZWUH24iMy2ZBRcVctusYj553giSkoyy6gZu/D9vceusYh667eIBrS/eWto7+d2G/fzy7T1sqapn6JBU7phbwl2XllKUNyTe5UnI9DbobwMWuPtXYstfBD7h7vefsN8twA+AkcCN7r7CzGYAjwFbgOnAGuCb7n7SYCNmdi9wL8DYsWNnl5eXn927DJh/emULP3trNz/87DTumDs2rrW4O6vLa3lhTSWvvF9FQ2sHRXlDuGVmESt2HWZXTSN//Pb8PplQZDByd97bfYQn3tnDks3VAFx3YSF3zxvPJaVnd61D5Fz1Nug/B1x3QtDPdfdvnGL/K4H/6e6fMrM5wEpgnru/a2b/CtS7+9+d7jXDfkb//JpK/vo/N/Dly0r5/s0Xxruc4zS3dfL6lmqeX1PJ2zsOEXF46NZp3H5JfL+MEkVlbRNPrSzn2fcqONrcztTRuXx5Xik3Tx8zKO4rkMFrQJtuYvvsBi4hekPWSncvja2/AnjA3W883WuGOejXlNdy52MruWT8MJ68e25CX9isPtrC5v1HuXrKSJ21nqC5rZMX1+3jiXd2s/1AI8Oz0vjC3LF88dJxjOqDC+giJ+rtnbGrgElmNh7YB9wBfOGEF5gI7IxdjJ0FpAGHY8sVZna+u5cB1xBtxpFuVB1t5qtPrWF0XgYPf2FWQoc8RCfqHuz95fvLkLRkvvCJsdw5t4QVOw/z+Nt7eHjpDh5ZtpPrp43m7nmlzCzJ0xekDIgzBr27d5jZ/cASot0rH3f3zWZ2X2z7I8CtwF1m1g40A7d3ufj6DeDXsR43u4C7++F9DHrNbZ385a9W09LeyTN/+QnyMsPZ3h00ZsZlE/O5bGI+ew838eSKPTy3qoLfbdjP9OKh3DBtNDNK8phWPJTMNI1IIv1DN0wlAHfnG8+s45WNVfziS3O4esqoeJck/ehYawe/WVvJUyvL2X6gEYhOdD55VA4zSvKYWZLHjLF5TCzI1rAL0mO6MzbBPfzmDv55SRkPXD+F+66aEO9yZAAdamxlQ0Ud67v8NLR0AJCdnsLFxUOZUZIX/Rmbx8gcNZVJ9zR6ZQJ7fXM1/7ykjEUzxvDVK4MzdID0TH52OtdcMIprLoj+Ly4ScXYdOhYL/VrWV9Tx2PJddESiJ2RFeUOYOiaX8flZlI7IonREJqX5WRTmZujsX05JQR9H26rr+e//sZ7pxUP54a0X68KckJRkTByZzcSR2dw2uxiI3pi1ad9R1lfUsa6iju3VDSzbXvPR4HQA6SlJjBuRGQ1/fQnICRT0cXLkWBtfeXI1WekpPHbXHPWxllPKSE1mTulw5pR+PLxEJOJU1bew59Ax9hw+FvvdxO5Dx1jazZdA0bAhDM9MIy8zlbzMNPKGpJKXmcrQzDSGZaaSN+TDbdHtWWnJOvEIEAV9HLR3Rvja02s42NDKc1+9VP2q5awlJRlFeUMoyhvCvIn5x23r7ktgX10zdU3t7KtrYcv+euqa22lq6zzl86ckGblDUkk+y/8JGDC9JI9FM4q45oKROoFJEAr6OPiH323m3d1H+MntM5hRkhfvciRgTvcl0FVrRydHm9qpa26nrqmd2qa22HIbdU3tHG1uJ3KWfTXaOiK89UENf9hygJz0FK67qJBFM4q4dMKIs/7SkL6joB9gT60s5+mVe7nvqgksmlkU73IkxNJTkhmZm9wnQ1131RlxVuw8zEvr9/HapuhwGSNz0vnM9DEsmlHERUW5ahYaYOpeOYDe2XmIu37xHldOLuBnd83RGY4EXkt7J3/cdpCX1u3jzbKDtHc65xVksWhGEQtnjDluNjTpHfWjTwAH61u47ifLGZGdzov/7TJNRyehc7SpncWbqnhp3T7e3R2d62Dm2Gh7/rVTRzFGQzv3ioI+Afzy7d38w++28Nq3rmBKYW68yxGJq/11zby8YT8vrdvHtuoGAEblpjO9OI/psbuDpxUP7bMToo7OCPvrWjjS1MaFY3JJTfBxpM6FbphKAMu21zA+P0shLwKMyRvCfVdN4L6rJlBW3cCKnYdYX1HHhsqjvL7lAABmMLEgm+kf3hlcksf5hTmnDOn2zgj7apuP625afvgY5YebqKhtor0zelI7PCuNG6eNZuGMMcweF475AhT0A6ClvZOVuw5zh8ZsFznJ+YU5nF+Y89FyXVMbGyqPsn5vHRsq6/jjtoM8v6YSiN4TcFHRUKYX5zEmL4OKI03sOdzEnsPHqKxtprNLN6GstGRK87O4YHQuCy4qpHREFpnpySzZfID/XFPBUyvLKR42hJunj2HRzCImj8o5qbagUNAPgHd3H6GlPcJV5xfEuxSRhJeXmcZVkwu4anL034u7U1nbzLqKuo/GBfr1u+W0dkTITk+hND+TaUVD+czFYxg3IpPx+VmMG5FFfnZat2frN108hsbWDl7fXM1v1+/n0eW7+H9LdzKlMIdFM4v4zPQxgZsKUm30A+Aff7eFp98tZ8P//LQmjxbpA+2dERpaOhiWmdrrppeahlYWb6zipfX7WLe3DoC544ezaEYRN0wrHDRDhutibJxd/aOlFA/L5Ff3zI13KSJyGnsPN/Hb9ft4af0+dtYcIzXZuGrySC6fOILpJXlMHZNLekpinqzpYmwcVRxpYlfNMf78E+PiXYqInMHYEZl845pJ3H/1RDbvr+e36/fxyvtV/NfW6AXi1GRj6uhcppfkfdRD6Lz8rIQfNE5B38+Wbq8B+Ki9UUQSn5lxUdFQLioayt/ccAHV9S2x6wNH2VBRxwtrKvnVinIAcjJSYqEfvUg8oySvz+827i0FfT9bVlZD8bAhTCjQHYAig5GZMXroEEYPHcKCi0YD0WEedtY0RruEVkR7Bz267ON5A0YPzWBUbgZne/kgb0gqv7y775t4FfT9qK0jwjs7D3HLzKJQ9NUVCYsPp36cPCqHz88pAaLdqDfvP/rRWX9tU9tZP29Wev9EsoK+H63ec4Smtk7mnz8y3qWISD/LSE1m9rjhzB43/Mw7D7Dg3QecQJZtryE12bh0woh4lyIiIaag70dLy2q4pHQ42f303zERkZ5Q0PeTqqPNlB1oUG8bEYk7BX0/WR7rVqn2eRGJNwV9P1laVkNhbgaTR2XHuxQRCTkFfT9o74zwpw8OcdXkAnWrFJG4U9D3g3V762ho7WC+RqsUkQSgoO8Hy7YfJDnJuGxifrxLERFR0PeHpWU1zB47jKFDNC+siMSfgr6PHWxoYfP+ek0yIiIJQ0Hfx97afgjQaJUikjh6FPRmtsDMysxsh5k90M32hWb2vpmtN7PVZnZ5l217zGzjh9v6svhEtHR7DfnZ6UwdrUnARSQxnPHefDNLBh4GrgUqgVVm9rK7b+my2xvAy+7uZnYx8Bwwpcv2P3P3Q31Yd0LqjDhvfVDDNVNGJfxEBCISHj05o58L7HD3Xe7eBjwLLOy6g7s3+sdzEmYBiTc/4QDYUFlHXVO72udFJKH0JOiLgIouy5Wxdccxs1vMbBvwCnBPl00OvG5ma8zs3t4Um+iWldWQZHCFulWKSALpSdB31wZx0hm7u7/o7lOARcCDXTbNc/dZwPXA183sym5fxOzeWPv+6pqamh6UlXiWbq9hekkew7IGx6zxIhIOPQn6SqCky3IxsP9UO7v7cmCCmeXHlvfHfh8EXiTaFNTd3z3m7nPcfU5BweBr+jhyrI33K+vU20ZEEk5Pgn4VMMnMxptZGnAH8HLXHcxsosUGdTGzWUAacNjMsswsJ7Y+C/g0sKkv30CieOuDGtw1WqWIJJ4z9rpx9w4zux9YAiQDj7v7ZjO7L7b9EeBW4C4zaweagdtjPXBGAS/GvgNSgH9399f66b3E1bKyGoZlpjKtaGi8SxEROU6Ppj5y98XA4hPWPdLl8UPAQ9383S5gei9rTHiRiLP8gxqunFxAsrpVikiC0Z2xfWDz/noONbapfV5EEpKCvg8s234QgCsV9CKSgBT0fWBpWQ3TioaSn50e71JERE6ioO+lo03trN1bq2YbEUlYCvpeenvnISKOZpMSkYSloO+lpWUHyc1IYUZJXrxLERHploK+F9ydZdtruGJSASnJOpQikpiUTr2wrbqBA/Wtap8XkYSmoO+FZdujg69pWGIRSWQK+l5YWnaQKYU5jMrNiHcpIiKnpKA/R42tHazeU6tBzEQk4Snoz9E7Ow7REXG1z4tIwlPQn6Ol22vISktm9rhh8S5FROS0FPTnwN1ZVlbDvIn5pKXoEIpIYlNKnYOdNY3sq2tWbxsRGRQU9OfgzW2xbpVqnxeRQUBBfw5e3VTFBaNzKR6WGe9SRETOSEF/lvbXNbN2bx03TiuMdykiIj2ioD9Lr26qBuCGaaPjXImISM8o6M/S4o1VTCnM4byC7HiXIiLSIwr6s1B1tJk15bXcqLN5ERlEFPRn4dWNsWabixX0IjJ4KOjPwofNNhPUbCMig4iCvoeqj7awurxWF2FFZNBR0PfQq5uqAPW2EZHBR0HfQ69urOb8UTlMHKlmGxEZXBT0PXCwvoVV5Ud0Ni8ig5KCvgde3VSNO9x4se6GFZHBR0HfA69srGLyqGwmjsyJdykiImdNQX8GB+tbWLVHzTYiMngp6M/gtc2xZhsFvYgMUgr6M3jl/Somjcxm0ig124jI4NSjoDezBWZWZmY7zOyBbrYvNLP3zWy9ma02s8tP2J5sZuvM7Pd9VfhAONjQwntqthGRQe6MQW9mycDDwPXAVOBOM5t6wm5vANPdfQZwD/DzE7Z/E9ja+3IH1pKPetso6EVk8OrJGf1cYIe773L3NuBZYGHXHdy90d09tpgFfPgYMysGbuTk8E94r2ysYuLIbCar2UZEBrGeBH0RUNFluTK27jhmdouZbQNeIXpW/6GfAN8BIqd7ETO7N9bss7qmpqYHZfWvmoZW3tutZhsRGfx6EvTWzTo/aYX7i+4+BVgEPAhgZjcBB919zZlexN0fc/c57j6noCD+k26/trmaiHrbiEgA9CToK4GSLsvFwP5T7ezuy4EJZpYPzANuNrM9RJt8rjazp8+93IGz+P0qJhRkMXmUxrYRkcGtJ0G/CphkZuPNLA24A3i56w5mNtHMLPZ4FpAGHHb377p7sbuXxv7uj+7+F336DvrBocZW3t19mBunjSb2tkREBq2UM+3g7h1mdj+wBEgGHnf3zWZ2X2z7I8CtwF1m1g40A7d3uTg76Ly2Kdpso5mkRCQIzhj0AO6+GFh8wrpHujx+CHjoDM+xFFh61hXGweKNVZxXkMX56m0jIgGgO2NPcKixlZW71GwjIsGhoD/BklhvG3WrFJGgUNCfYPHGKs7Lz2JKoZptRCQYFPRdHG5sZcXOw9ygZhsRCRAFfRdLNh9Qs42IBI6CvovFG6sYn5/FBaPVbCMiwaGgjzlyrI0Vuw5zw7RCNduISKAo6GOWbK6mM+JqthGRwFHQxyzeWEXpiEymjs6NdykiIn1KQU+02eYd9bYRkYBS0AOvq9lGRAJMQU90JqlxIzK5cIyabUQkeEIf9LVqthGRgAt90L++Jdpso5mkRCSoQh/0f9hygLHD1WwjIsEV+qDfvL+e2eOGqdlGRAIr1EF/tKmdqqMtnK+RKkUkwEId9GUHGgAU9CISaOEO+up6AI09LyKBFuqg31rdQG5GCoW5GfEuRUSk34Q66MuqG5hSmKsLsSISaKENendne3WD2udFJPBCG/T76pppaO1Q0ItI4IU26Muqoz1udCFWRIIutEG/LRb0kxX0IhJwoQ36suoGivKGkJuRGu9SRET6VaiDXu3zIhIGoQz6to4IO2saFfQiEgqhDPpdhxrpiLguxIpIKIQy6D/scaMzehEJg1AG/bbqBlKSjPPys+NdiohIv+tR0JvZAjMrM7MdZvZAN9sXmtn7ZrbezFab2eWx9Rlm9p6ZbTCzzWb2D339Bs5FWXUDEwqySUsJ5feciITMGZPOzJKBh4HrganAnWY29YTd3gCmu/sM4B7g57H1rcDV7j4dmAEsMLNP9lXx50o9bkQkTHpySjsX2OHuu9y9DXgWWNh1B3dvdHePLWYBHlvv7t4YW58a+3HiqL6lnX11zQp6EQmNngR9EVDRZbkytu44ZnaLmW0DXiF6Vv/h+mQzWw8cBP7g7u/2ruTe2a6hD0QkZHoS9N2N4XvSWbm7v+juU4BFwINd1nfGmnSKgblmdlG3L2J2b6x9f3VNTU3Pqj8H29TjRkRCpidBXwmUdFkuBvafamd3Xw5MMLP8E9bXAUuBBaf4u8fcfY67zykoKOhBWeemrLqBnPQUivKG9NtriIgkkp4E/SpgkpmNN7M04A7g5a47mNlEi83eYWazgDTgsJkVmFlebP0Q4FPAtr58A2errLqByYU5mmxEREIj5Uw7uHuHmd0PLAGSgcfdfbOZ3Rfb/ghwK3CXmbUDzcDt7u5mNhp4MtZzJwl4zt1/319v5kzcnW3V9dw0fUy8ShARGXBnDHoAd18MLD5h3SNdHj8EPNTN370PzOxljX2mur6F+pYOXYgVkVAJ1R1DH12IHaWgF5HwCFXQfzyrVG6cKxERGTihC/rC3AyGZmqyEREJj1AF/TYNfSAiIRSaoG/vjLDzYKMuxIpI6IQm6PccOkZbZ0Rn9CISOqEJeg19ICJhFZqgL6tuIDnJmDhSk42ISLiEJui3VTcwPj+L9JTkeJciIjKgQhP0ZQfq1WwjIqEUiqBvbO2g4kgzU3RHrIiEUCiCfvsBXYgVkfAKRdBr6AMRCbPQBH1mWjLFwzTZiIiETyiCflt1PZNH5ZCUpMlGRCR8Ah/07k5ZdYOGPhCR0Ap80Nc0tFLb1K4LsSISWoEPeg19ICJhF/igV48bEQm7wAf9tuoGCnLSGZ6VFu9SRETiIvBBX3agXhdiRSTUAh30nRHngwONmgxcREIt0EG/5/AxWjs02YiIhFugg14XYkVEAh7026obSDKYNEqTjYhIeAU66Muq6ykdkUVGqiYbEZHwCnjQN6h9XkRCL7BB39TWQfmRJgW9iIReYIP+gwONuKM+9CISeoEN+rKPxrhRjxsRCbfABv226gYyUpMYOzwz3qWIiMRVYIO+7EB0spFkTTYiIiHXo6A3swVmVmZmO8zsgW62LzSz981svZmtNrPLY+tLzOxNM9tqZpvN7Jt9/QZOpay6QUMfiIgAKWfawcySgYeBa4FKYJWZvezuW7rs9gbwsru7mV0MPAdMATqAb7v7WjPLAdaY2R9O+Ns+d6ixlUONbepxIyJCz87o5wI73H2Xu7cBzwILu+7g7o3u7rHFLMBj66vcfW3scQOwFSjqq+JPRUMfiIh8rCdBXwRUdFmupJuwNrNbzGwb8ApwTzfbS4GZwLvdvYiZ3Rtr9lldU1PTg7JOTbNKiYh8rCdB393VTD9phfuL7j4FWAQ8eNwTmGUDLwDfcvf67l7E3R9z9znuPqegoKAHZZ1aWXU9I7LSKMhJ79XziIgEQU+CvhIo6bJcDOw/1c7uvhyYYGb5AGaWSjTkf+3uv+lFrT2moQ9ERD7Wk6BfBUwys/FmlgbcAbzcdQczm2hmFns8C0gDDsfW/QLY6u4/7tvSuxeJONsPNCroRURiztjrxt07zOx+YAmQDDzu7pvN7L7Y9keAW4G7zKwdaAZuj/XAuRz4IrDRzNbHnvJv3H1xf7wZgL1Hmmhu79TQByIiMWcMeoBYMC8+Yd0jXR4/BDzUzd/9ie7b+PvNNg19ICJynMDdGVtW3YAZTNZkIyIiQBCD/kA9Y4dnkpnWo/+siIgEXuCCfpuGPhAROU6ggr6lvZM9h47pQqyISBeBCvodBxuJuC7Eioh0Faig19AHIiInC1TQl1XXk5aSROkITTYiIvKhQAX9tuoGJo3MJiU5UG9LRKRXApWIGuNGRORkgels3t4Z4YpJBVwxKT/epYiIJJTABH1qchI/+vz0eJchIpJwAtV0IyIiJ1PQi4gEnIJeRCTgFPQiIgGnoBcRCTgFvYhIwCnoRUQCTkEvIhJw5u7xruEkZlYDlJ/jn+cDh/qwnMFKxyFKxyFKxyEqyMdhnLsXdLchIYO+N8xstbvPiXcd8abjEKXjEKXjEBXW46CmGxGRgFPQi4gEXBCD/rF4F5AgdByidByidByiQnkcAtdGLyIixwviGb2IiHShoBcRCbjABL2ZLTCzMjPbYWYPxLueeDKzPWa20czWm9nqeNczUMzscTM7aGabuqwbbmZ/MLMPYr+HxbPGgXCK4/B9M9sX+0ysN7Mb4lnjQDCzEjN708y2mtlmM/tmbH3oPhOBCHozSwYeBq4HpgJ3mtnU+FYVd3/m7jNC1mf4CWDBCeseAN5w90nAG7HloHuCk48DwL/EPhMz3H3xANcUDx3At939AuCTwNdjuQaTECYAAAHISURBVBC6z0Qggh6YC+xw913u3gY8CyyMc00ywNx9OXDkhNULgSdjj58EFg1oUXFwiuMQOu5e5e5rY48bgK1AESH8TAQl6IuAii7LlbF1YeXA62a2xszujXcxcTbK3asg+g8fGBnneuLpfjN7P9a0E/jmiq7MrBSYCbxLCD8TQQl662ZdmPuNznP3WUSbsr5uZlfGuyCJu38DJgAzgCrgR/EtZ+CYWTbwAvAtd6+Pdz3xEJSgrwRKuiwXA/vjVEvcufv+2O+DwItEm7bC6oCZjQaI/T4Y53riwt0PuHunu0eAnxGSz4SZpRIN+V+7+29iq0P3mQhK0K8CJpnZeDNLA+4AXo5zTXFhZllmlvPhY+DTwKbT/1WgvQx8Kfb4S8Bv41hL3HwYbDG3EILPhJkZ8Atgq7v/uMum0H0mAnNnbKy72E+AZOBxd/+nOJcUF2Z2HtGzeIAU4N/DcizM7BlgPtGhaA8Afw+8BDwHjAX2Ap9z90BfqDzFcZhPtNnGgT3AVz9spw4qM7sceAvYCERiq/+GaDt9uD4TQQl6ERHpXlCabkRE5BQU9CIiAaegFxEJOAW9iEjAKehFRAJOQS8iEnAKehGRgPv/dGVDFxqK24oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"plt.plot(mccs, label=\\\"MCCs\\\")\";\n",
       "                var nbb_formatted_code = \"plt.plot(mccs, label=\\\"MCCs\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mccs, label=\"MCCs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"# Save the iteration of the model where max MCC score is reached\\nmax_value = max(mccs)\\nmax_index = mccs.index(max_value)\\nprint(max_index)\";\n",
       "                var nbb_formatted_code = \"# Save the iteration of the model where max MCC score is reached\\nmax_value = max(mccs)\\nmax_index = mccs.index(max_value)\\nprint(max_index)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the iteration of the model where max MCC score is reached\n",
    "max_value = max(mccs)\n",
    "max_index = mccs.index(max_value)\n",
    "print(max_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do only 1 iteration as baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"# Create copies of the data that can be overwritten in the function below\\nX_train_iter1 = X_train.copy()\\ny_train_iter1 = y_train.copy()\\nr_dev_iter1 = r_dev.copy()\";\n",
       "                var nbb_formatted_code = \"# Create copies of the data that can be overwritten in the function below\\nX_train_iter1 = X_train.copy()\\ny_train_iter1 = y_train.copy()\\nr_dev_iter1 = r_dev.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create copies of the data that can be overwritten in the function below\n",
    "X_train_iter1 = X_train.copy()\n",
    "y_train_iter1 = y_train.copy()\n",
    "r_dev_iter1 = r_dev.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Nr 1\n",
      "MCC:  0.3163564161895653\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"# Add more scores that you want to track\\nf1_scores = []\\nmccs = []\\niterations = []\\n# log_losses = []\\n\\nfor iteration in range(1, 2):  # Change to how many iterrations you like\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    # Build logistic regression\\n    KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n        X_train_iter1, y_train_iter1\\n    )\\n    # KGB1 = RandomForestClassifier().fit(X_train_iter1, y_train_iter1)\\n\\n    # Scores\\n    #     f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\\\"weighted\\\")\\n    #     f1_scores.append(f1_stat)\\n    #     print(\\\"F1: \\\", f1_stat)\\n\\n    #     logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\\n    #     log_losses.append(logloss)\\n\\n    mcc = matthews_corrcoef(y_test, KGB1.predict(X_test))\\n    mccs.append(mcc)\\n\\n    print(\\\"MCC: \\\", mcc)\\n\\n    # Make predictions on the rejected data\\n    pred = KGB1.predict_proba(r_dev_iter1)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev_iter1.index.copy(),\\n    )\\n\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.05)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train_iter1 = pd.concat((y_train_iter1, certain2))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev_iter1[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train_iter1 = pd.concat((X_train_iter1, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev_iter1 = r_dev_iter1.drop(rows, axis=\\\"index\\\")\";\n",
       "                var nbb_formatted_code = \"# Add more scores that you want to track\\nf1_scores = []\\nmccs = []\\niterations = []\\n# log_losses = []\\n\\nfor iteration in range(1, 2):  # Change to how many iterrations you like\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    # Build logistic regression\\n    KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n        X_train_iter1, y_train_iter1\\n    )\\n    # KGB1 = RandomForestClassifier().fit(X_train_iter1, y_train_iter1)\\n\\n    # Scores\\n    #     f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\\\"weighted\\\")\\n    #     f1_scores.append(f1_stat)\\n    #     print(\\\"F1: \\\", f1_stat)\\n\\n    #     logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\\n    #     log_losses.append(logloss)\\n\\n    mcc = matthews_corrcoef(y_test, KGB1.predict(X_test))\\n    mccs.append(mcc)\\n\\n    print(\\\"MCC: \\\", mcc)\\n\\n    # Make predictions on the rejected data\\n    pred = KGB1.predict_proba(r_dev_iter1)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev_iter1.index.copy(),\\n    )\\n\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.05)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train_iter1 = pd.concat((y_train_iter1, certain2))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev_iter1[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train_iter1 = pd.concat((X_train_iter1, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev_iter1 = r_dev_iter1.drop(rows, axis=\\\"index\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add more scores that you want to track\n",
    "f1_scores = []\n",
    "mccs = []\n",
    "iterations = []\n",
    "# log_losses = []\n",
    "\n",
    "for iteration in range(1, 2):  # Change to how many iterrations you like\n",
    "    print(\"Iteration Nr {}\".format(iteration))\n",
    "    # Build logistic regression\n",
    "    KGB1 = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(\n",
    "        X_train_iter1, y_train_iter1\n",
    "    )\n",
    "    # KGB1 = RandomForestClassifier().fit(X_train_iter1, y_train_iter1)\n",
    "\n",
    "    # Scores\n",
    "    #     f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\"weighted\")\n",
    "    #     f1_scores.append(f1_stat)\n",
    "    #     print(\"F1: \", f1_stat)\n",
    "\n",
    "    #     logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\n",
    "    #     log_losses.append(logloss)\n",
    "\n",
    "    mcc = matthews_corrcoef(y_test, KGB1.predict(X_test))\n",
    "    mccs.append(mcc)\n",
    "\n",
    "    print(\"MCC: \", mcc)\n",
    "\n",
    "    # Make predictions on the rejected data\n",
    "    pred = KGB1.predict_proba(r_dev_iter1)[:, 1]\n",
    "    pred = pd.DataFrame(\n",
    "        data=pred,\n",
    "        columns=[\"target\"],\n",
    "        index=r_dev_iter1.index.copy(),\n",
    "    )\n",
    "\n",
    "    # Choose the most certain predictions\n",
    "    lq = pred[\"target\"].quantile(q=0.05)\n",
    "    uq = pred[\"target\"].quantile(q=0.95)\n",
    "    pred[\"certain\"] = pred[\"target\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\n",
    "\n",
    "    # If PD is high, apply default status\n",
    "    pred[\"target\"] = pred[\"target\"].apply(lambda x: 1 if (x > uq) else 0)\n",
    "\n",
    "    # Pick only the certain predictions and concatenate them to the dev set\n",
    "    # Y TRAIN\n",
    "    certain = pred[pred[\"certain\"] == 1]\n",
    "    certain2 = certain[\"target\"].to_frame()\n",
    "    y_train_iter1 = pd.concat((y_train_iter1, certain2))\n",
    "\n",
    "    # Get significant columns of the rejects based on index\n",
    "    certain_features = pd.merge(\n",
    "        certain[\"target\"],\n",
    "        r_dev_iter1[significant_columns],\n",
    "        how=\"inner\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    # X TRAIN\n",
    "    certain_features = certain_features.loc[:, certain_features.columns != \"target\"]\n",
    "    X_train_iter1 = pd.concat((X_train_iter1, certain_features))\n",
    "\n",
    "    # Remove certain columns from rejected data\n",
    "    rows = certain_features.index\n",
    "    r_dev_iter1 = r_dev_iter1.drop(rows, axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"def predict_rejects(model, r_dev):\\n    # Make predictions on the Train Rejects\\n    pred_test = model.predict_proba(r_dev)[:, 1]\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_dev.index.copy(),\\n    )\\n\\n    # Make binary predictions based on cutoff DR\\n    q1 = pred_test[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test[\\\"target\\\"] = pred_test[\\\"pred\\\"].apply(lambda x: 0 if (x < q1) else 1)\\n    pred_test = pred_test[\\\"target\\\"].to_frame()\\n\\n    # Add new rows to df\\n    y_train_new = pd.concat((y_train, pred_test))\\n    X_train_new = pd.concat((X_train, r_dev))\\n\\n    # Fit new model\\n    KGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n        X_train_new, y_train_new\\n    )\\n    #     KGB_baseline_new = RandomForestClassifier().fit(X_train_new, y_train_new)\\n    return KGB_baseline_new\";\n",
       "                var nbb_formatted_code = \"def predict_rejects(model, r_dev):\\n    # Make predictions on the Train Rejects\\n    pred_test = model.predict_proba(r_dev)[:, 1]\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_dev.index.copy(),\\n    )\\n\\n    # Make binary predictions based on cutoff DR\\n    q1 = pred_test[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test[\\\"target\\\"] = pred_test[\\\"pred\\\"].apply(lambda x: 0 if (x < q1) else 1)\\n    pred_test = pred_test[\\\"target\\\"].to_frame()\\n\\n    # Add new rows to df\\n    y_train_new = pd.concat((y_train, pred_test))\\n    X_train_new = pd.concat((X_train, r_dev))\\n\\n    # Fit new model\\n    KGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n        X_train_new, y_train_new\\n    )\\n    #     KGB_baseline_new = RandomForestClassifier().fit(X_train_new, y_train_new)\\n    return KGB_baseline_new\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict_rejects(model, r_dev):\n",
    "    # Make predictions on the Train Rejects\n",
    "    pred_test = model.predict_proba(r_dev)[:, 1]\n",
    "    pred_test = pd.DataFrame(\n",
    "        data=pred_test,\n",
    "        columns=[\"pred\"],\n",
    "        index=r_dev.index.copy(),\n",
    "    )\n",
    "\n",
    "    # Make binary predictions based on cutoff DR\n",
    "    q1 = pred_test[\"pred\"].quantile(q=1 - conservative_dr)\n",
    "    pred_test[\"target\"] = pred_test[\"pred\"].apply(lambda x: 0 if (x < q1) else 1)\n",
    "    pred_test = pred_test[\"target\"].to_frame()\n",
    "\n",
    "    # Add new rows to df\n",
    "    y_train_new = pd.concat((y_train, pred_test))\n",
    "    X_train_new = pd.concat((X_train, r_dev))\n",
    "\n",
    "    # Fit new model\n",
    "    KGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(\n",
    "        X_train_new, y_train_new\n",
    "    )\n",
    "    #     KGB_baseline_new = RandomForestClassifier().fit(X_train_new, y_train_new)\n",
    "    return KGB_baseline_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"def evaluate_test_accepts(model, X_test):\\n    pred_test = model.predict_proba(X_test)[:, 1]\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=X_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_formatted_code = \"def evaluate_test_accepts(model, X_test):\\n    pred_test = model.predict_proba(X_test)[:, 1]\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=X_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_test_accepts(model, X_test):\n",
    "    pred_test = model.predict_proba(X_test)[:, 1]\n",
    "    pred_test = pd.DataFrame(\n",
    "        data=pred_test,\n",
    "        columns=[\"pred\"],\n",
    "        index=X_test.index.copy(),\n",
    "    )\n",
    "\n",
    "    # Merge with Target\n",
    "    pred_test2 = pd.merge(\n",
    "        pred_test[\"pred\"],\n",
    "        y_test[\"target\"],\n",
    "        how=\"inner\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    # Make binary predictions based on cutoff 50percentile of the distribution\n",
    "    q1 = pred_test2[\"pred\"].quantile(q=1 - conservative_dr)\n",
    "    pred_test2[\"prediction_baseline\"] = pred_test2[\"pred\"].apply(\n",
    "        lambda x: 0 if (x < q1) else 1\n",
    "    )\n",
    "    return pred_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"def evaluate_test_rejects(model, r_test):\\n    pred_test = model.predict_proba(r_test)[:, 1]\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_formatted_code = \"def evaluate_test_rejects(model, r_test):\\n    pred_test = model.predict_proba(r_test)[:, 1]\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_test_rejects(model, r_test):\n",
    "    pred_test = model.predict_proba(r_test)[:, 1]\n",
    "    pred_test = pd.DataFrame(\n",
    "        data=pred_test,\n",
    "        columns=[\"pred\"],\n",
    "        index=r_test.index.copy(),\n",
    "    )\n",
    "\n",
    "    # Merge with Target\n",
    "    pred_test2 = pd.merge(\n",
    "        pred_test[\"pred\"],\n",
    "        dfr_test_with_label[\"target\"],\n",
    "        how=\"inner\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    # Make binary predictions based on cutoff 50percentile of the distribution\n",
    "    q1 = pred_test2[\"pred\"].quantile(q=1 - conservative_dr)\n",
    "    pred_test2[\"prediction_baseline\"] = pred_test2[\"pred\"].apply(\n",
    "        lambda x: 0 if (x < q1) else 1\n",
    "    )\n",
    "    return pred_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"def flag_df_baseline(df):\\n\\n    # Flag kicked out bad cases (want more of these)\\n    if df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"CB\\\"\\n\\n    # Flag kicked out good cases (want less of these)\\n    elif df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"IB\\\"\\n\\n    # Flag kicked in good cases (want more of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"CG\\\"\\n\\n    # Flag kicked in bad cases (want less of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"IG\\\"\";\n",
       "                var nbb_formatted_code = \"def flag_df_baseline(df):\\n\\n    # Flag kicked out bad cases (want more of these)\\n    if df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"CB\\\"\\n\\n    # Flag kicked out good cases (want less of these)\\n    elif df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"IB\\\"\\n\\n    # Flag kicked in good cases (want more of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"CG\\\"\\n\\n    # Flag kicked in bad cases (want less of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"IG\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def flag_df_baseline(df):\n",
    "\n",
    "    # Flag kicked out bad cases (want more of these)\n",
    "    if df[\"target\"] == 1 and df[\"prediction_baseline\"] == 1:\n",
    "        return \"CB\"\n",
    "\n",
    "    # Flag kicked out good cases (want less of these)\n",
    "    elif df[\"target\"] == 1 and df[\"prediction_baseline\"] == 0:\n",
    "        return \"IB\"\n",
    "\n",
    "    # Flag kicked in good cases (want more of these)\n",
    "    elif df[\"target\"] == 0 and df[\"prediction_baseline\"] == 0:\n",
    "        return \"CG\"\n",
    "\n",
    "    # Flag kicked in bad cases (want less of these)\n",
    "    elif df[\"target\"] == 0 and df[\"prediction_baseline\"] == 1:\n",
    "        return \"IG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"def kickout_baseline(df):\\n\\n    # Counts of kickout bad and kickout good\\n    counts = df[\\\"Flag\\\"].value_counts()\\n    if \\\"CB\\\" in df.values:\\n        cb = counts.CB  # want more of these\\n    else:\\n        cb = 0\\n    if \\\"IB\\\" in df.values:\\n        ib = counts.IB  # want less of these\\n    else:\\n        ib = 0\\n\\n    if \\\"CG\\\" in df.values:\\n        cg = counts.CG  # want more of these\\n    else:\\n        cg = 0\\n\\n    if \\\"IG\\\" in df.values:\\n        ig = counts.IG  # want less of these\\n    else:\\n        ig = 0\\n\\n    # Target\\n    total_bads = df[df[\\\"target\\\"] == 1].shape[0]\\n    total_goods = df[df[\\\"target\\\"] == 0].shape[0]\\n    pb = total_bads / (total_bads + total_goods)\\n    pg = total_goods / (total_bads + total_goods)\\n\\n    kickout = (((cb / pb) - (ib / pb)) / total_bads) * (pb ** 2)\\n    kickin = (((cg / pg) - (ig / pg)) / total_goods) * (pg ** 2)\\n    weighted_total = kickout + kickin\\n    return weighted_total\";\n",
       "                var nbb_formatted_code = \"def kickout_baseline(df):\\n\\n    # Counts of kickout bad and kickout good\\n    counts = df[\\\"Flag\\\"].value_counts()\\n    if \\\"CB\\\" in df.values:\\n        cb = counts.CB  # want more of these\\n    else:\\n        cb = 0\\n    if \\\"IB\\\" in df.values:\\n        ib = counts.IB  # want less of these\\n    else:\\n        ib = 0\\n\\n    if \\\"CG\\\" in df.values:\\n        cg = counts.CG  # want more of these\\n    else:\\n        cg = 0\\n\\n    if \\\"IG\\\" in df.values:\\n        ig = counts.IG  # want less of these\\n    else:\\n        ig = 0\\n\\n    # Target\\n    total_bads = df[df[\\\"target\\\"] == 1].shape[0]\\n    total_goods = df[df[\\\"target\\\"] == 0].shape[0]\\n    pb = total_bads / (total_bads + total_goods)\\n    pg = total_goods / (total_bads + total_goods)\\n\\n    kickout = (((cb / pb) - (ib / pb)) / total_bads) * (pb ** 2)\\n    kickin = (((cg / pg) - (ig / pg)) / total_goods) * (pg ** 2)\\n    weighted_total = kickout + kickin\\n    return weighted_total\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def kickout_baseline(df):\n",
    "\n",
    "    # Counts of kickout bad and kickout good\n",
    "    counts = df[\"Flag\"].value_counts()\n",
    "    if \"CB\" in df.values:\n",
    "        cb = counts.CB  # want more of these\n",
    "    else:\n",
    "        cb = 0\n",
    "    if \"IB\" in df.values:\n",
    "        ib = counts.IB  # want less of these\n",
    "    else:\n",
    "        ib = 0\n",
    "\n",
    "    if \"CG\" in df.values:\n",
    "        cg = counts.CG  # want more of these\n",
    "    else:\n",
    "        cg = 0\n",
    "\n",
    "    if \"IG\" in df.values:\n",
    "        ig = counts.IG  # want less of these\n",
    "    else:\n",
    "        ig = 0\n",
    "\n",
    "    # Target\n",
    "    total_bads = df[df[\"target\"] == 1].shape[0]\n",
    "    total_goods = df[df[\"target\"] == 0].shape[0]\n",
    "    pb = total_bads / (total_bads + total_goods)\n",
    "    pg = total_goods / (total_bads + total_goods)\n",
    "\n",
    "    kickout = (((cb / pb) - (ib / pb)) / total_bads) * (pb ** 2)\n",
    "    kickin = (((cg / pg) - (ig / pg)) / total_goods) * (pg ** 2)\n",
    "    weighted_total = kickout + kickin\n",
    "    return weighted_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prediction before RI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: KGB Model ($m_{1}$)  <br>\n",
    "Step 2: Score Test Accepts and Test Rejects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"pred_test_a = evaluate_test_accepts(KGB1, X_test)\\npred_test_r = evaluate_test_rejects(KGB1, r_test)\";\n",
       "                var nbb_formatted_code = \"pred_test_a = evaluate_test_accepts(KGB1, X_test)\\npred_test_r = evaluate_test_rejects(KGB1, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a = evaluate_test_accepts(KGB1, X_test)\n",
    "pred_test_r = evaluate_test_rejects(KGB1, r_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_beforeRI = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_beforeRI = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a[\"Flag\"] = pred_test_a.apply(flag_df_baseline, axis=1)\n",
    "predictions_accepts_beforeRI = [round(kickout_baseline(pred_test_a).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_beforeRI = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_beforeRI = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_r[\"Flag\"] = pred_test_r.apply(flag_df_baseline, axis=1)\n",
    "predictions_rejects_beforeRI = [round(kickout_baseline(pred_test_r).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Predicions Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: KGB Model ($m_{1}$)  <br>\n",
    "Step 2: Infer status of each reject <br> \n",
    "Step 3: Redevelop KGB mdoel with inferred rejects ($m_{2}$)  <br>\n",
    "Step 4: Score Test Accepts and Test Rejects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"KGB_baseline_new = predict_rejects(KGB1, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\";\n",
       "                var nbb_formatted_code = \"KGB_baseline_new = predict_rejects(KGB1, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "KGB_baseline_new = predict_rejects(KGB1, r_dev)\n",
    "pred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\n",
    "pred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_base = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_base = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a[\"Flag\"] = pred_test_a.apply(flag_df_baseline, axis=1)\n",
    "predictions_accepts_base = [round(kickout_baseline(pred_test_a).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_base = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_base = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_r[\"Flag\"] = pred_test_r.apply(flag_df_baseline, axis=1)\n",
    "predictions_rejects_base = [round(kickout_baseline(pred_test_r).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain with the most optimal Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Nr 1\n",
      "MCC:  0.3163564161895653\n",
      "Iteration Nr 2\n",
      "MCC:  0.33494179519768463\n",
      "Iteration Nr 3\n",
      "MCC:  0.34478303312148695\n",
      "Iteration Nr 4\n",
      "MCC:  0.3563297917229042\n",
      "Iteration Nr 5\n",
      "MCC:  0.3603054839723956\n",
      "Iteration Nr 6\n",
      "MCC:  0.3615797460033729\n",
      "Iteration Nr 7\n",
      "MCC:  0.360848457356094\n",
      "Iteration Nr 8\n",
      "MCC:  0.3596341940122227\n",
      "Iteration Nr 9\n",
      "MCC:  0.36498499456095573\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Add more scores that you want to track\\nf1_scores = []\\niterations = []\\n# log_losses = []\\n\\nfor iteration in range(1, max_index + 1):  # Change to how many iterrations you like\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    # Build logistic regression\\n    KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train, y_train)\\n    # KGB1 = RandomForestClassifier().fit(X_train, y_train)\\n\\n    # Scores\\n    #     f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\\\"weighted\\\")\\n    #     f1_scores.append(f1_stat)\\n    #     print(\\\"F1: \\\", f1_stat)\\n\\n    #     logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\\n    #     log_losses.append(logloss)\\n\\n    mcc = matthews_corrcoef(y_test, KGB1.predict(X_test))\\n    mccs.append(mcc)\\n\\n    print(\\\"MCC: \\\", mcc)\\n\\n    # Make predictions on the rejected data\\n    pred = KGB1.predict_proba(r_dev)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev.index.copy(),\\n    )\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.05)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train = pd.concat((y_train, certain2))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train = pd.concat((X_train, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev = r_dev.drop(rows, axis=\\\"index\\\")\";\n",
       "                var nbb_formatted_code = \"# Add more scores that you want to track\\nf1_scores = []\\niterations = []\\n# log_losses = []\\n\\nfor iteration in range(1, max_index + 1):  # Change to how many iterrations you like\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    # Build logistic regression\\n    KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train, y_train)\\n    # KGB1 = RandomForestClassifier().fit(X_train, y_train)\\n\\n    # Scores\\n    #     f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\\\"weighted\\\")\\n    #     f1_scores.append(f1_stat)\\n    #     print(\\\"F1: \\\", f1_stat)\\n\\n    #     logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\\n    #     log_losses.append(logloss)\\n\\n    mcc = matthews_corrcoef(y_test, KGB1.predict(X_test))\\n    mccs.append(mcc)\\n\\n    print(\\\"MCC: \\\", mcc)\\n\\n    # Make predictions on the rejected data\\n    pred = KGB1.predict_proba(r_dev)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev.index.copy(),\\n    )\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.05)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train = pd.concat((y_train, certain2))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train = pd.concat((X_train, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev = r_dev.drop(rows, axis=\\\"index\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add more scores that you want to track\n",
    "f1_scores = []\n",
    "iterations = []\n",
    "# log_losses = []\n",
    "\n",
    "for iteration in range(1, max_index + 1):  # Change to how many iterrations you like\n",
    "    print(\"Iteration Nr {}\".format(iteration))\n",
    "    # Build logistic regression\n",
    "    KGB1 = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(X_train, y_train)\n",
    "    # KGB1 = RandomForestClassifier().fit(X_train, y_train)\n",
    "\n",
    "    # Scores\n",
    "    #     f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\"weighted\")\n",
    "    #     f1_scores.append(f1_stat)\n",
    "    #     print(\"F1: \", f1_stat)\n",
    "\n",
    "    #     logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\n",
    "    #     log_losses.append(logloss)\n",
    "\n",
    "    mcc = matthews_corrcoef(y_test, KGB1.predict(X_test))\n",
    "    mccs.append(mcc)\n",
    "\n",
    "    print(\"MCC: \", mcc)\n",
    "\n",
    "    # Make predictions on the rejected data\n",
    "    pred = KGB1.predict_proba(r_dev)[:, 1]\n",
    "    pred = pd.DataFrame(\n",
    "        data=pred,\n",
    "        columns=[\"target\"],\n",
    "        index=r_dev.index.copy(),\n",
    "    )\n",
    "    # Choose the most certain predictions\n",
    "    lq = pred[\"target\"].quantile(q=0.05)\n",
    "    uq = pred[\"target\"].quantile(q=0.95)\n",
    "    pred[\"certain\"] = pred[\"target\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\n",
    "\n",
    "    # If PD is high, apply default status\n",
    "    pred[\"target\"] = pred[\"target\"].apply(lambda x: 1 if (x > uq) else 0)\n",
    "\n",
    "    # Pick only the certain predictions and concatenate them to the dev set\n",
    "    # Y TRAIN\n",
    "    certain = pred[pred[\"certain\"] == 1]\n",
    "    certain2 = certain[\"target\"].to_frame()\n",
    "    y_train = pd.concat((y_train, certain2))\n",
    "\n",
    "    # Get significant columns of the rejects based on index\n",
    "    certain_features = pd.merge(\n",
    "        certain[\"target\"],\n",
    "        r_dev[significant_columns],\n",
    "        how=\"inner\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    # X TRAIN\n",
    "    certain_features = certain_features.loc[:, certain_features.columns != \"target\"]\n",
    "    X_train = pd.concat((X_train, certain_features))\n",
    "\n",
    "    # Remove certain columns from rejected data\n",
    "    rows = certain_features.index\n",
    "    r_dev = r_dev.drop(rows, axis=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. KGB model of best iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: KGB Model ($m_{1}$)  <br>\n",
    "Step 2: Infer status of each reject <br> \n",
    "Step 3: Choose the most certain predictions (0.05q and 0.95q of the predicted probailities) <br>\n",
    "Step 4: Add the most certain predictions to the training sample\n",
    "Step 5: Redevelop KGB Model ($m_{2}$)  <br>\n",
    "Step 6: Repeat Step 5 until convergence - best F1 score ($m_{i}$)  <br> \n",
    "Step 7: Score Test Accepts and Test Rejects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"pred_test_a = evaluate_test_accepts(KGB1, X_test)\\npred_test_r = evaluate_test_rejects(KGB1, r_test)\";\n",
       "                var nbb_formatted_code = \"pred_test_a = evaluate_test_accepts(KGB1, X_test)\\npred_test_r = evaluate_test_rejects(KGB1, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a = evaluate_test_accepts(KGB1, X_test)\n",
    "pred_test_r = evaluate_test_rejects(KGB1, r_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_iter = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_iter = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a[\"Flag\"] = pred_test_a.apply(flag_df_baseline, axis=1)\n",
    "predictions_accepts_iter = [round(kickout_baseline(pred_test_a).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_iter = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_iter = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_r[\"Flag\"] = pred_test_r.apply(flag_df_baseline, axis=1)\n",
    "predictions_rejects_iter = [round(kickout_baseline(pred_test_r).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. New model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: KGB Model ($m_{1}$)  <br>\n",
    "Step 2: Infer status of each reject <br> \n",
    "Step 3: Choose the most certain predictions (0.05q and 0.95q of the predicted probailities) <br>\n",
    "Step 4: Add the most certain predictions to the training sample <br>\n",
    "Step 5: Redevelop KGB Model ($m_{2}$)  <br>\n",
    "Step 6: Repeat Step 5 until convergence - best F1 score ($m_{i}$) <br> \n",
    "Step 7: Infer status of each reject with ($m_{i}$) <br> \n",
    "Step 8: Redevelop KGB mdoel with inferred rejects ($m_{final}$) <br> \n",
    "Step 9: Score Test Accepts and Test Rejects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"KGB_baseline_new = predict_rejects(KGB1, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\";\n",
       "                var nbb_formatted_code = \"KGB_baseline_new = predict_rejects(KGB1, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "KGB_baseline_new = predict_rejects(KGB1, r_dev)\n",
    "pred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\n",
    "pred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_new = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_new = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a[\"Flag\"] = pred_test_a.apply(flag_df_baseline, axis=1)\n",
    "predictions_accepts_new = [round(kickout_baseline(pred_test_a).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_new = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_new = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_r[\"Flag\"] = pred_test_r.apply(flag_df_baseline, axis=1)\n",
    "predictions_rejects_new = [round(kickout_baseline(pred_test_r).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parcelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"significant_columns = [\\n    \\\"known_col_0\\\",\\n    \\\"known_col_1\\\",\\n    \\\"known_col_3\\\",\\n    \\\"known_col_4\\\",\\n]\";\n",
       "                var nbb_formatted_code = \"significant_columns = [\\n    \\\"known_col_0\\\",\\n    \\\"known_col_1\\\",\\n    \\\"known_col_3\\\",\\n    \\\"known_col_4\\\",\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "significant_columns = [\n",
    "    \"known_col_0\",\n",
    "    \"known_col_1\",\n",
    "    \"known_col_3\",\n",
    "    \"known_col_4\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# Create copies of the dataframes\\nX_train_parc = X_train2[significant_columns]\\ny_train_parc = y_train2\\nX_test = X_test2[significant_columns]\\nr_dev = r_dev2[significant_columns]\";\n",
       "                var nbb_formatted_code = \"# Create copies of the dataframes\\nX_train_parc = X_train2[significant_columns]\\ny_train_parc = y_train2\\nX_test = X_test2[significant_columns]\\nr_dev = r_dev2[significant_columns]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create copies of the dataframes\n",
    "X_train_parc = X_train2[significant_columns]\n",
    "y_train_parc = y_train2\n",
    "X_test = X_test2[significant_columns]\n",
    "r_dev = r_dev2[significant_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>known_col_0</th>\n",
       "      <th>known_col_1</th>\n",
       "      <th>known_col_3</th>\n",
       "      <th>known_col_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13305</th>\n",
       "      <td>-1.043541</td>\n",
       "      <td>0.594547</td>\n",
       "      <td>-1.848210</td>\n",
       "      <td>-1.015519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17082</th>\n",
       "      <td>0.793891</td>\n",
       "      <td>-0.270097</td>\n",
       "      <td>0.432016</td>\n",
       "      <td>-0.416607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13301</th>\n",
       "      <td>-0.403891</td>\n",
       "      <td>-0.493661</td>\n",
       "      <td>-0.112094</td>\n",
       "      <td>0.597364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3747</th>\n",
       "      <td>0.014958</td>\n",
       "      <td>0.062999</td>\n",
       "      <td>-0.675906</td>\n",
       "      <td>0.843194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15024</th>\n",
       "      <td>-1.245504</td>\n",
       "      <td>-1.361101</td>\n",
       "      <td>-1.711946</td>\n",
       "      <td>-0.365454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11108</th>\n",
       "      <td>0.088334</td>\n",
       "      <td>-0.078472</td>\n",
       "      <td>0.074953</td>\n",
       "      <td>-0.180670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3353</th>\n",
       "      <td>0.848064</td>\n",
       "      <td>1.241789</td>\n",
       "      <td>0.454572</td>\n",
       "      <td>-0.227225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7497</th>\n",
       "      <td>-0.468867</td>\n",
       "      <td>0.061579</td>\n",
       "      <td>-0.975732</td>\n",
       "      <td>0.235623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15913</th>\n",
       "      <td>0.440719</td>\n",
       "      <td>-0.870013</td>\n",
       "      <td>0.960253</td>\n",
       "      <td>0.262081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9722</th>\n",
       "      <td>-1.201957</td>\n",
       "      <td>-0.677197</td>\n",
       "      <td>-0.410462</td>\n",
       "      <td>-0.433517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       known_col_0  known_col_1  known_col_3  known_col_4\n",
       "13305    -1.043541     0.594547    -1.848210    -1.015519\n",
       "17082     0.793891    -0.270097     0.432016    -0.416607\n",
       "13301    -0.403891    -0.493661    -0.112094     0.597364\n",
       "3747      0.014958     0.062999    -0.675906     0.843194\n",
       "15024    -1.245504    -1.361101    -1.711946    -0.365454\n",
       "...            ...          ...          ...          ...\n",
       "11108     0.088334    -0.078472     0.074953    -0.180670\n",
       "3353      0.848064     1.241789     0.454572    -0.227225\n",
       "7497     -0.468867     0.061579    -0.975732     0.235623\n",
       "15913     0.440719    -0.870013     0.960253     0.262081\n",
       "9722     -1.201957    -0.677197    -0.410462    -0.433517\n",
       "\n",
       "[3200 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"X_test\";\n",
       "                var nbb_formatted_code = \"X_test\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8803005414427618"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# Check how well known_col_0 discriminates goods and bads. Use as \\\"score\\\"\\nreg1 = LogisticRegression(fit_intercept=True, penalty=\\\"none\\\").fit(\\n    X_train_parc[[\\\"known_col_0\\\"]], y_train_parc\\n)\\nf1_score(y_test, reg1.predict(X_test[[\\\"known_col_0\\\"]]), average=\\\"weighted\\\")\";\n",
       "                var nbb_formatted_code = \"# Check how well known_col_0 discriminates goods and bads. Use as \\\"score\\\"\\nreg1 = LogisticRegression(fit_intercept=True, penalty=\\\"none\\\").fit(\\n    X_train_parc[[\\\"known_col_0\\\"]], y_train_parc\\n)\\nf1_score(y_test, reg1.predict(X_test[[\\\"known_col_0\\\"]]), average=\\\"weighted\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check how well known_col_0 discriminates goods and bads. Use as \"score\"\n",
    "reg1 = LogisticRegression(fit_intercept=True, penalty=\"none\").fit(\n",
    "    X_train_parc[[\"known_col_0\"]], y_train_parc\n",
    ")\n",
    "f1_score(y_test, reg1.predict(X_test[[\"known_col_0\"]]), average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Create 10 score bands\\nX_train_parc[\\\"score_band\\\"] = pd.qcut(X_train_parc[\\\"known_col_0\\\"].values, 10)\\nX_train_parc[\\\"nr_band\\\"] = pd.qcut(X_train_parc[\\\"known_col_0\\\"].values, 10, labels=False)\";\n",
       "                var nbb_formatted_code = \"# Create 10 score bands\\nX_train_parc[\\\"score_band\\\"] = pd.qcut(X_train_parc[\\\"known_col_0\\\"].values, 10)\\nX_train_parc[\\\"nr_band\\\"] = pd.qcut(X_train_parc[\\\"known_col_0\\\"].values, 10, labels=False)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create 10 score bands\n",
    "X_train_parc[\"score_band\"] = pd.qcut(X_train_parc[\"known_col_0\"].values, 10)\n",
    "X_train_parc[\"nr_band\"] = pd.qcut(X_train_parc[\"known_col_0\"].values, 10, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# Attach target\\ndf = pd.merge(\\n    X_train_parc,\\n    y_train_parc,\\n    how=\\\"inner\\\",\\n    left_index=True,\\n    right_index=True,\\n)\";\n",
       "                var nbb_formatted_code = \"# Attach target\\ndf = pd.merge(\\n    X_train_parc,\\n    y_train_parc,\\n    how=\\\"inner\\\",\\n    left_index=True,\\n    right_index=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Attach target\n",
    "df = pd.merge(\n",
    "    X_train_parc,\n",
    "    y_train_parc,\n",
    "    how=\"inner\",\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Select rows with target = 1\\ndf_bad = df[df[\\\"target\\\"] == 1]\\n# Select rows with target = 0\\ndf_good = df[df[\\\"target\\\"] == 0]\";\n",
       "                var nbb_formatted_code = \"# Select rows with target = 1\\ndf_bad = df[df[\\\"target\\\"] == 1]\\n# Select rows with target = 0\\ndf_good = df[df[\\\"target\\\"] == 0]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select rows with target = 1\n",
    "df_bad = df[df[\"target\"] == 1]\n",
    "# Select rows with target = 0\n",
    "df_good = df[df[\"target\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Count nr of bads in each interval\\ndf_bad = df_bad.groupby(\\\"nr_band\\\").size().sort_values().reset_index(name=\\\"nr_bad\\\")\\ndf_good = df_good.groupby(\\\"nr_band\\\").size().sort_values().reset_index(name=\\\"nr_good\\\")\";\n",
       "                var nbb_formatted_code = \"# Count nr of bads in each interval\\ndf_bad = df_bad.groupby(\\\"nr_band\\\").size().sort_values().reset_index(name=\\\"nr_bad\\\")\\ndf_good = df_good.groupby(\\\"nr_band\\\").size().sort_values().reset_index(name=\\\"nr_good\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count nr of bads in each interval\n",
    "df_bad = df_bad.groupby(\"nr_band\").size().sort_values().reset_index(name=\"nr_bad\")\n",
    "df_good = df_good.groupby(\"nr_band\").size().sort_values().reset_index(name=\"nr_good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Merge counts with original data\\ndf = pd.merge(df, df_bad, on=\\\"nr_band\\\")\\ndf = pd.merge(df, df_good, on=\\\"nr_band\\\")\";\n",
       "                var nbb_formatted_code = \"# Merge counts with original data\\ndf = pd.merge(df, df_bad, on=\\\"nr_band\\\")\\ndf = pd.merge(df, df_good, on=\\\"nr_band\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Merge counts with original data\n",
    "df = pd.merge(df, df_bad, on=\"nr_band\")\n",
    "df = pd.merge(df, df_good, on=\"nr_band\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"# Calculate %good and %bads\\ndf[\\\"perc_good\\\"] = df[\\\"nr_good\\\"] / (df[\\\"nr_bad\\\"] + df[\\\"nr_good\\\"])\\ndf[\\\"perc_bad\\\"] = df[\\\"nr_bad\\\"] / (df[\\\"nr_bad\\\"] + df[\\\"nr_good\\\"])\";\n",
       "                var nbb_formatted_code = \"# Calculate %good and %bads\\ndf[\\\"perc_good\\\"] = df[\\\"nr_good\\\"] / (df[\\\"nr_bad\\\"] + df[\\\"nr_good\\\"])\\ndf[\\\"perc_bad\\\"] = df[\\\"nr_bad\\\"] / (df[\\\"nr_bad\\\"] + df[\\\"nr_good\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate %good and %bads\n",
    "df[\"perc_good\"] = df[\"nr_good\"] / (df[\"nr_bad\"] + df[\"nr_good\"])\n",
    "df[\"perc_bad\"] = df[\"nr_bad\"] / (df[\"nr_bad\"] + df[\"nr_good\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>known_col_0</th>\n",
       "      <th>known_col_1</th>\n",
       "      <th>known_col_3</th>\n",
       "      <th>known_col_4</th>\n",
       "      <th>score_band</th>\n",
       "      <th>nr_band</th>\n",
       "      <th>target</th>\n",
       "      <th>nr_bad</th>\n",
       "      <th>nr_good</th>\n",
       "      <th>perc_good</th>\n",
       "      <th>perc_bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.792550</td>\n",
       "      <td>-2.589498</td>\n",
       "      <td>-0.503701</td>\n",
       "      <td>-0.449694</td>\n",
       "      <td>(-4.1160000000000005, -1.289]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>1085</td>\n",
       "      <td>0.847656</td>\n",
       "      <td>0.152344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7680</th>\n",
       "      <td>-1.132605</td>\n",
       "      <td>1.069127</td>\n",
       "      <td>1.699274</td>\n",
       "      <td>-0.177224</td>\n",
       "      <td>(-1.289, -0.849]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>1127</td>\n",
       "      <td>0.880469</td>\n",
       "      <td>0.119531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>-0.537899</td>\n",
       "      <td>-0.233608</td>\n",
       "      <td>1.313849</td>\n",
       "      <td>-0.671964</td>\n",
       "      <td>(-0.849, -0.532]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>1155</td>\n",
       "      <td>0.902344</td>\n",
       "      <td>0.097656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6400</th>\n",
       "      <td>-0.464268</td>\n",
       "      <td>-0.574961</td>\n",
       "      <td>0.396083</td>\n",
       "      <td>0.211963</td>\n",
       "      <td>(-0.532, -0.258]</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>1165</td>\n",
       "      <td>0.910156</td>\n",
       "      <td>0.089844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11520</th>\n",
       "      <td>-0.069581</td>\n",
       "      <td>-0.617390</td>\n",
       "      <td>-1.040663</td>\n",
       "      <td>-1.869903</td>\n",
       "      <td>(-0.258, -0.000969]</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>1178</td>\n",
       "      <td>0.920312</td>\n",
       "      <td>0.079687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5120</th>\n",
       "      <td>0.031915</td>\n",
       "      <td>-0.569975</td>\n",
       "      <td>-0.433074</td>\n",
       "      <td>-1.161790</td>\n",
       "      <td>(-0.000969, 0.252]</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>1187</td>\n",
       "      <td>0.927344</td>\n",
       "      <td>0.072656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10240</th>\n",
       "      <td>0.469467</td>\n",
       "      <td>0.430855</td>\n",
       "      <td>0.138424</td>\n",
       "      <td>0.342455</td>\n",
       "      <td>(0.252, 0.529]</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>1201</td>\n",
       "      <td>0.938281</td>\n",
       "      <td>0.061719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2560</th>\n",
       "      <td>0.566238</td>\n",
       "      <td>-0.143836</td>\n",
       "      <td>0.559692</td>\n",
       "      <td>0.048698</td>\n",
       "      <td>(0.529, 0.848]</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>1200</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840</th>\n",
       "      <td>1.064590</td>\n",
       "      <td>0.205395</td>\n",
       "      <td>2.053253</td>\n",
       "      <td>0.199221</td>\n",
       "      <td>(0.848, 1.303]</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>1196</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.065625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8960</th>\n",
       "      <td>1.522350</td>\n",
       "      <td>-0.073995</td>\n",
       "      <td>-0.109733</td>\n",
       "      <td>-0.828563</td>\n",
       "      <td>(1.303, 3.785]</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.964063</td>\n",
       "      <td>0.035937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       known_col_0  known_col_1  known_col_3  known_col_4  \\\n",
       "0        -2.792550    -2.589498    -0.503701    -0.449694   \n",
       "7680     -1.132605     1.069127     1.699274    -0.177224   \n",
       "1280     -0.537899    -0.233608     1.313849    -0.671964   \n",
       "6400     -0.464268    -0.574961     0.396083     0.211963   \n",
       "11520    -0.069581    -0.617390    -1.040663    -1.869903   \n",
       "5120      0.031915    -0.569975    -0.433074    -1.161790   \n",
       "10240     0.469467     0.430855     0.138424     0.342455   \n",
       "2560      0.566238    -0.143836     0.559692     0.048698   \n",
       "3840      1.064590     0.205395     2.053253     0.199221   \n",
       "8960      1.522350    -0.073995    -0.109733    -0.828563   \n",
       "\n",
       "                          score_band  nr_band  target  nr_bad  nr_good  \\\n",
       "0      (-4.1160000000000005, -1.289]        0       0     195     1085   \n",
       "7680                (-1.289, -0.849]        1       0     153     1127   \n",
       "1280                (-0.849, -0.532]        2       0     125     1155   \n",
       "6400                (-0.532, -0.258]        3       0     115     1165   \n",
       "11520            (-0.258, -0.000969]        4       0     102     1178   \n",
       "5120              (-0.000969, 0.252]        5       0      93     1187   \n",
       "10240                 (0.252, 0.529]        6       0      79     1201   \n",
       "2560                  (0.529, 0.848]        7       0      80     1200   \n",
       "3840                  (0.848, 1.303]        8       0      84     1196   \n",
       "8960                  (1.303, 3.785]        9       0      46     1234   \n",
       "\n",
       "       perc_good  perc_bad  \n",
       "0       0.847656  0.152344  \n",
       "7680    0.880469  0.119531  \n",
       "1280    0.902344  0.097656  \n",
       "6400    0.910156  0.089844  \n",
       "11520   0.920312  0.079687  \n",
       "5120    0.927344  0.072656  \n",
       "10240   0.938281  0.061719  \n",
       "2560    0.937500  0.062500  \n",
       "3840    0.934375  0.065625  \n",
       "8960    0.964063  0.035937  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"# Get distinct score bands\\ndf.drop_duplicates(subset=[\\\"score_band\\\"]).sort_values(by=\\\"nr_band\\\")\";\n",
       "                var nbb_formatted_code = \"# Get distinct score bands\\ndf.drop_duplicates(subset=[\\\"score_band\\\"]).sort_values(by=\\\"nr_band\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get distinct score bands\n",
    "df.drop_duplicates(subset=[\"score_band\"]).sort_values(by=\"nr_band\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"# make a copy of the r_dev data\\nr_dev_parc = r_dev.copy()\";\n",
       "                var nbb_formatted_code = \"# make a copy of the r_dev data\\nr_dev_parc = r_dev.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make a copy of the r_dev data\n",
    "r_dev_parc = r_dev.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"def rej_scoring(x):\\n    if x <= -1.289:\\n        return 0\\n    elif x > -1.289 and x <= -0.849:\\n        return 1\\n    elif x > -0.849 and x <= -0.532:\\n        return 2\\n    elif x > -0.534 and x <= -0.258:\\n        return 3\\n    elif x > -0.258 and x <= -0.000969:\\n        return 4\\n    elif x > -0.000969 and x <= 0.252:\\n        return 5\\n    elif x > 0.252 and x <= 0.529:\\n        return 6\\n    elif x > 0.529 and x <= 0.848:\\n        return 7\\n    elif x > 0.848 and x <= 1.303:\\n        return 8\\n    elif x > 1.303:\\n        return 9\";\n",
       "                var nbb_formatted_code = \"def rej_scoring(x):\\n    if x <= -1.289:\\n        return 0\\n    elif x > -1.289 and x <= -0.849:\\n        return 1\\n    elif x > -0.849 and x <= -0.532:\\n        return 2\\n    elif x > -0.534 and x <= -0.258:\\n        return 3\\n    elif x > -0.258 and x <= -0.000969:\\n        return 4\\n    elif x > -0.000969 and x <= 0.252:\\n        return 5\\n    elif x > 0.252 and x <= 0.529:\\n        return 6\\n    elif x > 0.529 and x <= 0.848:\\n        return 7\\n    elif x > 0.848 and x <= 1.303:\\n        return 8\\n    elif x > 1.303:\\n        return 9\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def rej_scoring(x):\n",
    "    if x <= -1.289:\n",
    "        return 0\n",
    "    elif x > -1.289 and x <= -0.849:\n",
    "        return 1\n",
    "    elif x > -0.849 and x <= -0.532:\n",
    "        return 2\n",
    "    elif x > -0.534 and x <= -0.258:\n",
    "        return 3\n",
    "    elif x > -0.258 and x <= -0.000969:\n",
    "        return 4\n",
    "    elif x > -0.000969 and x <= 0.252:\n",
    "        return 5\n",
    "    elif x > 0.252 and x <= 0.529:\n",
    "        return 6\n",
    "    elif x > 0.529 and x <= 0.848:\n",
    "        return 7\n",
    "    elif x > 0.848 and x <= 1.303:\n",
    "        return 8\n",
    "    elif x > 1.303:\n",
    "        return 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"# Apply these scores to the rejects\\nr_dev_parc[\\\"nr_band\\\"] = r_dev_parc[\\\"known_col_0\\\"].apply(rej_scoring)\";\n",
       "                var nbb_formatted_code = \"# Apply these scores to the rejects\\nr_dev_parc[\\\"nr_band\\\"] = r_dev_parc[\\\"known_col_0\\\"].apply(rej_scoring)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply these scores to the rejects\n",
    "r_dev_parc[\"nr_band\"] = r_dev_parc[\"known_col_0\"].apply(rej_scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"# Create another copy of the rejects\\nr_dev2 = r_dev_parc.copy()\";\n",
       "                var nbb_formatted_code = \"# Create another copy of the rejects\\nr_dev2 = r_dev_parc.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create another copy of the rejects\n",
    "r_dev2 = r_dev_parc.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"# Count number of rejects in each band\\nr_dev_parc = (\\n    r_dev_parc.groupby(\\\"nr_band\\\").size().sort_values().reset_index(name=\\\"nr_rejects\\\")\\n)\";\n",
       "                var nbb_formatted_code = \"# Count number of rejects in each band\\nr_dev_parc = (\\n    r_dev_parc.groupby(\\\"nr_band\\\").size().sort_values().reset_index(name=\\\"nr_rejects\\\")\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count number of rejects in each band\n",
    "r_dev_parc = (\n",
    "    r_dev_parc.groupby(\"nr_band\").size().sort_values().reset_index(name=\"nr_rejects\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"# attach rej. counts to original data\\ndf = pd.merge(df, r_dev_parc, on=\\\"nr_band\\\")\";\n",
       "                var nbb_formatted_code = \"# attach rej. counts to original data\\ndf = pd.merge(df, r_dev_parc, on=\\\"nr_band\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# attach rej. counts to original data\n",
    "df = pd.merge(df, r_dev_parc, on=\"nr_band\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"# infer nr rejects\\ndf[\\\"inf_good\\\"] = round((df[\\\"nr_rejects\\\"] * df[\\\"perc_good\\\"]), 0)\\ndf[\\\"inf_bad\\\"] = round((df[\\\"nr_rejects\\\"] * df[\\\"perc_bad\\\"]), 0)\";\n",
       "                var nbb_formatted_code = \"# infer nr rejects\\ndf[\\\"inf_good\\\"] = round((df[\\\"nr_rejects\\\"] * df[\\\"perc_good\\\"]), 0)\\ndf[\\\"inf_bad\\\"] = round((df[\\\"nr_rejects\\\"] * df[\\\"perc_bad\\\"]), 0)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# infer nr rejects\n",
    "df[\"inf_good\"] = round((df[\"nr_rejects\"] * df[\"perc_good\"]), 0)\n",
    "df[\"inf_bad\"] = round((df[\"nr_rejects\"] * df[\"perc_bad\"]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"# Augmentation factor\\n# Drop duplicates\\ndf[\\\"aug_factor\\\"] = (df[\\\"nr_bad\\\"] + df[\\\"nr_good\\\"] + df[\\\"nr_rejects\\\"]) / (\\n    df[\\\"nr_good\\\"] + df[\\\"nr_bad\\\"]\\n)\";\n",
       "                var nbb_formatted_code = \"# Augmentation factor\\n# Drop duplicates\\ndf[\\\"aug_factor\\\"] = (df[\\\"nr_bad\\\"] + df[\\\"nr_good\\\"] + df[\\\"nr_rejects\\\"]) / (\\n    df[\\\"nr_good\\\"] + df[\\\"nr_bad\\\"]\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Augmentation factor\n",
    "# Drop duplicates\n",
    "df[\"aug_factor\"] = (df[\"nr_bad\"] + df[\"nr_good\"] + df[\"nr_rejects\"]) / (\n",
    "    df[\"nr_good\"] + df[\"nr_bad\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"# Create Augmented nr of good and bad\\ndf[\\\"inf_bad_aug\\\"] = round((df[\\\"inf_bad\\\"] * df[\\\"aug_factor\\\"]), 0)\\ndf[\\\"inf_good_aug\\\"] = round((df[\\\"nr_rejects\\\"] - df[\\\"inf_bad_aug\\\"]), 0)\";\n",
       "                var nbb_formatted_code = \"# Create Augmented nr of good and bad\\ndf[\\\"inf_bad_aug\\\"] = round((df[\\\"inf_bad\\\"] * df[\\\"aug_factor\\\"]), 0)\\ndf[\\\"inf_good_aug\\\"] = round((df[\\\"nr_rejects\\\"] - df[\\\"inf_bad_aug\\\"]), 0)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Augmented nr of good and bad\n",
    "df[\"inf_bad_aug\"] = round((df[\"inf_bad\"] * df[\"aug_factor\"]), 0)\n",
    "df[\"inf_good_aug\"] = round((df[\"nr_rejects\"] - df[\"inf_bad_aug\"]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"# Inferred probabilities\\ndf[\\\"inf_p_good\\\"] = round((df[\\\"inf_good_aug\\\"] / df[\\\"nr_rejects\\\"]), 2)\\ndf[\\\"inf_p_bad\\\"] = round((df[\\\"inf_bad_aug\\\"] / df[\\\"nr_rejects\\\"]), 2)\";\n",
       "                var nbb_formatted_code = \"# Inferred probabilities\\ndf[\\\"inf_p_good\\\"] = round((df[\\\"inf_good_aug\\\"] / df[\\\"nr_rejects\\\"]), 2)\\ndf[\\\"inf_p_bad\\\"] = round((df[\\\"inf_bad_aug\\\"] / df[\\\"nr_rejects\\\"]), 2)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inferred probabilities\n",
    "df[\"inf_p_good\"] = round((df[\"inf_good_aug\"] / df[\"nr_rejects\"]), 2)\n",
    "df[\"inf_p_bad\"] = round((df[\"inf_bad_aug\"] / df[\"nr_rejects\"]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"df_n = df.drop_duplicates(subset=[\\\"score_band\\\"]).sort_values(by=\\\"nr_band\\\")\";\n",
       "                var nbb_formatted_code = \"df_n = df.drop_duplicates(subset=[\\\"score_band\\\"]).sort_values(by=\\\"nr_band\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_n = df.drop_duplicates(subset=[\"score_band\"]).sort_values(by=\"nr_band\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>known_col_0</th>\n",
       "      <th>known_col_1</th>\n",
       "      <th>known_col_3</th>\n",
       "      <th>known_col_4</th>\n",
       "      <th>score_band</th>\n",
       "      <th>nr_band</th>\n",
       "      <th>target</th>\n",
       "      <th>nr_bad</th>\n",
       "      <th>nr_good</th>\n",
       "      <th>perc_good</th>\n",
       "      <th>perc_bad</th>\n",
       "      <th>nr_rejects</th>\n",
       "      <th>inf_good</th>\n",
       "      <th>inf_bad</th>\n",
       "      <th>aug_factor</th>\n",
       "      <th>inf_bad_aug</th>\n",
       "      <th>inf_good_aug</th>\n",
       "      <th>inf_p_good</th>\n",
       "      <th>inf_p_bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.792550</td>\n",
       "      <td>-2.589498</td>\n",
       "      <td>-0.503701</td>\n",
       "      <td>-0.449694</td>\n",
       "      <td>(-4.1160000000000005, -1.289]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>1085</td>\n",
       "      <td>0.847656</td>\n",
       "      <td>0.152344</td>\n",
       "      <td>301</td>\n",
       "      <td>255.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.235156</td>\n",
       "      <td>57.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7680</th>\n",
       "      <td>-1.132605</td>\n",
       "      <td>1.069127</td>\n",
       "      <td>1.699274</td>\n",
       "      <td>-0.177224</td>\n",
       "      <td>(-1.289, -0.849]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>1127</td>\n",
       "      <td>0.880469</td>\n",
       "      <td>0.119531</td>\n",
       "      <td>290</td>\n",
       "      <td>255.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.226562</td>\n",
       "      <td>43.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>-0.537899</td>\n",
       "      <td>-0.233608</td>\n",
       "      <td>1.313849</td>\n",
       "      <td>-0.671964</td>\n",
       "      <td>(-0.849, -0.532]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>1155</td>\n",
       "      <td>0.902344</td>\n",
       "      <td>0.097656</td>\n",
       "      <td>340</td>\n",
       "      <td>307.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.265625</td>\n",
       "      <td>42.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6400</th>\n",
       "      <td>-0.464268</td>\n",
       "      <td>-0.574961</td>\n",
       "      <td>0.396083</td>\n",
       "      <td>0.211963</td>\n",
       "      <td>(-0.532, -0.258]</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>1165</td>\n",
       "      <td>0.910156</td>\n",
       "      <td>0.089844</td>\n",
       "      <td>308</td>\n",
       "      <td>280.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.240625</td>\n",
       "      <td>35.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11520</th>\n",
       "      <td>-0.069581</td>\n",
       "      <td>-0.617390</td>\n",
       "      <td>-1.040663</td>\n",
       "      <td>-1.869903</td>\n",
       "      <td>(-0.258, -0.000969]</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>1178</td>\n",
       "      <td>0.920312</td>\n",
       "      <td>0.079687</td>\n",
       "      <td>326</td>\n",
       "      <td>300.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.254687</td>\n",
       "      <td>33.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5120</th>\n",
       "      <td>0.031915</td>\n",
       "      <td>-0.569975</td>\n",
       "      <td>-0.433074</td>\n",
       "      <td>-1.161790</td>\n",
       "      <td>(-0.000969, 0.252]</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>1187</td>\n",
       "      <td>0.927344</td>\n",
       "      <td>0.072656</td>\n",
       "      <td>327</td>\n",
       "      <td>303.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.255469</td>\n",
       "      <td>30.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10240</th>\n",
       "      <td>0.469467</td>\n",
       "      <td>0.430855</td>\n",
       "      <td>0.138424</td>\n",
       "      <td>0.342455</td>\n",
       "      <td>(0.252, 0.529]</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>1201</td>\n",
       "      <td>0.938281</td>\n",
       "      <td>0.061719</td>\n",
       "      <td>344</td>\n",
       "      <td>323.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.268750</td>\n",
       "      <td>27.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2560</th>\n",
       "      <td>0.566238</td>\n",
       "      <td>-0.143836</td>\n",
       "      <td>0.559692</td>\n",
       "      <td>0.048698</td>\n",
       "      <td>(0.529, 0.848]</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>1200</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>347</td>\n",
       "      <td>325.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.271094</td>\n",
       "      <td>28.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840</th>\n",
       "      <td>1.064590</td>\n",
       "      <td>0.205395</td>\n",
       "      <td>2.053253</td>\n",
       "      <td>0.199221</td>\n",
       "      <td>(0.848, 1.303]</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>1196</td>\n",
       "      <td>0.934375</td>\n",
       "      <td>0.065625</td>\n",
       "      <td>322</td>\n",
       "      <td>301.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.251562</td>\n",
       "      <td>26.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8960</th>\n",
       "      <td>1.522350</td>\n",
       "      <td>-0.073995</td>\n",
       "      <td>-0.109733</td>\n",
       "      <td>-0.828563</td>\n",
       "      <td>(1.303, 3.785]</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>1234</td>\n",
       "      <td>0.964063</td>\n",
       "      <td>0.035937</td>\n",
       "      <td>295</td>\n",
       "      <td>284.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.230469</td>\n",
       "      <td>14.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       known_col_0  known_col_1  known_col_3  known_col_4  \\\n",
       "0        -2.792550    -2.589498    -0.503701    -0.449694   \n",
       "7680     -1.132605     1.069127     1.699274    -0.177224   \n",
       "1280     -0.537899    -0.233608     1.313849    -0.671964   \n",
       "6400     -0.464268    -0.574961     0.396083     0.211963   \n",
       "11520    -0.069581    -0.617390    -1.040663    -1.869903   \n",
       "5120      0.031915    -0.569975    -0.433074    -1.161790   \n",
       "10240     0.469467     0.430855     0.138424     0.342455   \n",
       "2560      0.566238    -0.143836     0.559692     0.048698   \n",
       "3840      1.064590     0.205395     2.053253     0.199221   \n",
       "8960      1.522350    -0.073995    -0.109733    -0.828563   \n",
       "\n",
       "                          score_band  nr_band  target  nr_bad  nr_good  \\\n",
       "0      (-4.1160000000000005, -1.289]        0       0     195     1085   \n",
       "7680                (-1.289, -0.849]        1       0     153     1127   \n",
       "1280                (-0.849, -0.532]        2       0     125     1155   \n",
       "6400                (-0.532, -0.258]        3       0     115     1165   \n",
       "11520            (-0.258, -0.000969]        4       0     102     1178   \n",
       "5120              (-0.000969, 0.252]        5       0      93     1187   \n",
       "10240                 (0.252, 0.529]        6       0      79     1201   \n",
       "2560                  (0.529, 0.848]        7       0      80     1200   \n",
       "3840                  (0.848, 1.303]        8       0      84     1196   \n",
       "8960                  (1.303, 3.785]        9       0      46     1234   \n",
       "\n",
       "       perc_good  perc_bad  nr_rejects  inf_good  inf_bad  aug_factor  \\\n",
       "0       0.847656  0.152344         301     255.0     46.0    1.235156   \n",
       "7680    0.880469  0.119531         290     255.0     35.0    1.226562   \n",
       "1280    0.902344  0.097656         340     307.0     33.0    1.265625   \n",
       "6400    0.910156  0.089844         308     280.0     28.0    1.240625   \n",
       "11520   0.920312  0.079687         326     300.0     26.0    1.254687   \n",
       "5120    0.927344  0.072656         327     303.0     24.0    1.255469   \n",
       "10240   0.938281  0.061719         344     323.0     21.0    1.268750   \n",
       "2560    0.937500  0.062500         347     325.0     22.0    1.271094   \n",
       "3840    0.934375  0.065625         322     301.0     21.0    1.251562   \n",
       "8960    0.964063  0.035937         295     284.0     11.0    1.230469   \n",
       "\n",
       "       inf_bad_aug  inf_good_aug  inf_p_good  inf_p_bad  \n",
       "0             57.0         244.0        0.81       0.19  \n",
       "7680          43.0         247.0        0.85       0.15  \n",
       "1280          42.0         298.0        0.88       0.12  \n",
       "6400          35.0         273.0        0.89       0.11  \n",
       "11520         33.0         293.0        0.90       0.10  \n",
       "5120          30.0         297.0        0.91       0.09  \n",
       "10240         27.0         317.0        0.92       0.08  \n",
       "2560          28.0         319.0        0.92       0.08  \n",
       "3840          26.0         296.0        0.92       0.08  \n",
       "8960          14.0         281.0        0.95       0.05  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 62;\n",
       "                var nbb_unformatted_code = \"df_n\";\n",
       "                var nbb_formatted_code = \"df_n\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Random Parcelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 63;\n",
       "                var nbb_unformatted_code = \"# Assign randomly given number of bads in each interval with a bad status with their given probabilities\\n\\ndf_list = []\\nfor i in range(0, 9):\\n    data = r_dev2[r_dev2[\\\"nr_band\\\"] == i]\\n    data[\\\"target\\\"] = np.random.choice(\\n        [0, 1],\\n        len(data),\\n        p=[float(df_n[[\\\"inf_p_good\\\"]].iloc[1]), float(df_n[[\\\"inf_p_bad\\\"]].iloc[1])],\\n    )\\n    df_list.append(data)\";\n",
       "                var nbb_formatted_code = \"# Assign randomly given number of bads in each interval with a bad status with their given probabilities\\n\\ndf_list = []\\nfor i in range(0, 9):\\n    data = r_dev2[r_dev2[\\\"nr_band\\\"] == i]\\n    data[\\\"target\\\"] = np.random.choice(\\n        [0, 1],\\n        len(data),\\n        p=[float(df_n[[\\\"inf_p_good\\\"]].iloc[1]), float(df_n[[\\\"inf_p_bad\\\"]].iloc[1])],\\n    )\\n    df_list.append(data)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assign randomly given number of bads in each interval with a bad status with their given probabilities\n",
    "\n",
    "df_list = []\n",
    "for i in range(0, 9):\n",
    "    data = r_dev2[r_dev2[\"nr_band\"] == i]\n",
    "    data[\"target\"] = np.random.choice(\n",
    "        [0, 1],\n",
    "        len(data),\n",
    "        p=[float(df_n[[\"inf_p_good\"]].iloc[1]), float(df_n[[\"inf_p_bad\"]].iloc[1])],\n",
    "    )\n",
    "    df_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 64;\n",
       "                var nbb_unformatted_code = \"# Concatenate all dataframes\\nnew_rej = pd.concat(df_list)\";\n",
       "                var nbb_formatted_code = \"# Concatenate all dataframes\\nnew_rej = pd.concat(df_list)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenate all dataframes\n",
    "new_rej = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 65;\n",
       "                var nbb_unformatted_code = \"significant_columns = [\\n    # \\\"known_col_0\\\",\\n    \\\"known_col_1\\\",\\n    \\\"known_col_3\\\",\\n    \\\"known_col_4\\\",\\n]\";\n",
       "                var nbb_formatted_code = \"significant_columns = [\\n    # \\\"known_col_0\\\",\\n    \\\"known_col_1\\\",\\n    \\\"known_col_3\\\",\\n    \\\"known_col_4\\\",\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "significant_columns = [\n",
    "    # \"known_col_0\",\n",
    "    \"known_col_1\",\n",
    "    \"known_col_3\",\n",
    "    \"known_col_4\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 66;\n",
       "                var nbb_unformatted_code = \"# Add new rows to df\\n\\n# Split X and y\\nnew_rej_X, new_rej_y = create_X_y(new_rej)\\nnew_rej_X = new_rej_X[significant_columns]\\n\\n# Extend training set\\ny_train_new = pd.concat((y_train, new_rej_y))\\nX_train_new = pd.concat((X_train, new_rej_X))\\n\\n# Fit new model\\nKGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n    X_train_new, y_train_new\\n)\";\n",
       "                var nbb_formatted_code = \"# Add new rows to df\\n\\n# Split X and y\\nnew_rej_X, new_rej_y = create_X_y(new_rej)\\nnew_rej_X = new_rej_X[significant_columns]\\n\\n# Extend training set\\ny_train_new = pd.concat((y_train, new_rej_y))\\nX_train_new = pd.concat((X_train, new_rej_X))\\n\\n# Fit new model\\nKGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n    X_train_new, y_train_new\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add new rows to df\n",
    "\n",
    "# Split X and y\n",
    "new_rej_X, new_rej_y = create_X_y(new_rej)\n",
    "new_rej_X = new_rej_X[significant_columns]\n",
    "\n",
    "# Extend training set\n",
    "y_train_new = pd.concat((y_train, new_rej_y))\n",
    "X_train_new = pd.concat((X_train, new_rej_X))\n",
    "\n",
    "# Fit new model\n",
    "KGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(\n",
    "    X_train_new, y_train_new\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 67;\n",
       "                var nbb_unformatted_code = \"pred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test[significant_columns])\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test[significant_columns])\";\n",
       "                var nbb_formatted_code = \"pred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test[significant_columns])\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test[significant_columns])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test[significant_columns])\n",
    "pred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test[significant_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 68;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_rand_parc = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_rand_parc = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a[\"Flag\"] = pred_test_a.apply(flag_df_baseline, axis=1)\n",
    "predictions_accepts_rand_parc = [round(kickout_baseline(pred_test_a).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 69;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_rand_parc = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_rand_parc = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_r[\"Flag\"] = pred_test_r.apply(flag_df_baseline, axis=1)\n",
    "predictions_rejects_rand_parc = [round(kickout_baseline(pred_test_r).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Non-Random Parcelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 70;\n",
       "                var nbb_unformatted_code = \"# Band 0\";\n",
       "                var nbb_formatted_code = \"# Band 0\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Band 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 71;\n",
       "                var nbb_unformatted_code = \"# r_dev_iter0 = r_dev2[r_dev2[\\\"nr_band\\\"] == 0]\\n# X_train_iter0 = X_train_parc[X_train_parc[\\\"nr_band\\\"] == 0]\\n# y_train_iter0 = pd.merge(\\n#     X_train_iter0[\\\"known_col_0\\\"],\\n#     y_train_parc,\\n#     how=\\\"inner\\\",\\n#     left_index=True,\\n#     right_index=True,\\n# )\\n# X_train_iter0 = X_train_iter0[significant_columns]\\n# X_test = X_test[significant_columns]\\n# # Drop unnecessary columns\\n# y_train_iter0 = y_train_iter0.drop([\\\"known_col_0\\\"], axis=1)\";\n",
       "                var nbb_formatted_code = \"# r_dev_iter0 = r_dev2[r_dev2[\\\"nr_band\\\"] == 0]\\n# X_train_iter0 = X_train_parc[X_train_parc[\\\"nr_band\\\"] == 0]\\n# y_train_iter0 = pd.merge(\\n#     X_train_iter0[\\\"known_col_0\\\"],\\n#     y_train_parc,\\n#     how=\\\"inner\\\",\\n#     left_index=True,\\n#     right_index=True,\\n# )\\n# X_train_iter0 = X_train_iter0[significant_columns]\\n# X_test = X_test[significant_columns]\\n# # Drop unnecessary columns\\n# y_train_iter0 = y_train_iter0.drop([\\\"known_col_0\\\"], axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# r_dev_iter0 = r_dev2[r_dev2[\"nr_band\"] == 0]\n",
    "# X_train_iter0 = X_train_parc[X_train_parc[\"nr_band\"] == 0]\n",
    "# y_train_iter0 = pd.merge(\n",
    "#     X_train_iter0[\"known_col_0\"],\n",
    "#     y_train_parc,\n",
    "#     how=\"inner\",\n",
    "#     left_index=True,\n",
    "#     right_index=True,\n",
    "# )\n",
    "# X_train_iter0 = X_train_iter0[significant_columns]\n",
    "# X_test = X_test[significant_columns]\n",
    "# # Drop unnecessary columns\n",
    "# y_train_iter0 = y_train_iter0.drop([\"known_col_0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 72;\n",
       "                var nbb_unformatted_code = \"# mccs = []\\n# for iteration in range(1, 10):  # Change to how many iterrations you like\\n#     print(\\\"Iteration Nr {}\\\".format(iteration))\\n#     # Build logistic regression\\n#     KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n#         X_train_iter0, y_train_iter0\\n#     )\\n\\n#     # Scores\\n#     #     f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\\\"weighted\\\")\\n#     #     f1_scores.append(f1_stat)\\n\\n#     #     logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\\n#     #     log_losses.append(logloss)\\n\\n#     #     print(\\\"F1: \\\", f1_stat)\\n\\n#     mcc = matthews_corrcoef(y_test, KGB1.predict(X_test))\\n#     mccs.append(mcc)\\n\\n#     print(\\\"MCC: \\\", mcc)\\n\\n#     # Make predictions on the rejected data\\n#     pred = KGB1.predict_proba(r_dev_iter0[significant_columns])[:, 1]\\n#     pred = pd.DataFrame(\\n#         data=pred,\\n#         columns=[\\\"target\\\"],\\n#         index=r_dev_iter0.index.copy(),\\n#     )\\n\\n#     # Choose the most certain predictions\\n#     lq = pred[\\\"target\\\"].quantile(q=0.05)\\n#     uq = pred[\\\"target\\\"].quantile(q=0.95)\\n#     pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n#     # If PD is high, apply default status\\n#     pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n#     # Pick only the certain predictions and concatenate them to the dev set\\n#     # Y TRAIN\\n#     certain = pred[pred[\\\"certain\\\"] == 1]\\n#     certain2 = certain[\\\"target\\\"].to_frame()\\n#     y_train_iter0 = pd.concat((y_train_iter0, certain2))\\n\\n#     # Get significant columns of the rejects based on index\\n#     certain_features = pd.merge(\\n#         certain[\\\"target\\\"],\\n#         r_dev_iter0[significant_columns],\\n#         how=\\\"inner\\\",\\n#         left_index=True,\\n#         right_index=True,\\n#     )\\n\\n#     # X TRAIN\\n#     certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n#     X_train_iter0 = pd.concat((X_train_iter0, certain_features))\\n\\n#     # Remove certain columns from rejected data\\n#     rows = certain_features.index\\n#     r_dev_iter0 = r_dev_iter0.drop(rows, axis=\\\"index\\\")\\n#     df_list.append(df)\";\n",
       "                var nbb_formatted_code = \"# mccs = []\\n# for iteration in range(1, 10):  # Change to how many iterrations you like\\n#     print(\\\"Iteration Nr {}\\\".format(iteration))\\n#     # Build logistic regression\\n#     KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n#         X_train_iter0, y_train_iter0\\n#     )\\n\\n#     # Scores\\n#     #     f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\\\"weighted\\\")\\n#     #     f1_scores.append(f1_stat)\\n\\n#     #     logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\\n#     #     log_losses.append(logloss)\\n\\n#     #     print(\\\"F1: \\\", f1_stat)\\n\\n#     mcc = matthews_corrcoef(y_test, KGB1.predict(X_test))\\n#     mccs.append(mcc)\\n\\n#     print(\\\"MCC: \\\", mcc)\\n\\n#     # Make predictions on the rejected data\\n#     pred = KGB1.predict_proba(r_dev_iter0[significant_columns])[:, 1]\\n#     pred = pd.DataFrame(\\n#         data=pred,\\n#         columns=[\\\"target\\\"],\\n#         index=r_dev_iter0.index.copy(),\\n#     )\\n\\n#     # Choose the most certain predictions\\n#     lq = pred[\\\"target\\\"].quantile(q=0.05)\\n#     uq = pred[\\\"target\\\"].quantile(q=0.95)\\n#     pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n#     # If PD is high, apply default status\\n#     pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n#     # Pick only the certain predictions and concatenate them to the dev set\\n#     # Y TRAIN\\n#     certain = pred[pred[\\\"certain\\\"] == 1]\\n#     certain2 = certain[\\\"target\\\"].to_frame()\\n#     y_train_iter0 = pd.concat((y_train_iter0, certain2))\\n\\n#     # Get significant columns of the rejects based on index\\n#     certain_features = pd.merge(\\n#         certain[\\\"target\\\"],\\n#         r_dev_iter0[significant_columns],\\n#         how=\\\"inner\\\",\\n#         left_index=True,\\n#         right_index=True,\\n#     )\\n\\n#     # X TRAIN\\n#     certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n#     X_train_iter0 = pd.concat((X_train_iter0, certain_features))\\n\\n#     # Remove certain columns from rejected data\\n#     rows = certain_features.index\\n#     r_dev_iter0 = r_dev_iter0.drop(rows, axis=\\\"index\\\")\\n#     df_list.append(df)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mccs = []\n",
    "# for iteration in range(1, 10):  # Change to how many iterrations you like\n",
    "#     print(\"Iteration Nr {}\".format(iteration))\n",
    "#     # Build logistic regression\n",
    "#     KGB1 = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(\n",
    "#         X_train_iter0, y_train_iter0\n",
    "#     )\n",
    "\n",
    "#     # Scores\n",
    "#     #     f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\"weighted\")\n",
    "#     #     f1_scores.append(f1_stat)\n",
    "\n",
    "#     #     logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\n",
    "#     #     log_losses.append(logloss)\n",
    "\n",
    "#     #     print(\"F1: \", f1_stat)\n",
    "\n",
    "#     mcc = matthews_corrcoef(y_test, KGB1.predict(X_test))\n",
    "#     mccs.append(mcc)\n",
    "\n",
    "#     print(\"MCC: \", mcc)\n",
    "\n",
    "#     # Make predictions on the rejected data\n",
    "#     pred = KGB1.predict_proba(r_dev_iter0[significant_columns])[:, 1]\n",
    "#     pred = pd.DataFrame(\n",
    "#         data=pred,\n",
    "#         columns=[\"target\"],\n",
    "#         index=r_dev_iter0.index.copy(),\n",
    "#     )\n",
    "\n",
    "#     # Choose the most certain predictions\n",
    "#     lq = pred[\"target\"].quantile(q=0.05)\n",
    "#     uq = pred[\"target\"].quantile(q=0.95)\n",
    "#     pred[\"certain\"] = pred[\"target\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\n",
    "\n",
    "#     # If PD is high, apply default status\n",
    "#     pred[\"target\"] = pred[\"target\"].apply(lambda x: 1 if (x > uq) else 0)\n",
    "\n",
    "#     # Pick only the certain predictions and concatenate them to the dev set\n",
    "#     # Y TRAIN\n",
    "#     certain = pred[pred[\"certain\"] == 1]\n",
    "#     certain2 = certain[\"target\"].to_frame()\n",
    "#     y_train_iter0 = pd.concat((y_train_iter0, certain2))\n",
    "\n",
    "#     # Get significant columns of the rejects based on index\n",
    "#     certain_features = pd.merge(\n",
    "#         certain[\"target\"],\n",
    "#         r_dev_iter0[significant_columns],\n",
    "#         how=\"inner\",\n",
    "#         left_index=True,\n",
    "#         right_index=True,\n",
    "#     )\n",
    "\n",
    "#     # X TRAIN\n",
    "#     certain_features = certain_features.loc[:, certain_features.columns != \"target\"]\n",
    "#     X_train_iter0 = pd.concat((X_train_iter0, certain_features))\n",
    "\n",
    "#     # Remove certain columns from rejected data\n",
    "#     rows = certain_features.index\n",
    "#     r_dev_iter0 = r_dev_iter0.drop(rows, axis=\"index\")\n",
    "#     df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 73;\n",
       "                var nbb_unformatted_code = \"# plt.plot(mccs, label=\\\"MCCs\\\")\";\n",
       "                var nbb_formatted_code = \"# plt.plot(mccs, label=\\\"MCCs\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(mccs, label=\"MCCs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Nr 1\n",
      "MCC:  0.36612466297702173\n",
      "Iteration Nr 2\n",
      "MCC:  0.3656432612328906\n",
      "Iteration Nr 3\n",
      "MCC:  0.3637265472579141\n",
      "Iteration Nr 4\n",
      "MCC:  0.3587614353620926\n",
      "Iteration Nr 5\n",
      "MCC:  0.35411902178264953\n",
      "Iteration Nr 6\n",
      "MCC:  0.3548416927183875\n",
      "Iteration Nr 7\n",
      "MCC:  0.35278929707420026\n",
      "Iteration Nr 8\n",
      "MCC:  0.352335379287274\n",
      "Iteration Nr 9\n",
      "MCC:  0.351429887365175\n",
      "Iteration Nr 10\n",
      "MCC:  0.34962819066221645\n",
      "Iteration Nr 1\n",
      "MCC:  0.36612466297702173\n",
      "Iteration Nr 2\n",
      "MCC:  0.3654028954749976\n",
      "Iteration Nr 3\n",
      "MCC:  0.36348795084587815\n",
      "Iteration Nr 4\n",
      "MCC:  0.35899573491613\n",
      "Iteration Nr 5\n",
      "MCC:  0.3548101569612283\n",
      "Iteration Nr 6\n",
      "MCC:  0.35342970264564355\n",
      "Iteration Nr 7\n",
      "MCC:  0.35392753472079824\n",
      "Iteration Nr 8\n",
      "MCC:  0.3534716474160843\n",
      "Iteration Nr 9\n",
      "MCC:  0.3530165503036042\n",
      "Iteration Nr 10\n",
      "MCC:  0.351429887365175\n",
      "Iteration Nr 1\n",
      "MCC:  0.36612466297702173\n",
      "Iteration Nr 2\n",
      "MCC:  0.36444365567228026\n",
      "Iteration Nr 3\n",
      "MCC:  0.36301141487001876\n",
      "Iteration Nr 4\n",
      "MCC:  0.35899573491613\n",
      "Iteration Nr 5\n",
      "MCC:  0.35411902178264953\n",
      "Iteration Nr 6\n",
      "MCC:  0.3541557756942492\n",
      "Iteration Nr 7\n",
      "MCC:  0.3530165503036042\n",
      "Iteration Nr 8\n",
      "MCC:  0.352108713940006\n",
      "Iteration Nr 9\n",
      "MCC:  0.34985273053341953\n",
      "Iteration Nr 10\n",
      "MCC:  0.3485083473221756\n",
      "Iteration Nr 1\n",
      "MCC:  0.36612466297702173\n",
      "Iteration Nr 2\n",
      "MCC:  0.3649228318561205\n",
      "Iteration Nr 3\n",
      "MCC:  0.3625357516623227\n",
      "Iteration Nr 4\n",
      "MCC:  0.3578263350053798\n",
      "Iteration Nr 5\n",
      "MCC:  0.3548101569612283\n",
      "Iteration Nr 6\n",
      "MCC:  0.35411902178264953\n",
      "Iteration Nr 7\n",
      "MCC:  0.3541557756942492\n",
      "Iteration Nr 8\n",
      "MCC:  0.352108713940006\n",
      "Iteration Nr 9\n",
      "MCC:  0.3518822437653468\n",
      "Iteration Nr 10\n",
      "MCC:  0.34962819066221645\n",
      "Iteration Nr 1\n",
      "MCC:  0.36612466297702173\n",
      "Iteration Nr 2\n",
      "MCC:  0.3649228318561205\n",
      "Iteration Nr 3\n",
      "MCC:  0.3596998992219916\n",
      "Iteration Nr 4\n",
      "MCC:  0.3543491978446085\n",
      "Iteration Nr 5\n",
      "MCC:  0.35274218849211614\n",
      "Iteration Nr 6\n",
      "MCC:  0.3541557756942492\n",
      "Iteration Nr 7\n",
      "MCC:  0.35278929707420026\n",
      "Iteration Nr 8\n",
      "MCC:  0.3509783069591518\n",
      "Iteration Nr 9\n",
      "MCC:  0.34962819066221645\n",
      "Iteration Nr 10\n",
      "MCC:  0.34985273053341953\n",
      "Iteration Nr 1\n",
      "MCC:  0.36612466297702173\n",
      "Iteration Nr 2\n",
      "MCC:  0.3651627525044242\n",
      "Iteration Nr 3\n",
      "MCC:  0.362773474396762\n",
      "Iteration Nr 4\n",
      "MCC:  0.3580597962777427\n",
      "Iteration Nr 5\n",
      "MCC:  0.35457957609990676\n",
      "Iteration Nr 6\n",
      "MCC:  0.3548416927183875\n",
      "Iteration Nr 7\n",
      "MCC:  0.3534716474160843\n",
      "Iteration Nr 8\n",
      "MCC:  0.3518822437653468\n",
      "Iteration Nr 9\n",
      "MCC:  0.3516559683708821\n",
      "Iteration Nr 10\n",
      "MCC:  0.34962819066221645\n",
      "Iteration Nr 1\n",
      "MCC:  0.36612466297702173\n",
      "Iteration Nr 2\n",
      "MCC:  0.3651627525044242\n",
      "Iteration Nr 3\n",
      "MCC:  0.362773474396762\n",
      "Iteration Nr 4\n",
      "MCC:  0.3578263350053798\n",
      "Iteration Nr 5\n",
      "MCC:  0.35274218849211614\n",
      "Iteration Nr 6\n",
      "MCC:  0.35369949209486184\n",
      "Iteration Nr 7\n",
      "MCC:  0.352335379287274\n",
      "Iteration Nr 8\n",
      "MCC:  0.35075280678081816\n",
      "Iteration Nr 9\n",
      "MCC:  0.34895571497768524\n",
      "Iteration Nr 10\n",
      "MCC:  0.3485083473221756\n",
      "Iteration Nr 1\n",
      "MCC:  0.36612466297702173\n",
      "Iteration Nr 2\n",
      "MCC:  0.3649228318561205\n",
      "Iteration Nr 3\n",
      "MCC:  0.3606417544235441\n",
      "Iteration Nr 4\n",
      "MCC:  0.3568945705998318\n",
      "Iteration Nr 5\n",
      "MCC:  0.3543842154165782\n",
      "Iteration Nr 6\n",
      "MCC:  0.35278929707420026\n",
      "Iteration Nr 7\n",
      "MCC:  0.3516559683708821\n",
      "Iteration Nr 8\n",
      "MCC:  0.34895571497768524\n",
      "Iteration Nr 9\n",
      "MCC:  0.3469484945902381\n",
      "Iteration Nr 10\n",
      "MCC:  0.3469484945902381\n",
      "Iteration Nr 1\n",
      "MCC:  0.36612466297702173\n",
      "Iteration Nr 2\n",
      "MCC:  0.36444365567228026\n",
      "Iteration Nr 3\n",
      "MCC:  0.3613503883029822\n",
      "Iteration Nr 4\n",
      "MCC:  0.3571272004518924\n",
      "Iteration Nr 5\n",
      "MCC:  0.3548416927183875\n",
      "Iteration Nr 6\n",
      "MCC:  0.35369949209486184\n",
      "Iteration Nr 7\n",
      "MCC:  0.352335379287274\n",
      "Iteration Nr 8\n",
      "MCC:  0.3509783069591518\n",
      "Iteration Nr 9\n",
      "MCC:  0.3485083473221756\n",
      "Iteration Nr 10\n",
      "MCC:  0.34828494719757164\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 74;\n",
       "                var nbb_unformatted_code = \"# Assign non-randomly given number of bads in each interval with a bad status with their given probabilities\\n\\ndf_list = []\\nf1_scores = []\\nmccs = []\\nfor i in range(0, 9):\\n    # Prepare the data\\n    r_dev_iter = r_dev2[r_dev2[\\\"nr_band\\\"] == i]\\n    X_train_iter = X_train_parc[X_train_parc[\\\"nr_band\\\"] == 0]\\n    y_train_iter = pd.merge(\\n        X_train_iter[\\\"known_col_0\\\"],\\n        y_train_parc,\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n    X_train_iter = X_train_iter[significant_columns]\\n    X_test = X_test[significant_columns]\\n    # Drop unnecessary columns\\n    y_train_iter = y_train_iter.drop([\\\"known_col_0\\\"], axis=1)\\n\\n    for iteration in range(1, 11):  # Change to how many iterrations you like\\n        print(\\\"Iteration Nr {}\\\".format(iteration))\\n        # Build logistic regression\\n        KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n            X_train_iter, y_train_iter\\n        )\\n\\n        # Scores\\n        #         f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\\\"weighted\\\")\\n        #         f1_scores.append(f1_stat)\\n\\n        #         logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\\n        #         log_losses.append(logloss)\\n\\n        #         print(\\\"F1: \\\", f1_stat)\\n\\n        mcc = matthews_corrcoef(y_test, KGB1.predict(X_test))\\n        mccs.append(mcc)\\n\\n        print(\\\"MCC: \\\", mcc)\\n\\n        # Make predictions on the rejected data\\n        pred = KGB1.predict_proba(r_dev_iter[significant_columns])[:, 1]\\n        pred = pd.DataFrame(\\n            data=pred,\\n            columns=[\\\"target\\\"],\\n            index=r_dev_iter.index.copy(),\\n        )\\n\\n        # Choose the most certain predictions\\n        lq = pred[\\\"target\\\"].quantile(q=0.05)\\n        uq = pred[\\\"target\\\"].quantile(q=0.95)\\n        pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n        # If PD is high, apply default status\\n        pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n        # Pick only the certain predictions and concatenate them to the dev set\\n        # Y TRAIN\\n        certain = pred[pred[\\\"certain\\\"] == 1]\\n        certain2 = certain[\\\"target\\\"].to_frame()\\n        y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n        # Get significant columns of the rejects based on index\\n        certain_features = pd.merge(\\n            certain[\\\"target\\\"],\\n            r_dev_iter[significant_columns],\\n            how=\\\"inner\\\",\\n            left_index=True,\\n            right_index=True,\\n        )\\n\\n        # X TRAIN\\n        certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n        X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n        # Remove certain columns from rejected data\\n        rows = certain_features.index\\n        r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\\n        df_list.append(df)\";\n",
       "                var nbb_formatted_code = \"# Assign non-randomly given number of bads in each interval with a bad status with their given probabilities\\n\\ndf_list = []\\nf1_scores = []\\nmccs = []\\nfor i in range(0, 9):\\n    # Prepare the data\\n    r_dev_iter = r_dev2[r_dev2[\\\"nr_band\\\"] == i]\\n    X_train_iter = X_train_parc[X_train_parc[\\\"nr_band\\\"] == 0]\\n    y_train_iter = pd.merge(\\n        X_train_iter[\\\"known_col_0\\\"],\\n        y_train_parc,\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n    X_train_iter = X_train_iter[significant_columns]\\n    X_test = X_test[significant_columns]\\n    # Drop unnecessary columns\\n    y_train_iter = y_train_iter.drop([\\\"known_col_0\\\"], axis=1)\\n\\n    for iteration in range(1, 11):  # Change to how many iterrations you like\\n        print(\\\"Iteration Nr {}\\\".format(iteration))\\n        # Build logistic regression\\n        KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n            X_train_iter, y_train_iter\\n        )\\n\\n        # Scores\\n        #         f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\\\"weighted\\\")\\n        #         f1_scores.append(f1_stat)\\n\\n        #         logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\\n        #         log_losses.append(logloss)\\n\\n        #         print(\\\"F1: \\\", f1_stat)\\n\\n        mcc = matthews_corrcoef(y_test, KGB1.predict(X_test))\\n        mccs.append(mcc)\\n\\n        print(\\\"MCC: \\\", mcc)\\n\\n        # Make predictions on the rejected data\\n        pred = KGB1.predict_proba(r_dev_iter[significant_columns])[:, 1]\\n        pred = pd.DataFrame(\\n            data=pred,\\n            columns=[\\\"target\\\"],\\n            index=r_dev_iter.index.copy(),\\n        )\\n\\n        # Choose the most certain predictions\\n        lq = pred[\\\"target\\\"].quantile(q=0.05)\\n        uq = pred[\\\"target\\\"].quantile(q=0.95)\\n        pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n        # If PD is high, apply default status\\n        pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n        # Pick only the certain predictions and concatenate them to the dev set\\n        # Y TRAIN\\n        certain = pred[pred[\\\"certain\\\"] == 1]\\n        certain2 = certain[\\\"target\\\"].to_frame()\\n        y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n        # Get significant columns of the rejects based on index\\n        certain_features = pd.merge(\\n            certain[\\\"target\\\"],\\n            r_dev_iter[significant_columns],\\n            how=\\\"inner\\\",\\n            left_index=True,\\n            right_index=True,\\n        )\\n\\n        # X TRAIN\\n        certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n        X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n        # Remove certain columns from rejected data\\n        rows = certain_features.index\\n        r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\\n        df_list.append(df)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assign non-randomly given number of bads in each interval with a bad status with their given probabilities\n",
    "\n",
    "df_list = []\n",
    "f1_scores = []\n",
    "mccs = []\n",
    "for i in range(0, 9):\n",
    "    # Prepare the data\n",
    "    r_dev_iter = r_dev2[r_dev2[\"nr_band\"] == i]\n",
    "    X_train_iter = X_train_parc[X_train_parc[\"nr_band\"] == 0]\n",
    "    y_train_iter = pd.merge(\n",
    "        X_train_iter[\"known_col_0\"],\n",
    "        y_train_parc,\n",
    "        how=\"inner\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "    X_train_iter = X_train_iter[significant_columns]\n",
    "    X_test = X_test[significant_columns]\n",
    "    # Drop unnecessary columns\n",
    "    y_train_iter = y_train_iter.drop([\"known_col_0\"], axis=1)\n",
    "\n",
    "    for iteration in range(1, 11):  # Change to how many iterrations you like\n",
    "        print(\"Iteration Nr {}\".format(iteration))\n",
    "        # Build logistic regression\n",
    "        KGB1 = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(\n",
    "            X_train_iter, y_train_iter\n",
    "        )\n",
    "\n",
    "        # Scores\n",
    "        #         f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\"weighted\")\n",
    "        #         f1_scores.append(f1_stat)\n",
    "\n",
    "        #         logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\n",
    "        #         log_losses.append(logloss)\n",
    "\n",
    "        #         print(\"F1: \", f1_stat)\n",
    "\n",
    "        mcc = matthews_corrcoef(y_test, KGB1.predict(X_test))\n",
    "        mccs.append(mcc)\n",
    "\n",
    "        print(\"MCC: \", mcc)\n",
    "\n",
    "        # Make predictions on the rejected data\n",
    "        pred = KGB1.predict_proba(r_dev_iter[significant_columns])[:, 1]\n",
    "        pred = pd.DataFrame(\n",
    "            data=pred,\n",
    "            columns=[\"target\"],\n",
    "            index=r_dev_iter.index.copy(),\n",
    "        )\n",
    "\n",
    "        # Choose the most certain predictions\n",
    "        lq = pred[\"target\"].quantile(q=0.05)\n",
    "        uq = pred[\"target\"].quantile(q=0.95)\n",
    "        pred[\"certain\"] = pred[\"target\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\n",
    "\n",
    "        # If PD is high, apply default status\n",
    "        pred[\"target\"] = pred[\"target\"].apply(lambda x: 1 if (x > uq) else 0)\n",
    "\n",
    "        # Pick only the certain predictions and concatenate them to the dev set\n",
    "        # Y TRAIN\n",
    "        certain = pred[pred[\"certain\"] == 1]\n",
    "        certain2 = certain[\"target\"].to_frame()\n",
    "        y_train_iter = pd.concat((y_train_iter, certain2))\n",
    "\n",
    "        # Get significant columns of the rejects based on index\n",
    "        certain_features = pd.merge(\n",
    "            certain[\"target\"],\n",
    "            r_dev_iter[significant_columns],\n",
    "            how=\"inner\",\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "        )\n",
    "\n",
    "        # X TRAIN\n",
    "        certain_features = certain_features.loc[:, certain_features.columns != \"target\"]\n",
    "        X_train_iter = pd.concat((X_train_iter, certain_features))\n",
    "\n",
    "        # Remove certain columns from rejected data\n",
    "        rows = certain_features.index\n",
    "        r_dev_iter = r_dev_iter.drop(rows, axis=\"index\")\n",
    "        df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 75;\n",
       "                var nbb_unformatted_code = \"len(mccs)\";\n",
       "                var nbb_formatted_code = \"len(mccs)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(mccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Nr 1\n",
      "F1:  0.735076304154721\n",
      "Iteration Nr 2\n",
      "F1:  0.7355800353998367\n",
      "Iteration Nr 3\n",
      "F1:  0.7340678990819234\n",
      "Iteration Nr 4\n",
      "F1:  0.7323001495955603\n",
      "Iteration Nr 5\n",
      "F1:  0.7315413511120867\n",
      "Iteration Nr 6\n",
      "F1:  0.7302750883747593\n",
      "Iteration Nr 7\n",
      "F1:  0.7290068167377991\n",
      "Iteration Nr 8\n",
      "F1:  0.727736523929963\n",
      "Iteration Nr 9\n",
      "F1:  0.7262094873675157\n",
      "Iteration Nr 1\n",
      "F1:  0.7267188262075754\n",
      "Iteration Nr 2\n",
      "F1:  0.72595469511049\n",
      "Iteration Nr 3\n",
      "F1:  0.7249347048891238\n",
      "Iteration Nr 4\n",
      "F1:  0.7236578621055889\n",
      "Iteration Nr 5\n",
      "F1:  0.7226348962660005\n",
      "Iteration Nr 6\n",
      "F1:  0.7216105977942039\n",
      "Iteration Nr 7\n",
      "F1:  0.7218667976871102\n",
      "Iteration Nr 8\n",
      "F1:  0.7203283412034283\n",
      "Iteration Nr 9\n",
      "F1:  0.7195579780491842\n",
      "Iteration Nr 1\n",
      "F1:  0.7185296443387016\n",
      "Iteration Nr 2\n",
      "F1:  0.7180149688061364\n",
      "Iteration Nr 3\n",
      "F1:  0.7177575035310734\n",
      "Iteration Nr 4\n",
      "F1:  0.7180149688061364\n",
      "Iteration Nr 5\n",
      "F1:  0.7162109206517927\n",
      "Iteration Nr 6\n",
      "F1:  0.7159528573962898\n",
      "Iteration Nr 7\n",
      "F1:  0.7167267901105854\n",
      "Iteration Nr 8\n",
      "F1:  0.7162109206517927\n",
      "Iteration Nr 9\n",
      "F1:  0.7159528573962898\n",
      "Iteration Nr 1\n",
      "F1:  0.7154364733490354\n",
      "Iteration Nr 2\n",
      "F1:  0.7151781523637233\n",
      "Iteration Nr 3\n",
      "F1:  0.7149197452749426\n",
      "Iteration Nr 4\n",
      "F1:  0.7146612519859562\n",
      "Iteration Nr 5\n",
      "F1:  0.7136264148937878\n",
      "Iteration Nr 6\n",
      "F1:  0.7128493772348038\n",
      "Iteration Nr 7\n",
      "F1:  0.7120715568141855\n",
      "Iteration Nr 8\n",
      "F1:  0.7118121089428654\n",
      "Iteration Nr 9\n",
      "F1:  0.7112929510242069\n",
      "Iteration Nr 1\n",
      "F1:  0.7112929510242069\n",
      "Iteration Nr 2\n",
      "F1:  0.7112929510242069\n",
      "Iteration Nr 3\n",
      "F1:  0.7102535837801279\n",
      "Iteration Nr 4\n",
      "F1:  0.7097333729107718\n",
      "Iteration Nr 5\n",
      "F1:  0.708952395377178\n",
      "Iteration Nr 6\n",
      "F1:  0.708952395377178\n",
      "Iteration Nr 7\n",
      "F1:  0.7081706220538209\n",
      "Iteration Nr 8\n",
      "F1:  0.7079098536539762\n",
      "Iteration Nr 9\n",
      "F1:  0.7071270152289477\n",
      "Iteration Nr 1\n",
      "F1:  0.7073880503379051\n",
      "Iteration Nr 2\n",
      "F1:  0.7073880503379051\n",
      "Iteration Nr 3\n",
      "F1:  0.7071270152289477\n",
      "Iteration Nr 4\n",
      "F1:  0.7071270152289477\n",
      "Iteration Nr 5\n",
      "F1:  0.7071270152289477\n",
      "Iteration Nr 6\n",
      "F1:  0.7068658910242374\n",
      "Iteration Nr 7\n",
      "F1:  0.7071270152289477\n",
      "Iteration Nr 8\n",
      "F1:  0.7071270152289477\n",
      "Iteration Nr 9\n",
      "F1:  0.7068658910242374\n",
      "Iteration Nr 1\n",
      "F1:  0.7068658910242374\n",
      "Iteration Nr 2\n",
      "F1:  0.7068658910242374\n",
      "Iteration Nr 3\n",
      "F1:  0.7063433749421939\n",
      "Iteration Nr 4\n",
      "F1:  0.7058205013211319\n",
      "Iteration Nr 5\n",
      "F1:  0.7052972693905377\n",
      "Iteration Nr 6\n",
      "F1:  0.7060819828722003\n",
      "Iteration Nr 7\n",
      "F1:  0.7063433749421939\n",
      "Iteration Nr 8\n",
      "F1:  0.7060819828722003\n",
      "Iteration Nr 9\n",
      "F1:  0.7060819828722003\n",
      "Iteration Nr 1\n",
      "F1:  0.7060819828722003\n",
      "Iteration Nr 2\n",
      "F1:  0.7060819828722003\n",
      "Iteration Nr 3\n",
      "F1:  0.7058205013211319\n",
      "Iteration Nr 4\n",
      "F1:  0.7058205013211319\n",
      "Iteration Nr 5\n",
      "F1:  0.7052972693905377\n",
      "Iteration Nr 6\n",
      "F1:  0.7047736783800177\n",
      "Iteration Nr 7\n",
      "F1:  0.70424972751929\n",
      "Iteration Nr 8\n",
      "F1:  0.70424972751929\n",
      "Iteration Nr 9\n",
      "F1:  0.7024130545677808\n",
      "Iteration Nr 1\n",
      "F1:  0.7018874748515007\n",
      "Iteration Nr 2\n",
      "F1:  0.7018874748515007\n",
      "Iteration Nr 3\n",
      "F1:  0.7013615310501184\n",
      "Iteration Nr 4\n",
      "F1:  0.7016245485095578\n",
      "Iteration Nr 5\n",
      "F1:  0.7016245485095578\n",
      "Iteration Nr 6\n",
      "F1:  0.7013615310501184\n",
      "Iteration Nr 7\n",
      "F1:  0.7010984223769665\n",
      "Iteration Nr 8\n",
      "F1:  0.700835222393889\n",
      "Iteration Nr 9\n",
      "F1:  0.7003085481131204\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 76;\n",
       "                var nbb_unformatted_code = \"# Assign non-randomly given number of bads in each interval with a bad status with their given probabilities\\n\\ndf_list = []\\nf1_scores = []\\nfor i in range(0, 9):\\n    r_dev_iter = r_dev2[r_dev2[\\\"nr_band\\\"] == i]\\n    for iteration in range(1, 10):  # Change to how many iterrations you like\\n        print(\\\"Iteration Nr {}\\\".format(iteration))\\n        # Build logistic regression\\n        KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n            X_train_iter, y_train_iter\\n        )\\n\\n        # Scores\\n        f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\\\"weighted\\\")\\n        f1_scores.append(f1_stat)\\n\\n        logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\\n        log_losses.append(logloss)\\n\\n        print(\\\"F1: \\\", f1_stat)\\n\\n        # Make predictions on the rejected data\\n        pred = KGB1.predict_proba(r_dev_iter[significant_columns])[:, 1]\\n        pred = pd.DataFrame(\\n            data=pred,\\n            columns=[\\\"target\\\"],\\n            index=r_dev_iter.index.copy(),\\n        )\\n\\n        # Choose the most certain predictions\\n        lq = pred[\\\"target\\\"].quantile(q=0.05)\\n        uq = pred[\\\"target\\\"].quantile(q=0.95)\\n        pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n        # If PD is high, apply default status\\n        pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n        # Pick only the certain predictions and concatenate them to the dev set\\n        # Y TRAIN\\n        certain = pred[pred[\\\"certain\\\"] == 1]\\n        certain2 = certain[\\\"target\\\"].to_frame()\\n        y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n        # Get significant columns of the rejects based on index\\n        certain_features = pd.merge(\\n            certain[\\\"target\\\"],\\n            r_dev_iter[significant_columns],\\n            how=\\\"inner\\\",\\n            left_index=True,\\n            right_index=True,\\n        )\\n\\n        # X TRAIN\\n        certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n        X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n        # Remove certain columns from rejected data\\n        rows = certain_features.index\\n        r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\\n        df_list.append(df)\";\n",
       "                var nbb_formatted_code = \"# Assign non-randomly given number of bads in each interval with a bad status with their given probabilities\\n\\ndf_list = []\\nf1_scores = []\\nfor i in range(0, 9):\\n    r_dev_iter = r_dev2[r_dev2[\\\"nr_band\\\"] == i]\\n    for iteration in range(1, 10):  # Change to how many iterrations you like\\n        print(\\\"Iteration Nr {}\\\".format(iteration))\\n        # Build logistic regression\\n        KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n            X_train_iter, y_train_iter\\n        )\\n\\n        # Scores\\n        f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\\\"weighted\\\")\\n        f1_scores.append(f1_stat)\\n\\n        logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\\n        log_losses.append(logloss)\\n\\n        print(\\\"F1: \\\", f1_stat)\\n\\n        # Make predictions on the rejected data\\n        pred = KGB1.predict_proba(r_dev_iter[significant_columns])[:, 1]\\n        pred = pd.DataFrame(\\n            data=pred,\\n            columns=[\\\"target\\\"],\\n            index=r_dev_iter.index.copy(),\\n        )\\n\\n        # Choose the most certain predictions\\n        lq = pred[\\\"target\\\"].quantile(q=0.05)\\n        uq = pred[\\\"target\\\"].quantile(q=0.95)\\n        pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n        # If PD is high, apply default status\\n        pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n        # Pick only the certain predictions and concatenate them to the dev set\\n        # Y TRAIN\\n        certain = pred[pred[\\\"certain\\\"] == 1]\\n        certain2 = certain[\\\"target\\\"].to_frame()\\n        y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n        # Get significant columns of the rejects based on index\\n        certain_features = pd.merge(\\n            certain[\\\"target\\\"],\\n            r_dev_iter[significant_columns],\\n            how=\\\"inner\\\",\\n            left_index=True,\\n            right_index=True,\\n        )\\n\\n        # X TRAIN\\n        certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n        X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n        # Remove certain columns from rejected data\\n        rows = certain_features.index\\n        r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\\n        df_list.append(df)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assign non-randomly given number of bads in each interval with a bad status with their given probabilities\n",
    "\n",
    "df_list = []\n",
    "f1_scores = []\n",
    "for i in range(0, 9):\n",
    "    r_dev_iter = r_dev2[r_dev2[\"nr_band\"] == i]\n",
    "    for iteration in range(1, 10):  # Change to how many iterrations you like\n",
    "        print(\"Iteration Nr {}\".format(iteration))\n",
    "        # Build logistic regression\n",
    "        KGB1 = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(\n",
    "            X_train_iter, y_train_iter\n",
    "        )\n",
    "\n",
    "        # Scores\n",
    "        f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\"weighted\")\n",
    "        f1_scores.append(f1_stat)\n",
    "\n",
    "        logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\n",
    "        log_losses.append(logloss)\n",
    "\n",
    "        print(\"F1: \", f1_stat)\n",
    "\n",
    "        # Make predictions on the rejected data\n",
    "        pred = KGB1.predict_proba(r_dev_iter[significant_columns])[:, 1]\n",
    "        pred = pd.DataFrame(\n",
    "            data=pred,\n",
    "            columns=[\"target\"],\n",
    "            index=r_dev_iter.index.copy(),\n",
    "        )\n",
    "\n",
    "        # Choose the most certain predictions\n",
    "        lq = pred[\"target\"].quantile(q=0.05)\n",
    "        uq = pred[\"target\"].quantile(q=0.95)\n",
    "        pred[\"certain\"] = pred[\"target\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\n",
    "\n",
    "        # If PD is high, apply default status\n",
    "        pred[\"target\"] = pred[\"target\"].apply(lambda x: 1 if (x > uq) else 0)\n",
    "\n",
    "        # Pick only the certain predictions and concatenate them to the dev set\n",
    "        # Y TRAIN\n",
    "        certain = pred[pred[\"certain\"] == 1]\n",
    "        certain2 = certain[\"target\"].to_frame()\n",
    "        y_train_iter = pd.concat((y_train_iter, certain2))\n",
    "\n",
    "        # Get significant columns of the rejects based on index\n",
    "        certain_features = pd.merge(\n",
    "            certain[\"target\"],\n",
    "            r_dev_iter[significant_columns],\n",
    "            how=\"inner\",\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "        )\n",
    "\n",
    "        # X TRAIN\n",
    "        certain_features = certain_features.loc[:, certain_features.columns != \"target\"]\n",
    "        X_train_iter = pd.concat((X_train_iter, certain_features))\n",
    "\n",
    "        # Remove certain columns from rejected data\n",
    "        rows = certain_features.index\n",
    "        r_dev_iter = r_dev_iter.drop(rows, axis=\"index\")\n",
    "        df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 96;\n",
       "                var nbb_unformatted_code = \"# Save the iteration of the model where max MCC score is reached\\nmax_value0 = max(mccs[0:9])\\nmax_index0 = mccs.index(max_value0)\\nmax_value1 = max(mccs[10:19])\\nmax_index1 = 10 + mccs.index(max_value1)\\nmax_value2 = max(mccs[20:29])\\nmax_index2 = 20 + mccs.index(max_value2)\\nmax_value3 = max(mccs[30:39])\\nmax_index3 = 30 + mccs.index(max_value3)\\nmax_value4 = max(mccs[40:49])\\nmax_index4 = 40 + mccs.index(max_value4)\\nmax_value5 = max(mccs[50:59])\\nmax_index5 = 50 + mccs.index(max_value5)\\nmax_value6 = max(mccs[60:69])\\nmax_index6 = 60 + mccs.index(max_value6)\\nmax_value7 = max(mccs[70:79])\\nmax_index7 = 70 + mccs.index(max_value7)\\nmax_value8 = max(mccs[80:89])\\nmax_index8 = 80 + mccs.index(max_value8)\\nprint(max_index7)\";\n",
       "                var nbb_formatted_code = \"# Save the iteration of the model where max MCC score is reached\\nmax_value0 = max(mccs[0:9])\\nmax_index0 = mccs.index(max_value0)\\nmax_value1 = max(mccs[10:19])\\nmax_index1 = 10 + mccs.index(max_value1)\\nmax_value2 = max(mccs[20:29])\\nmax_index2 = 20 + mccs.index(max_value2)\\nmax_value3 = max(mccs[30:39])\\nmax_index3 = 30 + mccs.index(max_value3)\\nmax_value4 = max(mccs[40:49])\\nmax_index4 = 40 + mccs.index(max_value4)\\nmax_value5 = max(mccs[50:59])\\nmax_index5 = 50 + mccs.index(max_value5)\\nmax_value6 = max(mccs[60:69])\\nmax_index6 = 60 + mccs.index(max_value6)\\nmax_value7 = max(mccs[70:79])\\nmax_index7 = 70 + mccs.index(max_value7)\\nmax_value8 = max(mccs[80:89])\\nmax_index8 = 80 + mccs.index(max_value8)\\nprint(max_index7)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the iteration of the model where max MCC score is reached\n",
    "max_value0 = max(mccs[0:9])\n",
    "max_index0 = mccs.index(max_value0)\n",
    "max_value1 = max(mccs[10:19])\n",
    "max_index1 = 10 + mccs.index(max_value1)\n",
    "max_value2 = max(mccs[20:29])\n",
    "max_index2 = 20 + mccs.index(max_value2)\n",
    "max_value3 = max(mccs[30:39])\n",
    "max_index3 = 30 + mccs.index(max_value3)\n",
    "max_value4 = max(mccs[40:49])\n",
    "max_index4 = 40 + mccs.index(max_value4)\n",
    "max_value5 = max(mccs[50:59])\n",
    "max_index5 = 50 + mccs.index(max_value5)\n",
    "max_value6 = max(mccs[60:69])\n",
    "max_index6 = 60 + mccs.index(max_value6)\n",
    "max_value7 = max(mccs[70:79])\n",
    "max_index7 = 70 + mccs.index(max_value7)\n",
    "max_value8 = max(mccs[80:89])\n",
    "max_index8 = 80 + mccs.index(max_value8)\n",
    "print(max_index7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### max_value1 = max(mccs[10:19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 87;\n",
       "                var nbb_unformatted_code = \"max_index1 = mccs.index(max_value1)\";\n",
       "                var nbb_formatted_code = \"max_index1 = mccs.index(max_value1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_index1 = mccs.index(max_value1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 88;\n",
       "                var nbb_unformatted_code = \"max_index1\";\n",
       "                var nbb_formatted_code = \"max_index1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_index1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = max(mccs[0:9])\n",
    "max_index = mccs.index(max_value)\n",
    "print(max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Nr 1\n",
      "F1:  0.6992540995994176\n",
      "Iteration Nr 2\n",
      "F1:  0.6992540995994176\n",
      "Iteration Nr 3\n",
      "F1:  0.6992540995994176\n",
      "Iteration Nr 4\n",
      "F1:  0.698990257753126\n",
      "Iteration Nr 5\n",
      "F1:  0.6992540995994176\n",
      "Iteration Nr 6\n",
      "F1:  0.698990257753126\n",
      "Iteration Nr 7\n",
      "F1:  0.6987263238272955\n",
      "Iteration Nr 8\n",
      "F1:  0.6981981793522428\n",
      "Iteration Nr 9\n",
      "F1:  0.6987263238272955\n",
      "Iteration Nr 1\n",
      "F1:  0.6984622977257321\n",
      "Iteration Nr 2\n",
      "F1:  0.6984622977257321\n",
      "Iteration Nr 3\n",
      "F1:  0.6984622977257321\n",
      "Iteration Nr 4\n",
      "F1:  0.6984622977257321\n",
      "Iteration Nr 5\n",
      "F1:  0.6984622977257321\n",
      "Iteration Nr 6\n",
      "F1:  0.6984622977257321\n",
      "Iteration Nr 7\n",
      "F1:  0.6981981793522428\n",
      "Iteration Nr 8\n",
      "F1:  0.6976696654047175\n",
      "Iteration Nr 9\n",
      "F1:  0.6979339686106353\n",
      "Iteration Nr 1\n",
      "F1:  0.6974052696382977\n",
      "Iteration Nr 2\n",
      "F1:  0.6974052696382977\n",
      "Iteration Nr 3\n",
      "F1:  0.6971407812151844\n",
      "Iteration Nr 4\n",
      "F1:  0.6974052696382977\n",
      "Iteration Nr 5\n",
      "F1:  0.6966115260141073\n",
      "Iteration Nr 6\n",
      "F1:  0.6963467590437579\n",
      "Iteration Nr 7\n",
      "F1:  0.6960818990319426\n",
      "Iteration Nr 8\n",
      "F1:  0.6955518994991305\n",
      "Iteration Nr 9\n",
      "F1:  0.6952867597857384\n",
      "Iteration Nr 1\n",
      "F1:  0.6947561999839793\n",
      "Iteration Nr 2\n",
      "F1:  0.6947561999839793\n",
      "Iteration Nr 3\n",
      "F1:  0.6947561999839793\n",
      "Iteration Nr 4\n",
      "F1:  0.6947561999839793\n",
      "Iteration Nr 5\n",
      "F1:  0.6947561999839793\n",
      "Iteration Nr 6\n",
      "F1:  0.6944907797032045\n",
      "Iteration Nr 7\n",
      "F1:  0.6939596579008263\n",
      "Iteration Nr 8\n",
      "F1:  0.6939596579008263\n",
      "Iteration Nr 9\n",
      "F1:  0.6939596579008263\n",
      "Iteration Nr 1\n",
      "F1:  0.6934281604692584\n",
      "Iteration Nr 2\n",
      "F1:  0.6934281604692584\n",
      "Iteration Nr 3\n",
      "F1:  0.6934281604692584\n",
      "Iteration Nr 4\n",
      "F1:  0.6936939561867991\n",
      "Iteration Nr 5\n",
      "F1:  0.6939596579008263\n",
      "Iteration Nr 6\n",
      "F1:  0.6936939561867991\n",
      "Iteration Nr 7\n",
      "F1:  0.6931622706519837\n",
      "Iteration Nr 8\n",
      "F1:  0.6931622706519837\n",
      "Iteration Nr 9\n",
      "F1:  0.6928962866387515\n",
      "Iteration Nr 1\n",
      "F1:  0.6931622706519837\n",
      "Iteration Nr 2\n",
      "F1:  0.6931622706519837\n",
      "Iteration Nr 3\n",
      "F1:  0.6931622706519837\n",
      "Iteration Nr 4\n",
      "F1:  0.6931622706519837\n",
      "Iteration Nr 5\n",
      "F1:  0.6931622706519837\n",
      "Iteration Nr 6\n",
      "F1:  0.6934281604692584\n",
      "Iteration Nr 7\n",
      "F1:  0.6931622706519837\n",
      "Iteration Nr 8\n",
      "F1:  0.6928962866387515\n",
      "Iteration Nr 9\n",
      "F1:  0.6931622706519837\n",
      "Iteration Nr 1\n",
      "F1:  0.6931622706519837\n",
      "Iteration Nr 2\n",
      "F1:  0.6931622706519837\n",
      "Iteration Nr 3\n",
      "F1:  0.6928962866387515\n",
      "Iteration Nr 4\n",
      "F1:  0.6928962866387515\n",
      "Iteration Nr 5\n",
      "F1:  0.6931622706519837\n",
      "Iteration Nr 6\n",
      "F1:  0.6934281604692584\n",
      "Iteration Nr 7\n",
      "F1:  0.6931622706519837\n",
      "Iteration Nr 8\n",
      "F1:  0.6931622706519837\n",
      "Iteration Nr 9\n",
      "F1:  0.6931622706519837\n",
      "Iteration Nr 1\n",
      "F1:  0.6931622706519837\n",
      "Iteration Nr 2\n",
      "F1:  0.6931622706519837\n",
      "Iteration Nr 3\n",
      "F1:  0.6931622706519837\n",
      "Iteration Nr 4\n",
      "F1:  0.6931622706519837\n",
      "Iteration Nr 5\n",
      "F1:  0.6928962866387515\n",
      "Iteration Nr 6\n",
      "F1:  0.6931622706519837\n",
      "Iteration Nr 7\n",
      "F1:  0.6926302083333333\n",
      "Iteration Nr 8\n",
      "F1:  0.6926302083333333\n",
      "Iteration Nr 9\n",
      "F1:  0.6926302083333333\n",
      "Iteration Nr 1\n",
      "F1:  0.6926302083333333\n",
      "Iteration Nr 2\n",
      "F1:  0.6926302083333333\n",
      "Iteration Nr 3\n",
      "F1:  0.6923640356394972\n",
      "Iteration Nr 4\n",
      "F1:  0.6923640356394972\n",
      "Iteration Nr 5\n",
      "F1:  0.6920977684610063\n",
      "Iteration Nr 6\n",
      "F1:  0.6920977684610063\n",
      "Iteration Nr 7\n",
      "F1:  0.6920977684610063\n",
      "Iteration Nr 8\n",
      "F1:  0.6918314067016196\n",
      "Iteration Nr 9\n",
      "F1:  0.6918314067016196\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 77;\n",
       "                var nbb_unformatted_code = \"# Assign non-randomly given number of bads in each interval with a bad status with their given probabilities\\n\\ndf_list = []\\nf1_scores = []\\nfor i in range(0, 9):\\n    r_dev_iter = r_dev2[r_dev2[\\\"nr_band\\\"] == i]\\n    for iteration in range(1, 10):  # Change to how many iterrations you like\\n        print(\\\"Iteration Nr {}\\\".format(iteration))\\n        # Build logistic regression\\n        KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n            X_train_iter, y_train_iter\\n        )\\n\\n        # Scores\\n        f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\\\"weighted\\\")\\n        f1_scores.append(f1_stat)\\n\\n        logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\\n        log_losses.append(logloss)\\n\\n        print(\\\"F1: \\\", f1_stat)\\n\\n        # Make predictions on the rejected data\\n        pred = KGB1.predict_proba(r_dev_iter[significant_columns])[:, 1]\\n        pred = pd.DataFrame(\\n            data=pred,\\n            columns=[\\\"target\\\"],\\n            index=r_dev_iter.index.copy(),\\n        )\\n\\n        # Choose the most certain predictions\\n        lq = pred[\\\"target\\\"].quantile(q=0.05)\\n        uq = pred[\\\"target\\\"].quantile(q=0.95)\\n        pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n        # If PD is high, apply default status\\n        pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n        # Pick only the certain predictions and concatenate them to the dev set\\n        # Y TRAIN\\n        certain = pred[pred[\\\"certain\\\"] == 1]\\n        certain2 = certain[\\\"target\\\"].to_frame()\\n        y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n        # Get significant columns of the rejects based on index\\n        certain_features = pd.merge(\\n            certain[\\\"target\\\"],\\n            r_dev_iter[significant_columns],\\n            how=\\\"inner\\\",\\n            left_index=True,\\n            right_index=True,\\n        )\\n\\n        # X TRAIN\\n        certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n        X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n        # Remove certain columns from rejected data\\n        rows = certain_features.index\\n        r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\\n        df_list.append(df)\";\n",
       "                var nbb_formatted_code = \"# Assign non-randomly given number of bads in each interval with a bad status with their given probabilities\\n\\ndf_list = []\\nf1_scores = []\\nfor i in range(0, 9):\\n    r_dev_iter = r_dev2[r_dev2[\\\"nr_band\\\"] == i]\\n    for iteration in range(1, 10):  # Change to how many iterrations you like\\n        print(\\\"Iteration Nr {}\\\".format(iteration))\\n        # Build logistic regression\\n        KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n            X_train_iter, y_train_iter\\n        )\\n\\n        # Scores\\n        f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\\\"weighted\\\")\\n        f1_scores.append(f1_stat)\\n\\n        logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\\n        log_losses.append(logloss)\\n\\n        print(\\\"F1: \\\", f1_stat)\\n\\n        # Make predictions on the rejected data\\n        pred = KGB1.predict_proba(r_dev_iter[significant_columns])[:, 1]\\n        pred = pd.DataFrame(\\n            data=pred,\\n            columns=[\\\"target\\\"],\\n            index=r_dev_iter.index.copy(),\\n        )\\n\\n        # Choose the most certain predictions\\n        lq = pred[\\\"target\\\"].quantile(q=0.05)\\n        uq = pred[\\\"target\\\"].quantile(q=0.95)\\n        pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n        # If PD is high, apply default status\\n        pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n        # Pick only the certain predictions and concatenate them to the dev set\\n        # Y TRAIN\\n        certain = pred[pred[\\\"certain\\\"] == 1]\\n        certain2 = certain[\\\"target\\\"].to_frame()\\n        y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n        # Get significant columns of the rejects based on index\\n        certain_features = pd.merge(\\n            certain[\\\"target\\\"],\\n            r_dev_iter[significant_columns],\\n            how=\\\"inner\\\",\\n            left_index=True,\\n            right_index=True,\\n        )\\n\\n        # X TRAIN\\n        certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n        X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n        # Remove certain columns from rejected data\\n        rows = certain_features.index\\n        r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\\n        df_list.append(df)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assign non-randomly given number of bads in each interval with a bad status with their given probabilities\n",
    "\n",
    "df_list = []\n",
    "f1_scores = []\n",
    "for i in range(0, 9):\n",
    "    r_dev_iter = r_dev2[r_dev2[\"nr_band\"] == i]\n",
    "    for iteration in range(1, 10):  # Change to how many iterrations you like\n",
    "        print(\"Iteration Nr {}\".format(iteration))\n",
    "        # Build logistic regression\n",
    "        KGB1 = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(\n",
    "            X_train_iter, y_train_iter\n",
    "        )\n",
    "\n",
    "        # Scores\n",
    "        f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\"weighted\")\n",
    "        f1_scores.append(f1_stat)\n",
    "\n",
    "        logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\n",
    "        log_losses.append(logloss)\n",
    "\n",
    "        print(\"F1: \", f1_stat)\n",
    "\n",
    "        # Make predictions on the rejected data\n",
    "        pred = KGB1.predict_proba(r_dev_iter[significant_columns])[:, 1]\n",
    "        pred = pd.DataFrame(\n",
    "            data=pred,\n",
    "            columns=[\"target\"],\n",
    "            index=r_dev_iter.index.copy(),\n",
    "        )\n",
    "\n",
    "        # Choose the most certain predictions\n",
    "        lq = pred[\"target\"].quantile(q=0.05)\n",
    "        uq = pred[\"target\"].quantile(q=0.95)\n",
    "        pred[\"certain\"] = pred[\"target\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\n",
    "\n",
    "        # If PD is high, apply default status\n",
    "        pred[\"target\"] = pred[\"target\"].apply(lambda x: 1 if (x > uq) else 0)\n",
    "\n",
    "        # Pick only the certain predictions and concatenate them to the dev set\n",
    "        # Y TRAIN\n",
    "        certain = pred[pred[\"certain\"] == 1]\n",
    "        certain2 = certain[\"target\"].to_frame()\n",
    "        y_train_iter = pd.concat((y_train_iter, certain2))\n",
    "\n",
    "        # Get significant columns of the rejects based on index\n",
    "        certain_features = pd.merge(\n",
    "            certain[\"target\"],\n",
    "            r_dev_iter[significant_columns],\n",
    "            how=\"inner\",\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "        )\n",
    "\n",
    "        # X TRAIN\n",
    "        certain_features = certain_features.loc[:, certain_features.columns != \"target\"]\n",
    "        X_train_iter = pd.concat((X_train_iter, certain_features))\n",
    "\n",
    "        # Remove certain columns from rejected data\n",
    "        rows = certain_features.index\n",
    "        r_dev_iter = r_dev_iter.drop(rows, axis=\"index\")\n",
    "        df_list.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 78;\n",
       "                var nbb_unformatted_code = \"my_list_accepts = [\\n    predictions_accepts_beforeRI,\\n    predictions_accepts_base,\\n    predictions_accepts_iter,\\n    predictions_accepts_new,\\n    predictions_accepts_rand_parc,\\n]\\ndf_pred_accepts = pd.DataFrame(my_list_accepts).transpose()\\ndf_pred_accepts = df_pred_accepts.rename(\\n    columns={\\n        0: \\\"Before RI\\\",\\n        1: \\\"Baseline\\\",\\n        2: \\\"Iteration n\\\",\\n        3: \\\"Self-Training\\\",\\n        4: \\\"Rand Parcelling\\\",\\n    },\\n)\";\n",
       "                var nbb_formatted_code = \"my_list_accepts = [\\n    predictions_accepts_beforeRI,\\n    predictions_accepts_base,\\n    predictions_accepts_iter,\\n    predictions_accepts_new,\\n    predictions_accepts_rand_parc,\\n]\\ndf_pred_accepts = pd.DataFrame(my_list_accepts).transpose()\\ndf_pred_accepts = df_pred_accepts.rename(\\n    columns={\\n        0: \\\"Before RI\\\",\\n        1: \\\"Baseline\\\",\\n        2: \\\"Iteration n\\\",\\n        3: \\\"Self-Training\\\",\\n        4: \\\"Rand Parcelling\\\",\\n    },\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_list_accepts = [\n",
    "    predictions_accepts_beforeRI,\n",
    "    predictions_accepts_base,\n",
    "    predictions_accepts_iter,\n",
    "    predictions_accepts_new,\n",
    "    predictions_accepts_rand_parc,\n",
    "]\n",
    "df_pred_accepts = pd.DataFrame(my_list_accepts).transpose()\n",
    "df_pred_accepts = df_pred_accepts.rename(\n",
    "    columns={\n",
    "        0: \"Before RI\",\n",
    "        1: \"Baseline\",\n",
    "        2: \"Iteration n\",\n",
    "        3: \"Self-Training\",\n",
    "        4: \"Rand Parcelling\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 79;\n",
       "                var nbb_unformatted_code = \"my_list_rejects = [\\n    predictions_rejects_beforeRI,\\n    predictions_rejects_base,\\n    predictions_rejects_iter,\\n    predictions_rejects_new,\\n    predictions_rejects_rand_parc,\\n]\\ndf_pred_rejects = pd.DataFrame(my_list_rejects).transpose()\\ndf_pred_rejects = df_pred_rejects.rename(\\n    columns={\\n        0: \\\"Before RI\\\",\\n        1: \\\"Baseline\\\",\\n        2: \\\"Iteration n\\\",\\n        3: \\\"Self-Training\\\",\\n        4: \\\"Rand Parcelling\\\",\\n    },\\n)\";\n",
       "                var nbb_formatted_code = \"my_list_rejects = [\\n    predictions_rejects_beforeRI,\\n    predictions_rejects_base,\\n    predictions_rejects_iter,\\n    predictions_rejects_new,\\n    predictions_rejects_rand_parc,\\n]\\ndf_pred_rejects = pd.DataFrame(my_list_rejects).transpose()\\ndf_pred_rejects = df_pred_rejects.rename(\\n    columns={\\n        0: \\\"Before RI\\\",\\n        1: \\\"Baseline\\\",\\n        2: \\\"Iteration n\\\",\\n        3: \\\"Self-Training\\\",\\n        4: \\\"Rand Parcelling\\\",\\n    },\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_list_rejects = [\n",
    "    predictions_rejects_beforeRI,\n",
    "    predictions_rejects_base,\n",
    "    predictions_rejects_iter,\n",
    "    predictions_rejects_new,\n",
    "    predictions_rejects_rand_parc,\n",
    "]\n",
    "df_pred_rejects = pd.DataFrame(my_list_rejects).transpose()\n",
    "df_pred_rejects = df_pred_rejects.rename(\n",
    "    columns={\n",
    "        0: \"Before RI\",\n",
    "        1: \"Baseline\",\n",
    "        2: \"Iteration n\",\n",
    "        3: \"Self-Training\",\n",
    "        4: \"Rand Parcelling\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Before RI</th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Iteration n</th>\n",
       "      <th>Self-Training</th>\n",
       "      <th>Rand Parcelling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Before RI  Baseline  Iteration n  Self-Training  Rand Parcelling\n",
       "0      0.849     0.936        0.889           0.92            0.932"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 80;\n",
       "                var nbb_unformatted_code = \"df_pred_accepts\";\n",
       "                var nbb_formatted_code = \"df_pred_accepts\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_pred_accepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Before RI</th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Iteration n</th>\n",
       "      <th>Self-Training</th>\n",
       "      <th>Rand Parcelling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.755</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Before RI  Baseline  Iteration n  Self-Training  Rand Parcelling\n",
       "0      0.755      0.86        0.805           0.85             0.86"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 81;\n",
       "                var nbb_unformatted_code = \"df_pred_rejects\";\n",
       "                var nbb_formatted_code = \"df_pred_rejects\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_pred_rejects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
