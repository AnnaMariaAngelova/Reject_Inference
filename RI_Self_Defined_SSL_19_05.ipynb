{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import sys\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Basic Packages\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Modelling\\n# Classification\\nimport statsmodels.api as sm\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom lightgbm import LGBMClassifier\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.ensemble import IsolationForest\\n\\n# Balancing\\nfrom imblearn.over_sampling import SMOTE\\nfrom imblearn.under_sampling import RandomUnderSampler\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Metrics\\nfrom sklearn.metrics import f1_score\\n\\n# Visualization\\nimport matplotlib.pyplot as plt\";\n",
       "                var nbb_formatted_code = \"import sys\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Basic Packages\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Modelling\\n# Classification\\nimport statsmodels.api as sm\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom lightgbm import LGBMClassifier\\nfrom sklearn.naive_bayes import GaussianNB\\nfrom sklearn.ensemble import IsolationForest\\n\\n# Balancing\\nfrom imblearn.over_sampling import SMOTE\\nfrom imblearn.under_sampling import RandomUnderSampler\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Metrics\\nfrom sklearn.metrics import f1_score\\n\\n# Visualization\\nimport matplotlib.pyplot as plt\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Basic Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modelling\n",
    "# Classification\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Balancing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, basic data preprocessing to obtain accepted and rejected training and test samples separately. Save rejected data in two versions: with and without lables. The rejected data without labels is needed for the semi-supervised model. The rejected data without labels is needed to perform evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"def data_preprocessing(df, accepted_flag, target, train_ratio):\\n    \\\"\\\"\\\"\\n    The goal of this function is to load the original dataset, split it into accepts and rejects,\\n    add ids, which can later be used for merging. For the rejects to further perform train / test split\\n\\n    Parameters\\n    ----------\\n\\n    df : name of the original dataset in quotation marks, csv format\\n    accepted_flag: name of the accepted flag; Binary: 1 if accepted, 0 if rejected\\n    target : name of the target column\\n    train_ratio : percentage used for training; Continuous (0,1)\\n\\n    Return\\n    ------\\n    a : accepted data\\n    r : rejected data\\n    r_dev : rejected trainining data without label\\n    r_test : rejected testing data without label\\n    dfr_dev_with_label: rejected training data with label\\n    dft_test_with_label: rejected training data with label\\n\\n    \\\"\\\"\\\"\\n    # Load data\\n    data = pd.read_csv(\\\"C:/Users/Asus/Desktop/Repo/MasterThesis_RI/Data_19_05/\\\" + df)\\n\\n    # Accepted\\n\\n    ## Create separate dataset with accepts\\n    dfa = data[data[accepted_flag] == 1]\\n    dfa = dfa.drop([accepted_flag], axis=1)\\n    ## Rename target variable as \\\"target\\\"\\n    dfa = dfa.rename(columns={target: \\\"target\\\"})\\n    ## Add id to the dataset, which can later be used for merging\\n    # dfa[\\\"id\\\"] = dfa.index.to_series().map(lambda x: uuid.uuid4())\\n\\n    # Rejected\\n\\n    ## Create separate dataset with accepts\\n    dfr = data[data[accepted_flag] == 0]\\n    dfr = dfr.drop([accepted_flag], axis=1)\\n    ## Add id to the dataset, which can later be used for merging\\n    #     dfr[\\\"id\\\"] = dfr.index.to_series().map(lambda x: uuid.uuid4())\\n    ## Train/Test Split (without labels)\\n    ### Shuffle the dataset\\n    shuffle_df = dfr.sample(frac=1, random_state=42)\\n    ### Define a size for the train set\\n    train_size = int(train_ratio * len(shuffle_df))\\n    ### Split the dataset\\n    dfr_dev = shuffle_df[:train_size]\\n    dfr_test = shuffle_df[train_size:]\\n    ## Save a copy of the rejected data with label\\n    dfr_dev_with_label = dfr_dev\\n    dfr_test_with_label = dfr_test\\n    ## Unlabel the rejects (i.e. drop the target) and save a copy of the rejeted data without label\\n    dfr_dev2 = dfr_dev_with_label.drop([target], axis=1)\\n    dfr_test2 = dfr_test_with_label.drop([target], axis=1)\\n    # Rename target variable\\n    dfr_dev_with_label = dfr_dev_with_label.rename(columns={target: \\\"target\\\"})\\n    dfr_test_with_label = dfr_test_with_label.rename(columns={target: \\\"target\\\"})\\n\\n    return dfr_dev_with_label, dfr_test_with_label, dfa, dfr, dfr_dev2, dfr_test2\";\n",
       "                var nbb_formatted_code = \"def data_preprocessing(df, accepted_flag, target, train_ratio):\\n    \\\"\\\"\\\"\\n    The goal of this function is to load the original dataset, split it into accepts and rejects,\\n    add ids, which can later be used for merging. For the rejects to further perform train / test split\\n\\n    Parameters\\n    ----------\\n\\n    df : name of the original dataset in quotation marks, csv format\\n    accepted_flag: name of the accepted flag; Binary: 1 if accepted, 0 if rejected\\n    target : name of the target column\\n    train_ratio : percentage used for training; Continuous (0,1)\\n\\n    Return\\n    ------\\n    a : accepted data\\n    r : rejected data\\n    r_dev : rejected trainining data without label\\n    r_test : rejected testing data without label\\n    dfr_dev_with_label: rejected training data with label\\n    dft_test_with_label: rejected training data with label\\n\\n    \\\"\\\"\\\"\\n    # Load data\\n    data = pd.read_csv(\\\"C:/Users/Asus/Desktop/Repo/MasterThesis_RI/Data_19_05/\\\" + df)\\n\\n    # Accepted\\n\\n    ## Create separate dataset with accepts\\n    dfa = data[data[accepted_flag] == 1]\\n    dfa = dfa.drop([accepted_flag], axis=1)\\n    ## Rename target variable as \\\"target\\\"\\n    dfa = dfa.rename(columns={target: \\\"target\\\"})\\n    ## Add id to the dataset, which can later be used for merging\\n    # dfa[\\\"id\\\"] = dfa.index.to_series().map(lambda x: uuid.uuid4())\\n\\n    # Rejected\\n\\n    ## Create separate dataset with accepts\\n    dfr = data[data[accepted_flag] == 0]\\n    dfr = dfr.drop([accepted_flag], axis=1)\\n    ## Add id to the dataset, which can later be used for merging\\n    #     dfr[\\\"id\\\"] = dfr.index.to_series().map(lambda x: uuid.uuid4())\\n    ## Train/Test Split (without labels)\\n    ### Shuffle the dataset\\n    shuffle_df = dfr.sample(frac=1, random_state=42)\\n    ### Define a size for the train set\\n    train_size = int(train_ratio * len(shuffle_df))\\n    ### Split the dataset\\n    dfr_dev = shuffle_df[:train_size]\\n    dfr_test = shuffle_df[train_size:]\\n    ## Save a copy of the rejected data with label\\n    dfr_dev_with_label = dfr_dev\\n    dfr_test_with_label = dfr_test\\n    ## Unlabel the rejects (i.e. drop the target) and save a copy of the rejeted data without label\\n    dfr_dev2 = dfr_dev_with_label.drop([target], axis=1)\\n    dfr_test2 = dfr_test_with_label.drop([target], axis=1)\\n    # Rename target variable\\n    dfr_dev_with_label = dfr_dev_with_label.rename(columns={target: \\\"target\\\"})\\n    dfr_test_with_label = dfr_test_with_label.rename(columns={target: \\\"target\\\"})\\n\\n    return dfr_dev_with_label, dfr_test_with_label, dfa, dfr, dfr_dev2, dfr_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def data_preprocessing(df, accepted_flag, target, train_ratio):\n",
    "    \"\"\"\n",
    "    The goal of this function is to load the original dataset, split it into accepts and rejects,\n",
    "    add ids, which can later be used for merging. For the rejects to further perform train / test split\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    df : name of the original dataset in quotation marks, csv format\n",
    "    accepted_flag: name of the accepted flag; Binary: 1 if accepted, 0 if rejected\n",
    "    target : name of the target column\n",
    "    train_ratio : percentage used for training; Continuous (0,1)\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    a : accepted data\n",
    "    r : rejected data\n",
    "    r_dev : rejected trainining data without label\n",
    "    r_test : rejected testing data without label\n",
    "    dfr_dev_with_label: rejected training data with label\n",
    "    dft_test_with_label: rejected training data with label\n",
    "\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    data = pd.read_csv(\"C:/Users/Asus/Desktop/Repo/MasterThesis_RI/Data_19_05/\" + df)\n",
    "\n",
    "    # Accepted\n",
    "\n",
    "    ## Create separate dataset with accepts\n",
    "    dfa = data[data[accepted_flag] == 1]\n",
    "    dfa = dfa.drop([accepted_flag], axis=1)\n",
    "    ## Rename target variable as \"target\"\n",
    "    dfa = dfa.rename(columns={target: \"target\"})\n",
    "    ## Add id to the dataset, which can later be used for merging\n",
    "    # dfa[\"id\"] = dfa.index.to_series().map(lambda x: uuid.uuid4())\n",
    "\n",
    "    # Rejected\n",
    "\n",
    "    ## Create separate dataset with accepts\n",
    "    dfr = data[data[accepted_flag] == 0]\n",
    "    dfr = dfr.drop([accepted_flag], axis=1)\n",
    "    ## Add id to the dataset, which can later be used for merging\n",
    "    #     dfr[\"id\"] = dfr.index.to_series().map(lambda x: uuid.uuid4())\n",
    "    ## Train/Test Split (without labels)\n",
    "    ### Shuffle the dataset\n",
    "    shuffle_df = dfr.sample(frac=1, random_state=42)\n",
    "    ### Define a size for the train set\n",
    "    train_size = int(train_ratio * len(shuffle_df))\n",
    "    ### Split the dataset\n",
    "    dfr_dev = shuffle_df[:train_size]\n",
    "    dfr_test = shuffle_df[train_size:]\n",
    "    ## Save a copy of the rejected data with label\n",
    "    dfr_dev_with_label = dfr_dev\n",
    "    dfr_test_with_label = dfr_test\n",
    "    ## Unlabel the rejects (i.e. drop the target) and save a copy of the rejeted data without label\n",
    "    dfr_dev2 = dfr_dev_with_label.drop([target], axis=1)\n",
    "    dfr_test2 = dfr_test_with_label.drop([target], axis=1)\n",
    "    # Rename target variable\n",
    "    dfr_dev_with_label = dfr_dev_with_label.rename(columns={target: \"target\"})\n",
    "    dfr_test_with_label = dfr_test_with_label.rename(columns={target: \"target\"})\n",
    "\n",
    "    return dfr_dev_with_label, dfr_test_with_label, dfa, dfr, dfr_dev2, dfr_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"dfr_dev_with_label, dfr_test_with_label, a, r, r_dev, r_test = data_preprocessing(\\n    \\\"cons_scen4_1.csv\\\", \\\"is_accepted\\\", \\\"y\\\", 0.8\\n)\";\n",
       "                var nbb_formatted_code = \"dfr_dev_with_label, dfr_test_with_label, a, r, r_dev, r_test = data_preprocessing(\\n    \\\"cons_scen4_1.csv\\\", \\\"is_accepted\\\", \\\"y\\\", 0.8\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfr_dev_with_label, dfr_test_with_label, a, r, r_dev, r_test = data_preprocessing(\n",
    "    \"cons_scen4_1.csv\", \"is_accepted\", \"y\", 0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below two functions continue the data preprocessing. Used to create feature and target data and to split into train and test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"def create_X_y(data):\\n    \\\"\\\"\\\"\\n    Undersample the data\\n\\n    Parameters\\n    ----------\\n    data : Dataframe\\n\\n    Return\\n    ------\\n    X_res : undersampled data; Dataframe\\n    y_res : undersampled labels; Dataframe\\n\\n    \\\"\\\"\\\"\\n    # Create X and y\\n    X = data.loc[:, data.columns != \\\"target\\\"]\\n    y = data.loc[:, data.columns == \\\"target\\\"]\\n\\n    return X, y\";\n",
       "                var nbb_formatted_code = \"def create_X_y(data):\\n    \\\"\\\"\\\"\\n    Undersample the data\\n\\n    Parameters\\n    ----------\\n    data : Dataframe\\n\\n    Return\\n    ------\\n    X_res : undersampled data; Dataframe\\n    y_res : undersampled labels; Dataframe\\n\\n    \\\"\\\"\\\"\\n    # Create X and y\\n    X = data.loc[:, data.columns != \\\"target\\\"]\\n    y = data.loc[:, data.columns == \\\"target\\\"]\\n\\n    return X, y\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_X_y(data):\n",
    "    \"\"\"\n",
    "    Undersample the data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Dataframe\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    X_res : undersampled data; Dataframe\n",
    "    y_res : undersampled labels; Dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    # Create X and y\n",
    "    X = data.loc[:, data.columns != \"target\"]\n",
    "    y = data.loc[:, data.columns == \"target\"]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"def split(X, y):\\n    \\\"\\\"\\\"\\n    Split the data into training and testing sample\\n\\n    Parameters\\n    ----------\\n    X : data\\n    y : labels\\n\\n    Return\\n    ------\\n    X_train : training modelling fields\\n    X_test : test modelling fields\\n    y_train : training labels\\n    y_test : testing labels\\n\\n    \\\"\\\"\\\"\\n    # Train-Test Split\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        X_res, y_res, test_size=0.2, random_state=7\\n    )\\n    columns = X_train.columns\\n\\n    # Columns\\n    X_train = pd.DataFrame(data=X_train, columns=columns)\\n    y_train = pd.DataFrame(data=y_train, columns=[\\\"target\\\"])\\n\\n    return X_train, X_test, y_train, y_test\";\n",
       "                var nbb_formatted_code = \"def split(X, y):\\n    \\\"\\\"\\\"\\n    Split the data into training and testing sample\\n\\n    Parameters\\n    ----------\\n    X : data\\n    y : labels\\n\\n    Return\\n    ------\\n    X_train : training modelling fields\\n    X_test : test modelling fields\\n    y_train : training labels\\n    y_test : testing labels\\n\\n    \\\"\\\"\\\"\\n    # Train-Test Split\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        X_res, y_res, test_size=0.2, random_state=7\\n    )\\n    columns = X_train.columns\\n\\n    # Columns\\n    X_train = pd.DataFrame(data=X_train, columns=columns)\\n    y_train = pd.DataFrame(data=y_train, columns=[\\\"target\\\"])\\n\\n    return X_train, X_test, y_train, y_test\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def split(X, y):\n",
    "    \"\"\"\n",
    "    Split the data into training and testing sample\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : data\n",
    "    y : labels\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    X_train : training modelling fields\n",
    "    X_test : test modelling fields\n",
    "    y_train : training labels\n",
    "    y_test : testing labels\n",
    "\n",
    "    \"\"\"\n",
    "    # Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_res, y_res, test_size=0.2, random_state=7\n",
    "    )\n",
    "    columns = X_train.columns\n",
    "\n",
    "    # Columns\n",
    "    X_train = pd.DataFrame(data=X_train, columns=columns)\n",
    "    y_train = pd.DataFrame(data=y_train, columns=[\"target\"])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"X_res, y_res = create_X_y(a)\\nX_train, X_test, y_train, y_test = split(X_res, y_res)\\ndfr_test_with_label_X = dfr_test_with_label.loc[:, dfr_test_with_label.columns != \\\"y\\\"]\\ndfr_test_with_label_y = dfr_test_with_label.loc[:, dfr_test_with_label.columns == \\\"y\\\"]\";\n",
       "                var nbb_formatted_code = \"X_res, y_res = create_X_y(a)\\nX_train, X_test, y_train, y_test = split(X_res, y_res)\\ndfr_test_with_label_X = dfr_test_with_label.loc[:, dfr_test_with_label.columns != \\\"y\\\"]\\ndfr_test_with_label_y = dfr_test_with_label.loc[:, dfr_test_with_label.columns == \\\"y\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_res, y_res = create_X_y(a)\n",
    "X_train, X_test, y_train, y_test = split(X_res, y_res)\n",
    "dfr_test_with_label_X = dfr_test_with_label.loc[:, dfr_test_with_label.columns != \"y\"]\n",
    "dfr_test_with_label_y = dfr_test_with_label.loc[:, dfr_test_with_label.columns == \"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we select the features that will end up in the model. The selection of columns below is subject to iteration based on the modelling outcomes from the logistic regression, i.e. significance (p-values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"significant_columns = [\\n    \\\"known_col_0\\\",\\n    \\\"known_col_1\\\",\\n    \\\"known_col_3\\\",\\n    \\\"known_col_4\\\",\\n]\";\n",
       "                var nbb_formatted_code = \"significant_columns = [\\n    \\\"known_col_0\\\",\\n    \\\"known_col_1\\\",\\n    \\\"known_col_3\\\",\\n    \\\"known_col_4\\\",\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "significant_columns = [\n",
    "    \"known_col_0\",\n",
    "    \"known_col_1\",\n",
    "    \"known_col_3\",\n",
    "    \"known_col_4\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"# Primary datasets\\nX_train = X_train[significant_columns]\\nX_test = X_test[significant_columns]\\nr_dev = r_dev[significant_columns]\\nr_test = r_test[significant_columns]\";\n",
       "                var nbb_formatted_code = \"# Primary datasets\\nX_train = X_train[significant_columns]\\nX_test = X_test[significant_columns]\\nr_dev = r_dev[significant_columns]\\nr_test = r_test[significant_columns]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Primary datasets\n",
    "X_train = X_train[significant_columns]\n",
    "X_test = X_test[significant_columns]\n",
    "r_dev = r_dev[significant_columns]\n",
    "r_test = r_test[significant_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.058502\n",
      "         Iterations 12\n",
      "                         Results: Logit\n",
      "================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.826    \n",
      "Dependent Variable: target           AIC:              1507.6555\n",
      "Date:               2021-05-19 23:52 BIC:              1544.9415\n",
      "No. Observations:   12800            Log-Likelihood:   -748.83  \n",
      "Df Model:           4                LL-Null:          -4295.6  \n",
      "Df Residuals:       12795            LLR p-value:      0.0000   \n",
      "Converged:          1.0000           Scale:            1.0000   \n",
      "No. Iterations:     12.0000                                     \n",
      "----------------------------------------------------------------\n",
      "              Coef.   Std.Err.    z     P>|z|   [0.025   0.975] \n",
      "----------------------------------------------------------------\n",
      "const        -13.3127   0.4849 -27.4539 0.0000 -14.2631 -12.3623\n",
      "known_col_0   -1.8920   0.0970 -19.4977 0.0000  -2.0822  -1.7018\n",
      "known_col_1    9.4761   0.3522  26.9043 0.0000   8.7858  10.1665\n",
      "known_col_3   -1.6384   0.0791 -20.7216 0.0000  -1.7933  -1.4834\n",
      "known_col_4    2.8086   0.1225  22.9294 0.0000   2.5685   3.0486\n",
      "================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"# Build Logistic regression\\n# Statmodels\\nX_in = sm.add_constant(X_train.astype(float))\\nlogit_model = sm.Logit(y_train, X_in)\\nresult3 = logit_model.fit()\\nprint(result3.summary2())\";\n",
       "                var nbb_formatted_code = \"# Build Logistic regression\\n# Statmodels\\nX_in = sm.add_constant(X_train.astype(float))\\nlogit_model = sm.Logit(y_train, X_in)\\nresult3 = logit_model.fit()\\nprint(result3.summary2())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build Logistic regression\n",
    "# Statmodels\n",
    "X_in = sm.add_constant(X_train.astype(float))\n",
    "logit_model = sm.Logit(y_train, X_in)\n",
    "result3 = logit_model.fit()\n",
    "print(result3.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# Calculate Default Rates\\ndr = len(y_test[y_test[\\\"target\\\"] == 1]) / (\\n    len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0])\\n)\\nconservative_dr = (\\n    1.1\\n    * len(y_test[y_test[\\\"target\\\"] == 1])\\n    / (len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0]))\\n)\";\n",
       "                var nbb_formatted_code = \"# Calculate Default Rates\\ndr = len(y_test[y_test[\\\"target\\\"] == 1]) / (\\n    len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0])\\n)\\nconservative_dr = (\\n    1.1\\n    * len(y_test[y_test[\\\"target\\\"] == 1])\\n    / (len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0]))\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate Default Rates\n",
    "dr = len(y_test[y_test[\"target\"] == 1]) / (\n",
    "    len(y_test[y_test[\"target\"] == 1]) + len(y_test[y_test[\"target\"] == 0])\n",
    ")\n",
    "conservative_dr = (\n",
    "    1.1\n",
    "    * len(y_test[y_test[\"target\"] == 1])\n",
    "    / (len(y_test[y_test[\"target\"] == 1]) + len(y_test[y_test[\"target\"] == 0]))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For rejects, another step of data preporcessing is applied via Isolation Forest model. The goal is to remove outliers. The isolation forest is trained on all accepts and is used to evaluate the similarity of the rejects. Then the rejects that are found to be the most and least similar to the accepts are dropped. The contaimination parameter determines how many observations are excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"# def isolation_forest(X_train, r_dev, r_test):\\n#     \\\"\\\"\\\"\\n#     The goal of this function is to filter the outliers from the rejected sample.\\n\\n#     Parameters\\n#     ----------\\n#     X_train: accepts training data; Dataframe\\n#     r_dev_mod: rejects modelling data prior outlier treatment; Dataframe\\n#     r_test_mod: rejects testinf data prior outlier treatment; Dataframe\\n\\n#     Return\\n#     ------\\n#     r_dev_mod: rejects modelling data post outlier treatment; Dataframe\\n#     r_test_mod: rejects training data prior outlier treatment; Dataframe\\n\\n#     \\\"\\\"\\\"\\n\\n#     # Build Isolation forest model\\n#     isf = IsolationForest(\\n#         n_estimators=50,\\n#         max_samples=\\\"auto\\\",\\n#         contamination=float(0.005),\\n#         max_features=1.0,\\n#     )\\n#     isf.fit(X_train)\\n#     rej_isf = isf.predict(r_dev)\\n#     # Add scores and anomaly columns to rejected train\\n#     r_dev[\\\"scores\\\"] = isf.decision_function(r_dev)\\n#     r_dev[\\\"anomaly\\\"] = isf.predict(r_dev[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Train. Number of non-outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Train. Number of outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_dev = r_dev[r_dev.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_dev = r_dev[significant_columns]\\n\\n#     # Add scores and anomaly columns to rejected test\\n#     r_test[\\\"scores\\\"] = isf.decision_function(r_test)\\n#     r_test[\\\"anomaly\\\"] = isf.predict(r_test[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Test. Number of non-outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Test. Number of outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_test = r_test[r_test.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_test = r_test[significant_columns]\\n\\n#     return r_dev, r_test\";\n",
       "                var nbb_formatted_code = \"# def isolation_forest(X_train, r_dev, r_test):\\n#     \\\"\\\"\\\"\\n#     The goal of this function is to filter the outliers from the rejected sample.\\n\\n#     Parameters\\n#     ----------\\n#     X_train: accepts training data; Dataframe\\n#     r_dev_mod: rejects modelling data prior outlier treatment; Dataframe\\n#     r_test_mod: rejects testinf data prior outlier treatment; Dataframe\\n\\n#     Return\\n#     ------\\n#     r_dev_mod: rejects modelling data post outlier treatment; Dataframe\\n#     r_test_mod: rejects training data prior outlier treatment; Dataframe\\n\\n#     \\\"\\\"\\\"\\n\\n#     # Build Isolation forest model\\n#     isf = IsolationForest(\\n#         n_estimators=50,\\n#         max_samples=\\\"auto\\\",\\n#         contamination=float(0.005),\\n#         max_features=1.0,\\n#     )\\n#     isf.fit(X_train)\\n#     rej_isf = isf.predict(r_dev)\\n#     # Add scores and anomaly columns to rejected train\\n#     r_dev[\\\"scores\\\"] = isf.decision_function(r_dev)\\n#     r_dev[\\\"anomaly\\\"] = isf.predict(r_dev[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Train. Number of non-outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Train. Number of outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_dev = r_dev[r_dev.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_dev = r_dev[significant_columns]\\n\\n#     # Add scores and anomaly columns to rejected test\\n#     r_test[\\\"scores\\\"] = isf.decision_function(r_test)\\n#     r_test[\\\"anomaly\\\"] = isf.predict(r_test[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Test. Number of non-outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Test. Number of outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_test = r_test[r_test.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_test = r_test[significant_columns]\\n\\n#     return r_dev, r_test\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def isolation_forest(X_train, r_dev, r_test):\n",
    "#     \"\"\"\n",
    "#     The goal of this function is to filter the outliers from the rejected sample.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     X_train: accepts training data; Dataframe\n",
    "#     r_dev_mod: rejects modelling data prior outlier treatment; Dataframe\n",
    "#     r_test_mod: rejects testinf data prior outlier treatment; Dataframe\n",
    "\n",
    "#     Return\n",
    "#     ------\n",
    "#     r_dev_mod: rejects modelling data post outlier treatment; Dataframe\n",
    "#     r_test_mod: rejects training data prior outlier treatment; Dataframe\n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Build Isolation forest model\n",
    "#     isf = IsolationForest(\n",
    "#         n_estimators=50,\n",
    "#         max_samples=\"auto\",\n",
    "#         contamination=float(0.005),\n",
    "#         max_features=1.0,\n",
    "#     )\n",
    "#     isf.fit(X_train)\n",
    "#     rej_isf = isf.predict(r_dev)\n",
    "#     # Add scores and anomaly columns to rejected train\n",
    "#     r_dev[\"scores\"] = isf.decision_function(r_dev)\n",
    "#     r_dev[\"anomaly\"] = isf.predict(r_dev[significant_columns])\n",
    "#     # Print number of non-outliers and outliers\n",
    "#     print(\"Rejected Train. Number of non-outliers is:\", np.sum(r_dev[\"anomaly\"] == 1))\n",
    "#     print(\"Rejected Train. Number of outliers is:\", np.sum(r_dev[\"anomaly\"] == -1))\n",
    "#     # Drop all outliers\n",
    "#     r_dev = r_dev[r_dev.anomaly != -1]\n",
    "#     # Delete columns related to the outliers\n",
    "#     r_dev = r_dev[significant_columns]\n",
    "\n",
    "#     # Add scores and anomaly columns to rejected test\n",
    "#     r_test[\"scores\"] = isf.decision_function(r_test)\n",
    "#     r_test[\"anomaly\"] = isf.predict(r_test[significant_columns])\n",
    "#     # Print number of non-outliers and outliers\n",
    "#     print(\"Rejected Test. Number of non-outliers is:\", np.sum(r_test[\"anomaly\"] == 1))\n",
    "#     print(\"Rejected Test. Number of outliers is:\", np.sum(r_test[\"anomaly\"] == -1))\n",
    "#     # Drop all outliers\n",
    "#     r_test = r_test[r_test.anomaly != -1]\n",
    "#     # Delete columns related to the outliers\n",
    "#     r_test = r_test[significant_columns]\n",
    "\n",
    "#     return r_dev, r_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# r_dev, r_test = isolation_forest(X_train, r_dev, r_test)\";\n",
       "                var nbb_formatted_code = \"# r_dev, r_test = isolation_forest(X_train, r_dev, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# r_dev, r_test = isolation_forest(X_train, r_dev, r_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Training for the Most Certain examples with Max F1 score as stopping criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"# Create copies of the data that can be overwritten in the function below\\nX_train_iter = X_train.copy()\\ny_train_iter = y_train.copy()\\nr_dev_iter = r_dev.copy()\";\n",
       "                var nbb_formatted_code = \"# Create copies of the data that can be overwritten in the function below\\nX_train_iter = X_train.copy()\\ny_train_iter = y_train.copy()\\nr_dev_iter = r_dev.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create copies of the data that can be overwritten in the function below\n",
    "X_train_iter = X_train.copy()\n",
    "y_train_iter = y_train.copy()\n",
    "r_dev_iter = r_dev.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Nr 1\n",
      "F1:  0.5221053350386908\n",
      "Iteration Nr 2\n",
      "F1:  0.5217587257899915\n",
      "Iteration Nr 3\n",
      "F1:  0.5224520429420242\n",
      "Iteration Nr 4\n",
      "F1:  0.5224520429420242\n",
      "Iteration Nr 5\n",
      "F1:  0.5221053350386908\n",
      "Iteration Nr 6\n",
      "F1:  0.5224520429420242\n",
      "Iteration Nr 7\n",
      "F1:  0.5221053350386908\n",
      "Iteration Nr 8\n",
      "F1:  0.5214122153033838\n",
      "Iteration Nr 9\n",
      "F1:  0.5217587257899915\n",
      "Iteration Nr 10\n",
      "F1:  0.5214122153033838\n",
      "Iteration Nr 11\n",
      "F1:  0.5207194910463432\n",
      "Iteration Nr 12\n",
      "F1:  0.5196811480637039\n",
      "Iteration Nr 13\n",
      "F1:  0.5196811480637039\n",
      "Iteration Nr 14\n",
      "F1:  0.5196811480637039\n",
      "Iteration Nr 15\n",
      "F1:  0.5196811480637039\n",
      "Iteration Nr 16\n",
      "F1:  0.5203732774908939\n",
      "Iteration Nr 17\n",
      "F1:  0.5196811480637039\n",
      "Iteration Nr 18\n",
      "F1:  0.5200271631275051\n",
      "Iteration Nr 19\n",
      "F1:  0.5196811480637039\n",
      "Iteration Nr 20\n",
      "F1:  0.5203732774908939\n",
      "Iteration Nr 21\n",
      "F1:  0.5214122153033838\n",
      "Iteration Nr 22\n",
      "F1:  0.5217587257899915\n",
      "Iteration Nr 23\n",
      "F1:  0.5217587257899915\n",
      "Iteration Nr 24\n",
      "F1:  0.5214122153033838\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"# Add more scores that you want to track\\nf1_scores = []\\niterations = []\\n# log_losses = []\\n\\nfor iteration in range(1, 25):  # Change to how many iterrations you like\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    # Build logistic regression\\n    KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n        X_train_iter, y_train_iter\\n    )\\n    # KGB1 = RandomForestClassifier().fit(X_train_iter, y_train_iter)\\n    f1_stat = f1_score(KGB1.predict(X_test), y_test, average=\\\"weighted\\\")\\n    f1_scores.append(f1_stat)\\n\\n    #     logloss = log_loss(KGB1.predict(X_test), y_test, eps=1e-15)\\n    #     log_losses.append(log_losses)\\n    print(\\\"F1: \\\", f1_stat)\\n    # print(\\\"Log Loss: \\\", logloss)\\n    # Make predictions on the rejected data\\n    pred = KGB1.predict_proba(r_dev_iter)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev_iter.index.copy(),\\n    )\\n\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.05)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev_iter[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\";\n",
       "                var nbb_formatted_code = \"# Add more scores that you want to track\\nf1_scores = []\\niterations = []\\n# log_losses = []\\n\\nfor iteration in range(1, 25):  # Change to how many iterrations you like\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    # Build logistic regression\\n    KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n        X_train_iter, y_train_iter\\n    )\\n    # KGB1 = RandomForestClassifier().fit(X_train_iter, y_train_iter)\\n    f1_stat = f1_score(KGB1.predict(X_test), y_test, average=\\\"weighted\\\")\\n    f1_scores.append(f1_stat)\\n\\n    #     logloss = log_loss(KGB1.predict(X_test), y_test, eps=1e-15)\\n    #     log_losses.append(log_losses)\\n    print(\\\"F1: \\\", f1_stat)\\n    # print(\\\"Log Loss: \\\", logloss)\\n    # Make predictions on the rejected data\\n    pred = KGB1.predict_proba(r_dev_iter)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev_iter.index.copy(),\\n    )\\n\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.05)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev_iter[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add more scores that you want to track\n",
    "f1_scores = []\n",
    "iterations = []\n",
    "# log_losses = []\n",
    "\n",
    "for iteration in range(1, 25):  # Change to how many iterrations you like\n",
    "    print(\"Iteration Nr {}\".format(iteration))\n",
    "    # Build logistic regression\n",
    "    KGB1 = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(\n",
    "        X_train_iter, y_train_iter\n",
    "    )\n",
    "    # KGB1 = RandomForestClassifier().fit(X_train_iter, y_train_iter)\n",
    "    f1_stat = f1_score(KGB1.predict(X_test), y_test, average=\"weighted\")\n",
    "    f1_scores.append(f1_stat)\n",
    "\n",
    "    #     logloss = log_loss(KGB1.predict(X_test), y_test, eps=1e-15)\n",
    "    #     log_losses.append(log_losses)\n",
    "    print(\"F1: \", f1_stat)\n",
    "    # print(\"Log Loss: \", logloss)\n",
    "    # Make predictions on the rejected data\n",
    "    pred = KGB1.predict_proba(r_dev_iter)[:, 1]\n",
    "    pred = pd.DataFrame(\n",
    "        data=pred,\n",
    "        columns=[\"target\"],\n",
    "        index=r_dev_iter.index.copy(),\n",
    "    )\n",
    "\n",
    "    # Choose the most certain predictions\n",
    "    lq = pred[\"target\"].quantile(q=0.05)\n",
    "    uq = pred[\"target\"].quantile(q=0.95)\n",
    "    pred[\"certain\"] = pred[\"target\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\n",
    "\n",
    "    # If PD is high, apply default status\n",
    "    pred[\"target\"] = pred[\"target\"].apply(lambda x: 1 if (x > uq) else 0)\n",
    "\n",
    "    # Pick only the certain predictions and concatenate them to the dev set\n",
    "    # Y TRAIN\n",
    "    certain = pred[pred[\"certain\"] == 1]\n",
    "    certain2 = certain[\"target\"].to_frame()\n",
    "    y_train_iter = pd.concat((y_train_iter, certain2))\n",
    "\n",
    "    # Get significant columns of the rejects based on index\n",
    "    certain_features = pd.merge(\n",
    "        certain[\"target\"],\n",
    "        r_dev_iter[significant_columns],\n",
    "        how=\"inner\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    # X TRAIN\n",
    "    certain_features = certain_features.loc[:, certain_features.columns != \"target\"]\n",
    "    X_train_iter = pd.concat((X_train_iter, certain_features))\n",
    "\n",
    "    # Remove certain columns from rejected data\n",
    "    rows = certain_features.index\n",
    "    r_dev_iter = r_dev_iter.drop(rows, axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2471b1ae7c0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"plt.plot(f1_scores, label=\\\"F1 Scores\\\")\";\n",
       "                var nbb_formatted_code = \"plt.plot(f1_scores, label=\\\"F1 Scores\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(f1_scores, label=\"F1 Scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"# Save the iteration of the model where max score is reached\\nmax_value = max(f1_scores)\\nmax_index = f1_scores.index(max_value)\";\n",
       "                var nbb_formatted_code = \"# Save the iteration of the model where max score is reached\\nmax_value = max(f1_scores)\\nmax_index = f1_scores.index(max_value)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the iteration of the model where max score is reached\n",
    "max_value = max(f1_scores)\n",
    "max_index = f1_scores.index(max_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do only 1 iteration as baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"# Create copies of the data that can be overwritten in the function below\\nX_train_iter1 = X_train.copy()\\ny_train_iter1 = y_train.copy()\\nr_dev_iter1 = r_dev.copy()\";\n",
       "                var nbb_formatted_code = \"# Create copies of the data that can be overwritten in the function below\\nX_train_iter1 = X_train.copy()\\ny_train_iter1 = y_train.copy()\\nr_dev_iter1 = r_dev.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create copies of the data that can be overwritten in the function below\n",
    "X_train_iter1 = X_train.copy()\n",
    "y_train_iter1 = y_train.copy()\n",
    "r_dev_iter1 = r_dev.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Nr 1\n",
      "F1:  0.5221053350386908\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"# Add more scores that you want to track\\nf1_scores = []\\niterations = []\\n# log_losses = []\\n\\nfor iteration in range(1, 2):  # Change to how many iterrations you like\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    # Build logistic regression\\n    KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n        X_train_iter1, y_train_iter1\\n    )\\n    # KGB1 = RandomForestClassifier().fit(X_train_iter1, y_train_iter1)\\n    f1_stat = f1_score(KGB1.predict(X_test), y_test, average=\\\"weighted\\\")\\n    f1_scores.append(f1_stat)\\n\\n    #     logloss = log_loss(KGB1.predict(X_test), y_test, eps=1e-15)\\n    #     log_losses.append(log_losses)\\n    print(\\\"F1: \\\", f1_stat)\\n    # print(\\\"Log Loss: \\\", logloss)\\n    # Make predictions on the rejected data\\n    pred = KGB1.predict_proba(r_dev_iter1)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev_iter1.index.copy(),\\n    )\\n\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.05)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train_iter1 = pd.concat((y_train_iter1, certain2))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev_iter1[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train_iter1 = pd.concat((X_train_iter1, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev_iter1 = r_dev_iter1.drop(rows, axis=\\\"index\\\")\";\n",
       "                var nbb_formatted_code = \"# Add more scores that you want to track\\nf1_scores = []\\niterations = []\\n# log_losses = []\\n\\nfor iteration in range(1, 2):  # Change to how many iterrations you like\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    # Build logistic regression\\n    KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n        X_train_iter1, y_train_iter1\\n    )\\n    # KGB1 = RandomForestClassifier().fit(X_train_iter1, y_train_iter1)\\n    f1_stat = f1_score(KGB1.predict(X_test), y_test, average=\\\"weighted\\\")\\n    f1_scores.append(f1_stat)\\n\\n    #     logloss = log_loss(KGB1.predict(X_test), y_test, eps=1e-15)\\n    #     log_losses.append(log_losses)\\n    print(\\\"F1: \\\", f1_stat)\\n    # print(\\\"Log Loss: \\\", logloss)\\n    # Make predictions on the rejected data\\n    pred = KGB1.predict_proba(r_dev_iter1)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev_iter1.index.copy(),\\n    )\\n\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.05)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train_iter1 = pd.concat((y_train_iter1, certain2))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev_iter1[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train_iter1 = pd.concat((X_train_iter1, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev_iter1 = r_dev_iter1.drop(rows, axis=\\\"index\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add more scores that you want to track\n",
    "f1_scores = []\n",
    "iterations = []\n",
    "# log_losses = []\n",
    "\n",
    "for iteration in range(1, 2):  # Change to how many iterrations you like\n",
    "    print(\"Iteration Nr {}\".format(iteration))\n",
    "    # Build logistic regression\n",
    "    KGB1 = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(\n",
    "        X_train_iter1, y_train_iter1\n",
    "    )\n",
    "    # KGB1 = RandomForestClassifier().fit(X_train_iter1, y_train_iter1)\n",
    "    f1_stat = f1_score(KGB1.predict(X_test), y_test, average=\"weighted\")\n",
    "    f1_scores.append(f1_stat)\n",
    "\n",
    "    #     logloss = log_loss(KGB1.predict(X_test), y_test, eps=1e-15)\n",
    "    #     log_losses.append(log_losses)\n",
    "    print(\"F1: \", f1_stat)\n",
    "    # print(\"Log Loss: \", logloss)\n",
    "    # Make predictions on the rejected data\n",
    "    pred = KGB1.predict_proba(r_dev_iter1)[:, 1]\n",
    "    pred = pd.DataFrame(\n",
    "        data=pred,\n",
    "        columns=[\"target\"],\n",
    "        index=r_dev_iter1.index.copy(),\n",
    "    )\n",
    "\n",
    "    # Choose the most certain predictions\n",
    "    lq = pred[\"target\"].quantile(q=0.05)\n",
    "    uq = pred[\"target\"].quantile(q=0.95)\n",
    "    pred[\"certain\"] = pred[\"target\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\n",
    "\n",
    "    # If PD is high, apply default status\n",
    "    pred[\"target\"] = pred[\"target\"].apply(lambda x: 1 if (x > uq) else 0)\n",
    "\n",
    "    # Pick only the certain predictions and concatenate them to the dev set\n",
    "    # Y TRAIN\n",
    "    certain = pred[pred[\"certain\"] == 1]\n",
    "    certain2 = certain[\"target\"].to_frame()\n",
    "    y_train_iter1 = pd.concat((y_train_iter1, certain2))\n",
    "\n",
    "    # Get significant columns of the rejects based on index\n",
    "    certain_features = pd.merge(\n",
    "        certain[\"target\"],\n",
    "        r_dev_iter1[significant_columns],\n",
    "        how=\"inner\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    # X TRAIN\n",
    "    certain_features = certain_features.loc[:, certain_features.columns != \"target\"]\n",
    "    X_train_iter1 = pd.concat((X_train_iter1, certain_features))\n",
    "\n",
    "    # Remove certain columns from rejected data\n",
    "    rows = certain_features.index\n",
    "    r_dev_iter1 = r_dev_iter1.drop(rows, axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"def predict_rejects(model, r_dev):\\n    # Make predictions on the Train Rejects\\n    pred_test = model.predict_proba(r_dev)[:, 1]\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_dev.index.copy(),\\n    )\\n\\n    # Make binary predictions based on cutoff DR\\n    q1 = pred_test[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test[\\\"target\\\"] = pred_test[\\\"pred\\\"].apply(lambda x: 0 if (x < q1) else 1)\\n    pred_test = pred_test[\\\"target\\\"].to_frame()\\n\\n    # Add new rows to df\\n    y_train_new = pd.concat((y_train, pred_test))\\n    X_train_new = pd.concat((X_train, r_dev))\\n\\n    # Fit new model\\n    KGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n        X_train_new, y_train_new\\n    )\\n    #     KGB_baseline_new = RandomForestClassifier().fit(X_train_new, y_train_new)\\n    return KGB_baseline_new\";\n",
       "                var nbb_formatted_code = \"def predict_rejects(model, r_dev):\\n    # Make predictions on the Train Rejects\\n    pred_test = model.predict_proba(r_dev)[:, 1]\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_dev.index.copy(),\\n    )\\n\\n    # Make binary predictions based on cutoff DR\\n    q1 = pred_test[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test[\\\"target\\\"] = pred_test[\\\"pred\\\"].apply(lambda x: 0 if (x < q1) else 1)\\n    pred_test = pred_test[\\\"target\\\"].to_frame()\\n\\n    # Add new rows to df\\n    y_train_new = pd.concat((y_train, pred_test))\\n    X_train_new = pd.concat((X_train, r_dev))\\n\\n    # Fit new model\\n    KGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n        X_train_new, y_train_new\\n    )\\n    #     KGB_baseline_new = RandomForestClassifier().fit(X_train_new, y_train_new)\\n    return KGB_baseline_new\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict_rejects(model, r_dev):\n",
    "    # Make predictions on the Train Rejects\n",
    "    pred_test = model.predict_proba(r_dev)[:, 1]\n",
    "    pred_test = pd.DataFrame(\n",
    "        data=pred_test,\n",
    "        columns=[\"pred\"],\n",
    "        index=r_dev.index.copy(),\n",
    "    )\n",
    "\n",
    "    # Make binary predictions based on cutoff DR\n",
    "    q1 = pred_test[\"pred\"].quantile(q=1 - conservative_dr)\n",
    "    pred_test[\"target\"] = pred_test[\"pred\"].apply(lambda x: 0 if (x < q1) else 1)\n",
    "    pred_test = pred_test[\"target\"].to_frame()\n",
    "\n",
    "    # Add new rows to df\n",
    "    y_train_new = pd.concat((y_train, pred_test))\n",
    "    X_train_new = pd.concat((X_train, r_dev))\n",
    "\n",
    "    # Fit new model\n",
    "    KGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(\n",
    "        X_train_new, y_train_new\n",
    "    )\n",
    "    #     KGB_baseline_new = RandomForestClassifier().fit(X_train_new, y_train_new)\n",
    "    return KGB_baseline_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"def evaluate_test_accepts(model, X_test):\\n    pred_test = model.predict_proba(X_test)[:, 1]\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=X_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_formatted_code = \"def evaluate_test_accepts(model, X_test):\\n    pred_test = model.predict_proba(X_test)[:, 1]\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=X_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_test_accepts(model, X_test):\n",
    "    pred_test = model.predict_proba(X_test)[:, 1]\n",
    "    pred_test = pd.DataFrame(\n",
    "        data=pred_test,\n",
    "        columns=[\"pred\"],\n",
    "        index=X_test.index.copy(),\n",
    "    )\n",
    "\n",
    "    # Merge with Target\n",
    "    pred_test2 = pd.merge(\n",
    "        pred_test[\"pred\"],\n",
    "        y_test[\"target\"],\n",
    "        how=\"inner\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    # Make binary predictions based on cutoff 50percentile of the distribution\n",
    "    q1 = pred_test2[\"pred\"].quantile(q=1 - conservative_dr)\n",
    "    pred_test2[\"prediction_baseline\"] = pred_test2[\"pred\"].apply(\n",
    "        lambda x: 0 if (x < q1) else 1\n",
    "    )\n",
    "    return pred_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"def evaluate_test_rejects(model, r_test):\\n    pred_test = model.predict_proba(r_test)[:, 1]\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_formatted_code = \"def evaluate_test_rejects(model, r_test):\\n    pred_test = model.predict_proba(r_test)[:, 1]\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_test_rejects(model, r_test):\n",
    "    pred_test = model.predict_proba(r_test)[:, 1]\n",
    "    pred_test = pd.DataFrame(\n",
    "        data=pred_test,\n",
    "        columns=[\"pred\"],\n",
    "        index=r_test.index.copy(),\n",
    "    )\n",
    "\n",
    "    # Merge with Target\n",
    "    pred_test2 = pd.merge(\n",
    "        pred_test[\"pred\"],\n",
    "        dfr_test_with_label[\"target\"],\n",
    "        how=\"inner\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    # Make binary predictions based on cutoff 50percentile of the distribution\n",
    "    q1 = pred_test2[\"pred\"].quantile(q=1 - conservative_dr)\n",
    "    pred_test2[\"prediction_baseline\"] = pred_test2[\"pred\"].apply(\n",
    "        lambda x: 0 if (x < q1) else 1\n",
    "    )\n",
    "    return pred_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"def flag_df_baseline(df):\\n\\n    # Flag kicked out bad cases (want more of these)\\n    if df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"CB\\\"\\n\\n    # Flag kicked out good cases (want less of these)\\n    elif df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"IB\\\"\\n\\n    # Flag kicked in good cases (want more of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"CG\\\"\\n\\n    # Flag kicked in bad cases (want less of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"IG\\\"\";\n",
       "                var nbb_formatted_code = \"def flag_df_baseline(df):\\n\\n    # Flag kicked out bad cases (want more of these)\\n    if df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"CB\\\"\\n\\n    # Flag kicked out good cases (want less of these)\\n    elif df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"IB\\\"\\n\\n    # Flag kicked in good cases (want more of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"CG\\\"\\n\\n    # Flag kicked in bad cases (want less of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"IG\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def flag_df_baseline(df):\n",
    "\n",
    "    # Flag kicked out bad cases (want more of these)\n",
    "    if df[\"target\"] == 1 and df[\"prediction_baseline\"] == 1:\n",
    "        return \"CB\"\n",
    "\n",
    "    # Flag kicked out good cases (want less of these)\n",
    "    elif df[\"target\"] == 1 and df[\"prediction_baseline\"] == 0:\n",
    "        return \"IB\"\n",
    "\n",
    "    # Flag kicked in good cases (want more of these)\n",
    "    elif df[\"target\"] == 0 and df[\"prediction_baseline\"] == 0:\n",
    "        return \"CG\"\n",
    "\n",
    "    # Flag kicked in bad cases (want less of these)\n",
    "    elif df[\"target\"] == 0 and df[\"prediction_baseline\"] == 1:\n",
    "        return \"IG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"def kickout_baseline(df):\\n\\n    # Counts of kickout bad and kickout good\\n    counts = df[\\\"Flag\\\"].value_counts()\\n    if \\\"CB\\\" in df.values:\\n        cb = counts.CB  # want more of these\\n    else:\\n        cb = 0\\n    if \\\"IB\\\" in df.values:\\n        ib = counts.IB  # want less of these\\n    else:\\n        ib = 0\\n\\n    if \\\"CG\\\" in df.values:\\n        cg = counts.CG  # want more of these\\n    else:\\n        cg = 0\\n\\n    if \\\"IG\\\" in df.values:\\n        ig = counts.IG  # want less of these\\n    else:\\n        ig = 0\\n\\n    # Target\\n    total_bads = df[df[\\\"target\\\"] == 1].shape[0]\\n    total_goods = df[df[\\\"target\\\"] == 0].shape[0]\\n    pb = total_bads / (total_bads + total_goods)\\n    pg = total_goods / (total_bads + total_goods)\\n\\n    kickout = (((cb / pb) - (ib / pb)) / total_bads) * (pb ** 2)\\n    kickin = (((cg / pg) - (ig / pg)) / total_goods) * (pg ** 2)\\n    weighted_total = kickout + kickin\\n    return weighted_total\";\n",
       "                var nbb_formatted_code = \"def kickout_baseline(df):\\n\\n    # Counts of kickout bad and kickout good\\n    counts = df[\\\"Flag\\\"].value_counts()\\n    if \\\"CB\\\" in df.values:\\n        cb = counts.CB  # want more of these\\n    else:\\n        cb = 0\\n    if \\\"IB\\\" in df.values:\\n        ib = counts.IB  # want less of these\\n    else:\\n        ib = 0\\n\\n    if \\\"CG\\\" in df.values:\\n        cg = counts.CG  # want more of these\\n    else:\\n        cg = 0\\n\\n    if \\\"IG\\\" in df.values:\\n        ig = counts.IG  # want less of these\\n    else:\\n        ig = 0\\n\\n    # Target\\n    total_bads = df[df[\\\"target\\\"] == 1].shape[0]\\n    total_goods = df[df[\\\"target\\\"] == 0].shape[0]\\n    pb = total_bads / (total_bads + total_goods)\\n    pg = total_goods / (total_bads + total_goods)\\n\\n    kickout = (((cb / pb) - (ib / pb)) / total_bads) * (pb ** 2)\\n    kickin = (((cg / pg) - (ig / pg)) / total_goods) * (pg ** 2)\\n    weighted_total = kickout + kickin\\n    return weighted_total\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def kickout_baseline(df):\n",
    "\n",
    "    # Counts of kickout bad and kickout good\n",
    "    counts = df[\"Flag\"].value_counts()\n",
    "    if \"CB\" in df.values:\n",
    "        cb = counts.CB  # want more of these\n",
    "    else:\n",
    "        cb = 0\n",
    "    if \"IB\" in df.values:\n",
    "        ib = counts.IB  # want less of these\n",
    "    else:\n",
    "        ib = 0\n",
    "\n",
    "    if \"CG\" in df.values:\n",
    "        cg = counts.CG  # want more of these\n",
    "    else:\n",
    "        cg = 0\n",
    "\n",
    "    if \"IG\" in df.values:\n",
    "        ig = counts.IG  # want less of these\n",
    "    else:\n",
    "        ig = 0\n",
    "\n",
    "    # Target\n",
    "    total_bads = df[df[\"target\"] == 1].shape[0]\n",
    "    total_goods = df[df[\"target\"] == 0].shape[0]\n",
    "    pb = total_bads / (total_bads + total_goods)\n",
    "    pg = total_goods / (total_bads + total_goods)\n",
    "\n",
    "    kickout = (((cb / pb) - (ib / pb)) / total_bads) * (pb ** 2)\n",
    "    kickin = (((cg / pg) - (ig / pg)) / total_goods) * (pg ** 2)\n",
    "    weighted_total = kickout + kickin\n",
    "    return weighted_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prediction before RI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: KGB Model ($m_{1}$)  <br>\n",
    "Step 2: Score Test Accepts and Test Rejects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"pred_test_a = evaluate_test_accepts(KGB1, X_test)\\npred_test_r = evaluate_test_rejects(KGB1, r_test)\";\n",
       "                var nbb_formatted_code = \"pred_test_a = evaluate_test_accepts(KGB1, X_test)\\npred_test_r = evaluate_test_rejects(KGB1, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a = evaluate_test_accepts(KGB1, X_test)\n",
    "pred_test_r = evaluate_test_rejects(KGB1, r_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_beforeRI = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_beforeRI = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a[\"Flag\"] = pred_test_a.apply(flag_df_baseline, axis=1)\n",
    "predictions_accepts_beforeRI = [round(kickout_baseline(pred_test_a).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_beforeRI = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_beforeRI = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_r[\"Flag\"] = pred_test_r.apply(flag_df_baseline, axis=1)\n",
    "predictions_rejects_beforeRI = [round(kickout_baseline(pred_test_r).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Predicions Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: KGB Model ($m_{1}$)  <br>\n",
    "Step 2: Infer status of each reject <br> \n",
    "Step 3: Redevelop KGB mdoel with inferred rejects ($m_{2}$)  <br>\n",
    "Step 4: Score Test Accepts and Test Rejects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"KGB_baseline_new = predict_rejects(KGB1, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\";\n",
       "                var nbb_formatted_code = \"KGB_baseline_new = predict_rejects(KGB1, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "KGB_baseline_new = predict_rejects(KGB1, r_dev)\n",
    "pred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\n",
    "pred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_base = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_base = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a[\"Flag\"] = pred_test_a.apply(flag_df_baseline, axis=1)\n",
    "predictions_accepts_base = [round(kickout_baseline(pred_test_a).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_base = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_base = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_r[\"Flag\"] = pred_test_r.apply(flag_df_baseline, axis=1)\n",
    "predictions_rejects_base = [round(kickout_baseline(pred_test_r).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain with the most optimal Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Nr 1\n",
      "F1:  0.5221053350386908\n",
      "Iteration Nr 2\n",
      "F1:  0.5217587257899915\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Add more scores that you want to track\\nf1_scores = []\\niterations = []\\n# log_losses = []\\n\\nfor iteration in range(1, max_index + 1):  # Change to how many iterrations you like\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    # Build logistic regression\\n    KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train, y_train)\\n    # KGB1 = RandomForestClassifier().fit(X_train, y_train)\\n    f1_stat = f1_score(KGB1.predict(X_test), y_test, average=\\\"weighted\\\")\\n    f1_scores.append(f1_stat)\\n\\n    #     logloss = log_loss(KGB1.predict(X_test), y_test, eps=1e-15)\\n    #     log_losses.append(log_losses)\\n    print(\\\"F1: \\\", f1_stat)\\n    # print(\\\"Log Loss: \\\", logloss)\\n    # Make predictions on the rejected data\\n    pred = KGB1.predict_proba(r_dev)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev.index.copy(),\\n    )\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.05)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train = pd.concat((y_train, certain2))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train = pd.concat((X_train, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev = r_dev.drop(rows, axis=\\\"index\\\")\";\n",
       "                var nbb_formatted_code = \"# Add more scores that you want to track\\nf1_scores = []\\niterations = []\\n# log_losses = []\\n\\nfor iteration in range(1, max_index + 1):  # Change to how many iterrations you like\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    # Build logistic regression\\n    KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train, y_train)\\n    # KGB1 = RandomForestClassifier().fit(X_train, y_train)\\n    f1_stat = f1_score(KGB1.predict(X_test), y_test, average=\\\"weighted\\\")\\n    f1_scores.append(f1_stat)\\n\\n    #     logloss = log_loss(KGB1.predict(X_test), y_test, eps=1e-15)\\n    #     log_losses.append(log_losses)\\n    print(\\\"F1: \\\", f1_stat)\\n    # print(\\\"Log Loss: \\\", logloss)\\n    # Make predictions on the rejected data\\n    pred = KGB1.predict_proba(r_dev)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev.index.copy(),\\n    )\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.05)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train = pd.concat((y_train, certain2))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train = pd.concat((X_train, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev = r_dev.drop(rows, axis=\\\"index\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add more scores that you want to track\n",
    "f1_scores = []\n",
    "iterations = []\n",
    "# log_losses = []\n",
    "\n",
    "for iteration in range(1, max_index + 1):  # Change to how many iterrations you like\n",
    "    print(\"Iteration Nr {}\".format(iteration))\n",
    "    # Build logistic regression\n",
    "    KGB1 = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(X_train, y_train)\n",
    "    # KGB1 = RandomForestClassifier().fit(X_train, y_train)\n",
    "    f1_stat = f1_score(KGB1.predict(X_test), y_test, average=\"weighted\")\n",
    "    f1_scores.append(f1_stat)\n",
    "\n",
    "    #     logloss = log_loss(KGB1.predict(X_test), y_test, eps=1e-15)\n",
    "    #     log_losses.append(log_losses)\n",
    "    print(\"F1: \", f1_stat)\n",
    "    # print(\"Log Loss: \", logloss)\n",
    "    # Make predictions on the rejected data\n",
    "    pred = KGB1.predict_proba(r_dev)[:, 1]\n",
    "    pred = pd.DataFrame(\n",
    "        data=pred,\n",
    "        columns=[\"target\"],\n",
    "        index=r_dev.index.copy(),\n",
    "    )\n",
    "    # Choose the most certain predictions\n",
    "    lq = pred[\"target\"].quantile(q=0.05)\n",
    "    uq = pred[\"target\"].quantile(q=0.95)\n",
    "    pred[\"certain\"] = pred[\"target\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\n",
    "\n",
    "    # If PD is high, apply default status\n",
    "    pred[\"target\"] = pred[\"target\"].apply(lambda x: 1 if (x > uq) else 0)\n",
    "\n",
    "    # Pick only the certain predictions and concatenate them to the dev set\n",
    "    # Y TRAIN\n",
    "    certain = pred[pred[\"certain\"] == 1]\n",
    "    certain2 = certain[\"target\"].to_frame()\n",
    "    y_train = pd.concat((y_train, certain2))\n",
    "\n",
    "    # Get significant columns of the rejects based on index\n",
    "    certain_features = pd.merge(\n",
    "        certain[\"target\"],\n",
    "        r_dev[significant_columns],\n",
    "        how=\"inner\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    # X TRAIN\n",
    "    certain_features = certain_features.loc[:, certain_features.columns != \"target\"]\n",
    "    X_train = pd.concat((X_train, certain_features))\n",
    "\n",
    "    # Remove certain columns from rejected data\n",
    "    rows = certain_features.index\n",
    "    r_dev = r_dev.drop(rows, axis=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. KGB model of best iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: KGB Model ($m_{1}$)  <br>\n",
    "Step 2: Infer status of each reject <br> \n",
    "Step 3: Choose the most certain predictions (0.05q and 0.95q of the predicted probailities) <br>\n",
    "Step 4: Add the most certain predictions to the training sample\n",
    "Step 5: Redevelop KGB Model ($m_{2}$)  <br>\n",
    "Step 6: Repeat Step 5 until convergence - best F1 score ($m_{i}$)  <br> \n",
    "Step 7: Score Test Accepts and Test Rejects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"pred_test_a = evaluate_test_accepts(KGB1, X_test)\\npred_test_r = evaluate_test_rejects(KGB1, r_test)\";\n",
       "                var nbb_formatted_code = \"pred_test_a = evaluate_test_accepts(KGB1, X_test)\\npred_test_r = evaluate_test_rejects(KGB1, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a = evaluate_test_accepts(KGB1, X_test)\n",
    "pred_test_r = evaluate_test_rejects(KGB1, r_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_iter = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_iter = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a[\"Flag\"] = pred_test_a.apply(flag_df_baseline, axis=1)\n",
    "predictions_accepts_iter = [round(kickout_baseline(pred_test_a).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_iter = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_iter = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_r[\"Flag\"] = pred_test_r.apply(flag_df_baseline, axis=1)\n",
    "predictions_rejects_iter = [round(kickout_baseline(pred_test_r).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. New model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: KGB Model ($m_{1}$)  <br>\n",
    "Step 2: Infer status of each reject <br> \n",
    "Step 3: Choose the most certain predictions (0.05q and 0.95q of the predicted probailities) <br>\n",
    "Step 4: Add the most certain predictions to the training sample <br>\n",
    "Step 5: Redevelop KGB Model ($m_{2}$)  <br>\n",
    "Step 6: Repeat Step 5 until convergence - best F1 score ($m_{i}$) <br> \n",
    "Step 7: Infer status of each reject with ($m_{i}$) <br> \n",
    "Step 8: Redevelop KGB mdoel with inferred rejects ($m_{final}$) <br> \n",
    "Step 9: Score Test Accepts and Test Rejects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"KGB_baseline_new = predict_rejects(KGB1, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\";\n",
       "                var nbb_formatted_code = \"KGB_baseline_new = predict_rejects(KGB1, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "KGB_baseline_new = predict_rejects(KGB1, r_dev)\n",
    "pred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\n",
    "pred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_new = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_new = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a[\"Flag\"] = pred_test_a.apply(flag_df_baseline, axis=1)\n",
    "predictions_accepts_new = [round(kickout_baseline(pred_test_a).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_new = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_new = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_r[\"Flag\"] = pred_test_r.apply(flag_df_baseline, axis=1)\n",
    "predictions_rejects_new = [round(kickout_baseline(pred_test_r).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"my_list_accepts = [\\n    predictions_accepts_beforeRI,\\n    predictions_accepts_base,\\n    predictions_accepts_iter,\\n    predictions_accepts_new,\\n]\\ndf_pred_accepts = pd.DataFrame(my_list_accepts).transpose()\\ndf_pred_accepts = df_pred_accepts.rename(\\n    columns={0: \\\"Before RI\\\", 1: \\\"Baseline\\\", 2: \\\"Iteration n\\\", 3: \\\"Self-Training\\\"},\\n)\";\n",
       "                var nbb_formatted_code = \"my_list_accepts = [\\n    predictions_accepts_beforeRI,\\n    predictions_accepts_base,\\n    predictions_accepts_iter,\\n    predictions_accepts_new,\\n]\\ndf_pred_accepts = pd.DataFrame(my_list_accepts).transpose()\\ndf_pred_accepts = df_pred_accepts.rename(\\n    columns={0: \\\"Before RI\\\", 1: \\\"Baseline\\\", 2: \\\"Iteration n\\\", 3: \\\"Self-Training\\\"},\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_list_accepts = [\n",
    "    predictions_accepts_beforeRI,\n",
    "    predictions_accepts_base,\n",
    "    predictions_accepts_iter,\n",
    "    predictions_accepts_new,\n",
    "]\n",
    "df_pred_accepts = pd.DataFrame(my_list_accepts).transpose()\n",
    "df_pred_accepts = df_pred_accepts.rename(\n",
    "    columns={0: \"Before RI\", 1: \"Baseline\", 2: \"Iteration n\", 3: \"Self-Training\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"my_list_rejects = [\\n    predictions_rejects_beforeRI,\\n    predictions_rejects_base,\\n    predictions_rejects_iter,\\n    predictions_rejects_new,\\n]\\ndf_pred_rejects = pd.DataFrame(my_list_rejects).transpose()\\ndf_pred_rejects = df_pred_rejects.rename(\\n    columns={0: \\\"Before RI\\\", 1: \\\"Baseline\\\", 2: \\\"Iteration n\\\", 3: \\\"Self-Training\\\"},\\n)\";\n",
       "                var nbb_formatted_code = \"my_list_rejects = [\\n    predictions_rejects_beforeRI,\\n    predictions_rejects_base,\\n    predictions_rejects_iter,\\n    predictions_rejects_new,\\n]\\ndf_pred_rejects = pd.DataFrame(my_list_rejects).transpose()\\ndf_pred_rejects = df_pred_rejects.rename(\\n    columns={0: \\\"Before RI\\\", 1: \\\"Baseline\\\", 2: \\\"Iteration n\\\", 3: \\\"Self-Training\\\"},\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_list_rejects = [\n",
    "    predictions_rejects_beforeRI,\n",
    "    predictions_rejects_base,\n",
    "    predictions_rejects_iter,\n",
    "    predictions_rejects_new,\n",
    "]\n",
    "df_pred_rejects = pd.DataFrame(my_list_rejects).transpose()\n",
    "df_pred_rejects = df_pred_rejects.rename(\n",
    "    columns={0: \"Before RI\", 1: \"Baseline\", 2: \"Iteration n\", 3: \"Self-Training\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Before RI</th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Iteration n</th>\n",
       "      <th>Self-Training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Before RI  Baseline  Iteration n  Self-Training\n",
       "0      0.926     0.935        0.926          0.932"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"df_pred_accepts\";\n",
       "                var nbb_formatted_code = \"df_pred_accepts\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_pred_accepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Before RI</th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Iteration n</th>\n",
       "      <th>Self-Training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.932</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Before RI  Baseline  Iteration n  Self-Training\n",
       "0      0.932     0.943        0.932          0.943"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"df_pred_rejects\";\n",
       "                var nbb_formatted_code = \"df_pred_rejects\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_pred_rejects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parcelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
