{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import sys\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Basic Packages\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Modelling\\n# Classification\\nimport statsmodels.api as sm\\nfrom sklearn.linear_model import LogisticRegression\\nfrom modAL.models import ActiveLearner\\nfrom modAL.uncertainty import uncertainty_sampling\\n\\n# Balancing\\nfrom imblearn.over_sampling import SMOTE\\nfrom imblearn.under_sampling import RandomUnderSampler\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Metrics\\nfrom sklearn.metrics import f1_score, log_loss\\n\\n# Visualization\\nimport matplotlib.pyplot as plt\";\n",
       "                var nbb_formatted_code = \"import sys\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Basic Packages\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Modelling\\n# Classification\\nimport statsmodels.api as sm\\nfrom sklearn.linear_model import LogisticRegression\\nfrom modAL.models import ActiveLearner\\nfrom modAL.uncertainty import uncertainty_sampling\\n\\n# Balancing\\nfrom imblearn.over_sampling import SMOTE\\nfrom imblearn.under_sampling import RandomUnderSampler\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Metrics\\nfrom sklearn.metrics import f1_score, log_loss\\n\\n# Visualization\\nimport matplotlib.pyplot as plt\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Basic Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modelling\n",
    "# Classification\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from modAL.models import ActiveLearner\n",
    "from modAL.uncertainty import uncertainty_sampling\n",
    "\n",
    "# Balancing\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import f1_score, log_loss\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, basic data preprocessing to obtain accepted and rejected training and test samples separately. Save rejected data in two versions: with and without lables. The rejected data without labels is needed for the semi-supervised model. The rejected data without labels is needed to perform evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"def data_preprocessing(df, accepted_flag, target, train_ratio):\\n    \\\"\\\"\\\"\\n    The goal of this function is to load the original dataset, split it into accepts and rejects,\\n    add ids, which can later be used for merging. For the rejects to further perform train / test split\\n\\n    Parameters\\n    ----------\\n\\n    df : name of the original dataset in quotation marks, csv format\\n    accepted_flag: name of the accepted flag; Binary: 1 if accepted, 0 if rejected\\n    target : name of the target column\\n    train_ratio : percentage used for training; Continuous (0,1)\\n\\n    Return\\n    ------\\n    a : accepted data\\n    r : rejected data\\n    r_dev : rejected trainining data without label\\n    r_test : rejected testing data without label\\n    dfr_dev_with_label: rejected training data with label\\n    dft_test_with_label: rejected training data with label\\n\\n    \\\"\\\"\\\"\\n    # Load data\\n    data = pd.read_csv(\\\"C:/Users/Asus/Desktop/Repo/MasterThesis_RI/Data_09_05/\\\" + df)\\n\\n    # Accepted\\n\\n    ## Create separate dataset with accepts\\n    dfa = data[data[accepted_flag] == 1]\\n    dfa = dfa.drop([accepted_flag], axis=1)\\n    ## Rename target variable as \\\"target\\\"\\n    dfa = dfa.rename(columns={target: \\\"target\\\"})\\n    ## Add id to the dataset, which can later be used for merging\\n    # dfa[\\\"id\\\"] = dfa.index.to_series().map(lambda x: uuid.uuid4())\\n\\n    # Rejected\\n\\n    ## Create separate dataset with accepts\\n    dfr = data[data[accepted_flag] == 0]\\n    dfr = dfr.drop([accepted_flag], axis=1)\\n    ## Add id to the dataset, which can later be used for merging\\n    #     dfr[\\\"id\\\"] = dfr.index.to_series().map(lambda x: uuid.uuid4())\\n    ## Train/Test Split (without labels)\\n    ### Shuffle the dataset\\n    shuffle_df = dfr.sample(frac=1, random_state=42)\\n    ### Define a size for the train set\\n    train_size = int(train_ratio * len(shuffle_df))\\n    ### Split the dataset\\n    dfr_dev = shuffle_df[:train_size]\\n    dfr_test = shuffle_df[train_size:]\\n    ## Save a copy of the rejected data with label\\n    dfr_dev_with_label = dfr_dev\\n    dfr_test_with_label = dfr_test\\n    ## Unlabel the rejects (i.e. drop the target) and save a copy of the rejeted data without label\\n    dfr_dev2 = dfr_dev_with_label.drop([target], axis=1)\\n    dfr_test2 = dfr_test_with_label.drop([target], axis=1)\\n    # Rename target variable\\n    dfr_dev_with_label = dfr_dev_with_label.rename(columns={target: \\\"target\\\"})\\n    dfr_test_with_label = dfr_test_with_label.rename(columns={target: \\\"target\\\"})\\n\\n    return dfr_dev_with_label, dfr_test_with_label, dfa, dfr, dfr_dev2, dfr_test2\";\n",
       "                var nbb_formatted_code = \"def data_preprocessing(df, accepted_flag, target, train_ratio):\\n    \\\"\\\"\\\"\\n    The goal of this function is to load the original dataset, split it into accepts and rejects,\\n    add ids, which can later be used for merging. For the rejects to further perform train / test split\\n\\n    Parameters\\n    ----------\\n\\n    df : name of the original dataset in quotation marks, csv format\\n    accepted_flag: name of the accepted flag; Binary: 1 if accepted, 0 if rejected\\n    target : name of the target column\\n    train_ratio : percentage used for training; Continuous (0,1)\\n\\n    Return\\n    ------\\n    a : accepted data\\n    r : rejected data\\n    r_dev : rejected trainining data without label\\n    r_test : rejected testing data without label\\n    dfr_dev_with_label: rejected training data with label\\n    dft_test_with_label: rejected training data with label\\n\\n    \\\"\\\"\\\"\\n    # Load data\\n    data = pd.read_csv(\\\"C:/Users/Asus/Desktop/Repo/MasterThesis_RI/Data_09_05/\\\" + df)\\n\\n    # Accepted\\n\\n    ## Create separate dataset with accepts\\n    dfa = data[data[accepted_flag] == 1]\\n    dfa = dfa.drop([accepted_flag], axis=1)\\n    ## Rename target variable as \\\"target\\\"\\n    dfa = dfa.rename(columns={target: \\\"target\\\"})\\n    ## Add id to the dataset, which can later be used for merging\\n    # dfa[\\\"id\\\"] = dfa.index.to_series().map(lambda x: uuid.uuid4())\\n\\n    # Rejected\\n\\n    ## Create separate dataset with accepts\\n    dfr = data[data[accepted_flag] == 0]\\n    dfr = dfr.drop([accepted_flag], axis=1)\\n    ## Add id to the dataset, which can later be used for merging\\n    #     dfr[\\\"id\\\"] = dfr.index.to_series().map(lambda x: uuid.uuid4())\\n    ## Train/Test Split (without labels)\\n    ### Shuffle the dataset\\n    shuffle_df = dfr.sample(frac=1, random_state=42)\\n    ### Define a size for the train set\\n    train_size = int(train_ratio * len(shuffle_df))\\n    ### Split the dataset\\n    dfr_dev = shuffle_df[:train_size]\\n    dfr_test = shuffle_df[train_size:]\\n    ## Save a copy of the rejected data with label\\n    dfr_dev_with_label = dfr_dev\\n    dfr_test_with_label = dfr_test\\n    ## Unlabel the rejects (i.e. drop the target) and save a copy of the rejeted data without label\\n    dfr_dev2 = dfr_dev_with_label.drop([target], axis=1)\\n    dfr_test2 = dfr_test_with_label.drop([target], axis=1)\\n    # Rename target variable\\n    dfr_dev_with_label = dfr_dev_with_label.rename(columns={target: \\\"target\\\"})\\n    dfr_test_with_label = dfr_test_with_label.rename(columns={target: \\\"target\\\"})\\n\\n    return dfr_dev_with_label, dfr_test_with_label, dfa, dfr, dfr_dev2, dfr_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def data_preprocessing(df, accepted_flag, target, train_ratio):\n",
    "    \"\"\"\n",
    "    The goal of this function is to load the original dataset, split it into accepts and rejects,\n",
    "    add ids, which can later be used for merging. For the rejects to further perform train / test split\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    df : name of the original dataset in quotation marks, csv format\n",
    "    accepted_flag: name of the accepted flag; Binary: 1 if accepted, 0 if rejected\n",
    "    target : name of the target column\n",
    "    train_ratio : percentage used for training; Continuous (0,1)\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    a : accepted data\n",
    "    r : rejected data\n",
    "    r_dev : rejected trainining data without label\n",
    "    r_test : rejected testing data without label\n",
    "    dfr_dev_with_label: rejected training data with label\n",
    "    dft_test_with_label: rejected training data with label\n",
    "\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    data = pd.read_csv(\"C:/Users/Asus/Desktop/Repo/MasterThesis_RI/Data_09_05/\" + df)\n",
    "\n",
    "    # Accepted\n",
    "\n",
    "    ## Create separate dataset with accepts\n",
    "    dfa = data[data[accepted_flag] == 1]\n",
    "    dfa = dfa.drop([accepted_flag], axis=1)\n",
    "    ## Rename target variable as \"target\"\n",
    "    dfa = dfa.rename(columns={target: \"target\"})\n",
    "    ## Add id to the dataset, which can later be used for merging\n",
    "    # dfa[\"id\"] = dfa.index.to_series().map(lambda x: uuid.uuid4())\n",
    "\n",
    "    # Rejected\n",
    "\n",
    "    ## Create separate dataset with accepts\n",
    "    dfr = data[data[accepted_flag] == 0]\n",
    "    dfr = dfr.drop([accepted_flag], axis=1)\n",
    "    ## Add id to the dataset, which can later be used for merging\n",
    "    #     dfr[\"id\"] = dfr.index.to_series().map(lambda x: uuid.uuid4())\n",
    "    ## Train/Test Split (without labels)\n",
    "    ### Shuffle the dataset\n",
    "    shuffle_df = dfr.sample(frac=1, random_state=42)\n",
    "    ### Define a size for the train set\n",
    "    train_size = int(train_ratio * len(shuffle_df))\n",
    "    ### Split the dataset\n",
    "    dfr_dev = shuffle_df[:train_size]\n",
    "    dfr_test = shuffle_df[train_size:]\n",
    "    ## Save a copy of the rejected data with label\n",
    "    dfr_dev_with_label = dfr_dev\n",
    "    dfr_test_with_label = dfr_test\n",
    "    ## Unlabel the rejects (i.e. drop the target) and save a copy of the rejeted data without label\n",
    "    dfr_dev2 = dfr_dev_with_label.drop([target], axis=1)\n",
    "    dfr_test2 = dfr_test_with_label.drop([target], axis=1)\n",
    "    # Rename target variable\n",
    "    dfr_dev_with_label = dfr_dev_with_label.rename(columns={target: \"target\"})\n",
    "    dfr_test_with_label = dfr_test_with_label.rename(columns={target: \"target\"})\n",
    "\n",
    "    return dfr_dev_with_label, dfr_test_with_label, dfa, dfr, dfr_dev2, dfr_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"dfr_dev_with_label, dfr_test_with_label, a, r, r_dev, r_test = data_preprocessing(\\n    \\\"paper_1.csv\\\", \\\"is_accepted\\\", \\\"y\\\", 0.8\\n)\";\n",
       "                var nbb_formatted_code = \"dfr_dev_with_label, dfr_test_with_label, a, r, r_dev, r_test = data_preprocessing(\\n    \\\"paper_1.csv\\\", \\\"is_accepted\\\", \\\"y\\\", 0.8\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfr_dev_with_label, dfr_test_with_label, a, r, r_dev, r_test = data_preprocessing(\n",
    "    \"paper_1.csv\", \"is_accepted\", \"y\", 0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below two functions continue the data preprocessing. Used to create feature and target data and to split into train and test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"def create_X_y(data):\\n    \\\"\\\"\\\"\\n    Undersample the data\\n\\n    Parameters\\n    ----------\\n    data : Dataframe\\n\\n    Return\\n    ------\\n    X_res : undersampled data; Dataframe\\n    y_res : undersampled labels; Dataframe\\n\\n    \\\"\\\"\\\"\\n    # Create X and y\\n    X = data.loc[:, data.columns != \\\"target\\\"]\\n    y = data.loc[:, data.columns == \\\"target\\\"]\\n\\n    return X, y\";\n",
       "                var nbb_formatted_code = \"def create_X_y(data):\\n    \\\"\\\"\\\"\\n    Undersample the data\\n\\n    Parameters\\n    ----------\\n    data : Dataframe\\n\\n    Return\\n    ------\\n    X_res : undersampled data; Dataframe\\n    y_res : undersampled labels; Dataframe\\n\\n    \\\"\\\"\\\"\\n    # Create X and y\\n    X = data.loc[:, data.columns != \\\"target\\\"]\\n    y = data.loc[:, data.columns == \\\"target\\\"]\\n\\n    return X, y\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_X_y(data):\n",
    "    \"\"\"\n",
    "    Undersample the data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Dataframe\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    X_res : undersampled data; Dataframe\n",
    "    y_res : undersampled labels; Dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    # Create X and y\n",
    "    X = data.loc[:, data.columns != \"target\"]\n",
    "    y = data.loc[:, data.columns == \"target\"]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"def split(X, y):\\n    \\\"\\\"\\\"\\n    Split the data into training and testing sample\\n\\n    Parameters\\n    ----------\\n    X : data\\n    y : labels\\n\\n    Return\\n    ------\\n    X_train : training modelling fields\\n    X_test : test modelling fields\\n    y_train : training labels\\n    y_test : testing labels\\n\\n    \\\"\\\"\\\"\\n    # Train-Test Split\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        X_res, y_res, test_size=0.2, random_state=7\\n    )\\n    columns = X_train.columns\\n\\n    # Columns\\n    X_train = pd.DataFrame(data=X_train, columns=columns)\\n    y_train = pd.DataFrame(data=y_train, columns=[\\\"target\\\"])\\n\\n    return X_train, X_test, y_train, y_test\";\n",
       "                var nbb_formatted_code = \"def split(X, y):\\n    \\\"\\\"\\\"\\n    Split the data into training and testing sample\\n\\n    Parameters\\n    ----------\\n    X : data\\n    y : labels\\n\\n    Return\\n    ------\\n    X_train : training modelling fields\\n    X_test : test modelling fields\\n    y_train : training labels\\n    y_test : testing labels\\n\\n    \\\"\\\"\\\"\\n    # Train-Test Split\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        X_res, y_res, test_size=0.2, random_state=7\\n    )\\n    columns = X_train.columns\\n\\n    # Columns\\n    X_train = pd.DataFrame(data=X_train, columns=columns)\\n    y_train = pd.DataFrame(data=y_train, columns=[\\\"target\\\"])\\n\\n    return X_train, X_test, y_train, y_test\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def split(X, y):\n",
    "    \"\"\"\n",
    "    Split the data into training and testing sample\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : data\n",
    "    y : labels\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    X_train : training modelling fields\n",
    "    X_test : test modelling fields\n",
    "    y_train : training labels\n",
    "    y_test : testing labels\n",
    "\n",
    "    \"\"\"\n",
    "    # Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_res, y_res, test_size=0.2, random_state=7\n",
    "    )\n",
    "    columns = X_train.columns\n",
    "\n",
    "    # Columns\n",
    "    X_train = pd.DataFrame(data=X_train, columns=columns)\n",
    "    y_train = pd.DataFrame(data=y_train, columns=[\"target\"])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"X_res, y_res = create_X_y(a)\\nX_train, X_test, y_train, y_test = split(X_res, y_res)\\ndfr_test_with_label_X = dfr_test_with_label.loc[:, dfr_test_with_label.columns != \\\"y\\\"]\\ndfr_test_with_label_y = dfr_test_with_label.loc[:, dfr_test_with_label.columns == \\\"y\\\"]\";\n",
       "                var nbb_formatted_code = \"X_res, y_res = create_X_y(a)\\nX_train, X_test, y_train, y_test = split(X_res, y_res)\\ndfr_test_with_label_X = dfr_test_with_label.loc[:, dfr_test_with_label.columns != \\\"y\\\"]\\ndfr_test_with_label_y = dfr_test_with_label.loc[:, dfr_test_with_label.columns == \\\"y\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_res, y_res = create_X_y(a)\n",
    "X_train, X_test, y_train, y_test = split(X_res, y_res)\n",
    "dfr_test_with_label_X = dfr_test_with_label.loc[:, dfr_test_with_label.columns != \"y\"]\n",
    "dfr_test_with_label_y = dfr_test_with_label.loc[:, dfr_test_with_label.columns == \"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we select the features that will end up in the model. The selection of columns below is subject to iteration based on the modelling outcomes from the logistic regression, i.e. significance (p-values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"significant_columns = [\\n    \\\"known_col_0\\\",\\n    \\\"known_col_1\\\",\\n    \\\"known_col_3\\\",\\n    \\\"known_col_4\\\",\\n]\";\n",
       "                var nbb_formatted_code = \"significant_columns = [\\n    \\\"known_col_0\\\",\\n    \\\"known_col_1\\\",\\n    \\\"known_col_3\\\",\\n    \\\"known_col_4\\\",\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "significant_columns = [\n",
    "    \"known_col_0\",\n",
    "    \"known_col_1\",\n",
    "    \"known_col_3\",\n",
    "    \"known_col_4\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"# Primary datasets\\nX_train = X_train[significant_columns]\\nX_test = X_test[significant_columns]\\nr_dev = r_dev[significant_columns]\\nr_test = r_test[significant_columns]\";\n",
       "                var nbb_formatted_code = \"# Primary datasets\\nX_train = X_train[significant_columns]\\nX_test = X_test[significant_columns]\\nr_dev = r_dev[significant_columns]\\nr_test = r_test[significant_columns]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Primary datasets\n",
    "X_train = X_train[significant_columns]\n",
    "X_test = X_test[significant_columns]\n",
    "r_dev = r_dev[significant_columns]\n",
    "r_test = r_test[significant_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.137072\n",
      "         Iterations 10\n",
      "                         Results: Logit\n",
      "================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.789    \n",
      "Dependent Variable: target           AIC:              3080.4233\n",
      "Date:               2021-05-21 18:07 BIC:              3117.0417\n",
      "No. Observations:   11200            Log-Likelihood:   -1535.2  \n",
      "Df Model:           4                LL-Null:          -7279.5  \n",
      "Df Residuals:       11195            LLR p-value:      0.0000   \n",
      "Converged:          1.0000           Scale:            1.0000   \n",
      "No. Iterations:     10.0000                                     \n",
      "----------------------------------------------------------------\n",
      "                 Coef.  Std.Err.    z     P>|z|   [0.025  0.975]\n",
      "----------------------------------------------------------------\n",
      "const           -2.1944   0.0759 -28.9214 0.0000 -2.3431 -2.0457\n",
      "known_col_0     -1.8043   0.0651 -27.6975 0.0000 -1.9320 -1.6766\n",
      "known_col_1      7.7684   0.2035  38.1830 0.0000  7.3697  8.1672\n",
      "known_col_3     -2.5893   0.0814 -31.8231 0.0000 -2.7488 -2.4299\n",
      "known_col_4      2.6540   0.0950  27.9406 0.0000  2.4678  2.8402\n",
      "================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"# Build Logistic regression\\n# Statmodels\\nX_in = sm.add_constant(X_train.astype(float))\\nlogit_model = sm.Logit(y_train, X_in)\\nresult3 = logit_model.fit()\\nprint(result3.summary2())\";\n",
       "                var nbb_formatted_code = \"# Build Logistic regression\\n# Statmodels\\nX_in = sm.add_constant(X_train.astype(float))\\nlogit_model = sm.Logit(y_train, X_in)\\nresult3 = logit_model.fit()\\nprint(result3.summary2())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build Logistic regression\n",
    "# Statmodels\n",
    "X_in = sm.add_constant(X_train.astype(float))\n",
    "logit_model = sm.Logit(y_train, X_in)\n",
    "result3 = logit_model.fit()\n",
    "print(result3.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# Calculate Default Rates\\ndr = len(y_test[y_test[\\\"target\\\"] == 1]) / (\\n    len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0])\\n)\\nconservative_dr = (\\n    1.1\\n    * len(y_test[y_test[\\\"target\\\"] == 1])\\n    / (len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0]))\\n)\";\n",
       "                var nbb_formatted_code = \"# Calculate Default Rates\\ndr = len(y_test[y_test[\\\"target\\\"] == 1]) / (\\n    len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0])\\n)\\nconservative_dr = (\\n    1.1\\n    * len(y_test[y_test[\\\"target\\\"] == 1])\\n    / (len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0]))\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate Default Rates\n",
    "dr = len(y_test[y_test[\"target\"] == 1]) / (\n",
    "    len(y_test[y_test[\"target\"] == 1]) + len(y_test[y_test[\"target\"] == 0])\n",
    ")\n",
    "conservative_dr = (\n",
    "    1.1\n",
    "    * len(y_test[y_test[\"target\"] == 1])\n",
    "    / (len(y_test[y_test[\"target\"] == 1]) + len(y_test[y_test[\"target\"] == 0]))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For rejects, another step of data preporcessing is applied via Isolation Forest model. The goal is to remove outliers. The isolation forest is trained on all accepts and is used to evaluate the similarity of the rejects. Then the rejects that are found to be the most and least similar to the accepts are dropped. The contaimination parameter determines how many observations are excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"# def isolation_forest(X_train, r_dev, r_test):\\n#     \\\"\\\"\\\"\\n#     The goal of this function is to filter the outliers from the rejected sample.\\n\\n#     Parameters\\n#     ----------\\n#     X_train: accepts training data; Dataframe\\n#     r_dev_mod: rejects modelling data prior outlier treatment; Dataframe\\n#     r_test_mod: rejects testinf data prior outlier treatment; Dataframe\\n\\n#     Return\\n#     ------\\n#     r_dev_mod: rejects modelling data post outlier treatment; Dataframe\\n#     r_test_mod: rejects training data prior outlier treatment; Dataframe\\n\\n#     \\\"\\\"\\\"\\n\\n#     # Build Isolation forest model\\n#     isf = IsolationForest(\\n#         n_estimators=50,\\n#         max_samples=\\\"auto\\\",\\n#         contamination=float(0.005),\\n#         max_features=1.0,\\n#     )\\n#     isf.fit(X_train)\\n#     rej_isf = isf.predict(r_dev)\\n#     # Add scores and anomaly columns to rejected train\\n#     r_dev[\\\"scores\\\"] = isf.decision_function(r_dev)\\n#     r_dev[\\\"anomaly\\\"] = isf.predict(r_dev[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Train. Number of non-outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Train. Number of outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_dev = r_dev[r_dev.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_dev = r_dev[significant_columns]\\n\\n#     # Add scores and anomaly columns to rejected test\\n#     r_test[\\\"scores\\\"] = isf.decision_function(r_test)\\n#     r_test[\\\"anomaly\\\"] = isf.predict(r_test[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Test. Number of non-outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Test. Number of outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_test = r_test[r_test.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_test = r_test[significant_columns]\\n\\n#     return r_dev, r_test\";\n",
       "                var nbb_formatted_code = \"# def isolation_forest(X_train, r_dev, r_test):\\n#     \\\"\\\"\\\"\\n#     The goal of this function is to filter the outliers from the rejected sample.\\n\\n#     Parameters\\n#     ----------\\n#     X_train: accepts training data; Dataframe\\n#     r_dev_mod: rejects modelling data prior outlier treatment; Dataframe\\n#     r_test_mod: rejects testinf data prior outlier treatment; Dataframe\\n\\n#     Return\\n#     ------\\n#     r_dev_mod: rejects modelling data post outlier treatment; Dataframe\\n#     r_test_mod: rejects training data prior outlier treatment; Dataframe\\n\\n#     \\\"\\\"\\\"\\n\\n#     # Build Isolation forest model\\n#     isf = IsolationForest(\\n#         n_estimators=50,\\n#         max_samples=\\\"auto\\\",\\n#         contamination=float(0.005),\\n#         max_features=1.0,\\n#     )\\n#     isf.fit(X_train)\\n#     rej_isf = isf.predict(r_dev)\\n#     # Add scores and anomaly columns to rejected train\\n#     r_dev[\\\"scores\\\"] = isf.decision_function(r_dev)\\n#     r_dev[\\\"anomaly\\\"] = isf.predict(r_dev[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Train. Number of non-outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Train. Number of outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_dev = r_dev[r_dev.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_dev = r_dev[significant_columns]\\n\\n#     # Add scores and anomaly columns to rejected test\\n#     r_test[\\\"scores\\\"] = isf.decision_function(r_test)\\n#     r_test[\\\"anomaly\\\"] = isf.predict(r_test[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Test. Number of non-outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Test. Number of outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_test = r_test[r_test.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_test = r_test[significant_columns]\\n\\n#     return r_dev, r_test\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def isolation_forest(X_train, r_dev, r_test):\n",
    "#     \"\"\"\n",
    "#     The goal of this function is to filter the outliers from the rejected sample.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     X_train: accepts training data; Dataframe\n",
    "#     r_dev_mod: rejects modelling data prior outlier treatment; Dataframe\n",
    "#     r_test_mod: rejects testinf data prior outlier treatment; Dataframe\n",
    "\n",
    "#     Return\n",
    "#     ------\n",
    "#     r_dev_mod: rejects modelling data post outlier treatment; Dataframe\n",
    "#     r_test_mod: rejects training data prior outlier treatment; Dataframe\n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Build Isolation forest model\n",
    "#     isf = IsolationForest(\n",
    "#         n_estimators=50,\n",
    "#         max_samples=\"auto\",\n",
    "#         contamination=float(0.005),\n",
    "#         max_features=1.0,\n",
    "#     )\n",
    "#     isf.fit(X_train)\n",
    "#     rej_isf = isf.predict(r_dev)\n",
    "#     # Add scores and anomaly columns to rejected train\n",
    "#     r_dev[\"scores\"] = isf.decision_function(r_dev)\n",
    "#     r_dev[\"anomaly\"] = isf.predict(r_dev[significant_columns])\n",
    "#     # Print number of non-outliers and outliers\n",
    "#     print(\"Rejected Train. Number of non-outliers is:\", np.sum(r_dev[\"anomaly\"] == 1))\n",
    "#     print(\"Rejected Train. Number of outliers is:\", np.sum(r_dev[\"anomaly\"] == -1))\n",
    "#     # Drop all outliers\n",
    "#     r_dev = r_dev[r_dev.anomaly != -1]\n",
    "#     # Delete columns related to the outliers\n",
    "#     r_dev = r_dev[significant_columns]\n",
    "\n",
    "#     # Add scores and anomaly columns to rejected test\n",
    "#     r_test[\"scores\"] = isf.decision_function(r_test)\n",
    "#     r_test[\"anomaly\"] = isf.predict(r_test[significant_columns])\n",
    "#     # Print number of non-outliers and outliers\n",
    "#     print(\"Rejected Test. Number of non-outliers is:\", np.sum(r_test[\"anomaly\"] == 1))\n",
    "#     print(\"Rejected Test. Number of outliers is:\", np.sum(r_test[\"anomaly\"] == -1))\n",
    "#     # Drop all outliers\n",
    "#     r_test = r_test[r_test.anomaly != -1]\n",
    "#     # Delete columns related to the outliers\n",
    "#     r_test = r_test[significant_columns]\n",
    "\n",
    "#     return r_dev, r_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# r_dev, r_test = isolation_forest(X_train, r_dev, r_test)\";\n",
       "                var nbb_formatted_code = \"# r_dev, r_test = isolation_forest(X_train, r_dev, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# r_dev, r_test = isolation_forest(X_train, r_dev, r_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Training for the Most Certain examples with Max F1 score as stopping criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"# Create copies of the data that can be overwritten in the function below\\nX_train_iter = X_train.copy()\\ny_train_iter = y_train.copy()\\nr_dev_iter = r_dev.copy()\";\n",
       "                var nbb_formatted_code = \"# Create copies of the data that can be overwritten in the function below\\nX_train_iter = X_train.copy()\\ny_train_iter = y_train.copy()\\nr_dev_iter = r_dev.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create copies of the data that can be overwritten in the function below\n",
    "X_train_iter = X_train.copy()\n",
    "y_train_iter = y_train.copy()\n",
    "r_dev_iter = r_dev.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"# f1_scores = []\\n# iterations = []\\n# # log_losses = []\\n\\n# for iteration in range(1, 25):  # Change to how many iterrations you like\\n#     print(\\\"Iteration Nr {}\\\".format(iteration))\\n#     # Build logistic regression\\n#     #     KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n#     #         X_train_iter, y_train_iter\\n#     #     )\\n#     # KGB1 = RandomForestClassifier().fit(X_train_iter, y_train_iter)\\n\\n#     # Active Learning\\n#     n_initial = len(X_train_iter)\\n#     initial_idx = np.random.choice(\\n#         range(len(X_train_iter)), size=n_initial, replace=False\\n#     )\\n#     X_training, y_training = (\\n#         X_train_iter.iloc[initial_idx],\\n#         y_train_iter.iloc[initial_idx],\\n#     )\\n\\n#     KGB1 = ActiveLearner(\\n#         estimator=LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n#             X_train_iter, y_train_iter\\n#         ),\\n#         query_strategy=uncertainty_sampling,\\n#         X_training=X_training,\\n#         y_training=y_training,\\n#     )\\n#     query_idx, query_inst = KGB1.query(X_training)\\n#     # active learning\\n#     for idx in range(5):\\n#         query_idx, query_instance = KGB1.query(X_train_iter)\\n#         KGB1.teach(X_train_iter.iloc[query_idx], y_train.iloc[query_idx])\\n\\n#     f1_stat = f1_score(KGB1.predict(X_test), y_test, average=\\\"weighted\\\")\\n#     f1_scores.append(f1_stat)\\n#     print(\\\"F1: \\\", f1_stat)\\n\\n#     #     logloss = log_loss(KGB1.predict(X_test), y_test, eps=1e-15)\\n#     #     log_losses.append(log_losses)\\n#     # print(\\\"Log Loss: \\\", logloss)\\n#     # Make predictions on the rejected data\\n#     pred = KGB1.predict_proba(r_dev_iter)[:, 1]\\n#     pred = pd.DataFrame(\\n#         data=pred,\\n#         columns=[\\\"target\\\"],\\n#         index=r_dev_iter.index.copy(),\\n#     )\\n\\n#     # Choose the most certain predictions\\n#     lq = pred[\\\"target\\\"].quantile(q=0.05)\\n#     uq = pred[\\\"target\\\"].quantile(q=0.95)\\n#     pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n#     # If PD is high, apply default status\\n#     pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n#     # Pick only the certain predictions and concatenate them to the dev set\\n#     # Y TRAIN\\n#     certain = pred[pred[\\\"certain\\\"] == 1]\\n#     certain2 = certain[\\\"target\\\"].to_frame()\\n#     y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n#     # Get significant columns of the rejects based on index\\n#     certain_features = pd.merge(\\n#         certain[\\\"target\\\"],\\n#         r_dev_iter[significant_columns],\\n#         how=\\\"inner\\\",\\n#         left_index=True,\\n#         right_index=True,\\n#     )\\n\\n#     # X TRAIN\\n#     certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n#     X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n#     # Remove certain columns from rejected data\\n#     rows = certain_features.index\\n#     r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\";\n",
       "                var nbb_formatted_code = \"# f1_scores = []\\n# iterations = []\\n# # log_losses = []\\n\\n# for iteration in range(1, 25):  # Change to how many iterrations you like\\n#     print(\\\"Iteration Nr {}\\\".format(iteration))\\n#     # Build logistic regression\\n#     #     KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n#     #         X_train_iter, y_train_iter\\n#     #     )\\n#     # KGB1 = RandomForestClassifier().fit(X_train_iter, y_train_iter)\\n\\n#     # Active Learning\\n#     n_initial = len(X_train_iter)\\n#     initial_idx = np.random.choice(\\n#         range(len(X_train_iter)), size=n_initial, replace=False\\n#     )\\n#     X_training, y_training = (\\n#         X_train_iter.iloc[initial_idx],\\n#         y_train_iter.iloc[initial_idx],\\n#     )\\n\\n#     KGB1 = ActiveLearner(\\n#         estimator=LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n#             X_train_iter, y_train_iter\\n#         ),\\n#         query_strategy=uncertainty_sampling,\\n#         X_training=X_training,\\n#         y_training=y_training,\\n#     )\\n#     query_idx, query_inst = KGB1.query(X_training)\\n#     # active learning\\n#     for idx in range(5):\\n#         query_idx, query_instance = KGB1.query(X_train_iter)\\n#         KGB1.teach(X_train_iter.iloc[query_idx], y_train.iloc[query_idx])\\n\\n#     f1_stat = f1_score(KGB1.predict(X_test), y_test, average=\\\"weighted\\\")\\n#     f1_scores.append(f1_stat)\\n#     print(\\\"F1: \\\", f1_stat)\\n\\n#     #     logloss = log_loss(KGB1.predict(X_test), y_test, eps=1e-15)\\n#     #     log_losses.append(log_losses)\\n#     # print(\\\"Log Loss: \\\", logloss)\\n#     # Make predictions on the rejected data\\n#     pred = KGB1.predict_proba(r_dev_iter)[:, 1]\\n#     pred = pd.DataFrame(\\n#         data=pred,\\n#         columns=[\\\"target\\\"],\\n#         index=r_dev_iter.index.copy(),\\n#     )\\n\\n#     # Choose the most certain predictions\\n#     lq = pred[\\\"target\\\"].quantile(q=0.05)\\n#     uq = pred[\\\"target\\\"].quantile(q=0.95)\\n#     pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n#     # If PD is high, apply default status\\n#     pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n#     # Pick only the certain predictions and concatenate them to the dev set\\n#     # Y TRAIN\\n#     certain = pred[pred[\\\"certain\\\"] == 1]\\n#     certain2 = certain[\\\"target\\\"].to_frame()\\n#     y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n#     # Get significant columns of the rejects based on index\\n#     certain_features = pd.merge(\\n#         certain[\\\"target\\\"],\\n#         r_dev_iter[significant_columns],\\n#         how=\\\"inner\\\",\\n#         left_index=True,\\n#         right_index=True,\\n#     )\\n\\n#     # X TRAIN\\n#     certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n#     X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n#     # Remove certain columns from rejected data\\n#     rows = certain_features.index\\n#     r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# f1_scores = []\n",
    "# iterations = []\n",
    "# # log_losses = []\n",
    "\n",
    "# for iteration in range(1, 25):  # Change to how many iterrations you like\n",
    "#     print(\"Iteration Nr {}\".format(iteration))\n",
    "#     # Build logistic regression\n",
    "#     #     KGB1 = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(\n",
    "#     #         X_train_iter, y_train_iter\n",
    "#     #     )\n",
    "#     # KGB1 = RandomForestClassifier().fit(X_train_iter, y_train_iter)\n",
    "\n",
    "#     # Active Learning\n",
    "#     n_initial = len(X_train_iter)\n",
    "#     initial_idx = np.random.choice(\n",
    "#         range(len(X_train_iter)), size=n_initial, replace=False\n",
    "#     )\n",
    "#     X_training, y_training = (\n",
    "#         X_train_iter.iloc[initial_idx],\n",
    "#         y_train_iter.iloc[initial_idx],\n",
    "#     )\n",
    "\n",
    "#     KGB1 = ActiveLearner(\n",
    "#         estimator=LogisticRegression(fit_intercept=False, penalty=\"none\").fit(\n",
    "#             X_train_iter, y_train_iter\n",
    "#         ),\n",
    "#         query_strategy=uncertainty_sampling,\n",
    "#         X_training=X_training,\n",
    "#         y_training=y_training,\n",
    "#     )\n",
    "#     query_idx, query_inst = KGB1.query(X_training)\n",
    "#     # active learning\n",
    "#     for idx in range(5):\n",
    "#         query_idx, query_instance = KGB1.query(X_train_iter)\n",
    "#         KGB1.teach(X_train_iter.iloc[query_idx], y_train.iloc[query_idx])\n",
    "\n",
    "#     f1_stat = f1_score(KGB1.predict(X_test), y_test, average=\"weighted\")\n",
    "#     f1_scores.append(f1_stat)\n",
    "#     print(\"F1: \", f1_stat)\n",
    "\n",
    "#     #     logloss = log_loss(KGB1.predict(X_test), y_test, eps=1e-15)\n",
    "#     #     log_losses.append(log_losses)\n",
    "#     # print(\"Log Loss: \", logloss)\n",
    "#     # Make predictions on the rejected data\n",
    "#     pred = KGB1.predict_proba(r_dev_iter)[:, 1]\n",
    "#     pred = pd.DataFrame(\n",
    "#         data=pred,\n",
    "#         columns=[\"target\"],\n",
    "#         index=r_dev_iter.index.copy(),\n",
    "#     )\n",
    "\n",
    "#     # Choose the most certain predictions\n",
    "#     lq = pred[\"target\"].quantile(q=0.05)\n",
    "#     uq = pred[\"target\"].quantile(q=0.95)\n",
    "#     pred[\"certain\"] = pred[\"target\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\n",
    "\n",
    "#     # If PD is high, apply default status\n",
    "#     pred[\"target\"] = pred[\"target\"].apply(lambda x: 1 if (x > uq) else 0)\n",
    "\n",
    "#     # Pick only the certain predictions and concatenate them to the dev set\n",
    "#     # Y TRAIN\n",
    "#     certain = pred[pred[\"certain\"] == 1]\n",
    "#     certain2 = certain[\"target\"].to_frame()\n",
    "#     y_train_iter = pd.concat((y_train_iter, certain2))\n",
    "\n",
    "#     # Get significant columns of the rejects based on index\n",
    "#     certain_features = pd.merge(\n",
    "#         certain[\"target\"],\n",
    "#         r_dev_iter[significant_columns],\n",
    "#         how=\"inner\",\n",
    "#         left_index=True,\n",
    "#         right_index=True,\n",
    "#     )\n",
    "\n",
    "#     # X TRAIN\n",
    "#     certain_features = certain_features.loc[:, certain_features.columns != \"target\"]\n",
    "#     X_train_iter = pd.concat((X_train_iter, certain_features))\n",
    "\n",
    "#     # Remove certain columns from rejected data\n",
    "#     rows = certain_features.index\n",
    "#     r_dev_iter = r_dev_iter.drop(rows, axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Nr 1\n",
      "F1:  0.9088069264752435\n",
      "Iteration Nr 2\n",
      "F1:  0.9088069264752435\n",
      "Iteration Nr 3\n",
      "F1:  0.9088069264752435\n",
      "Iteration Nr 4\n",
      "F1:  0.9088069264752435\n",
      "Iteration Nr 5\n",
      "F1:  0.9088177078673029\n",
      "Iteration Nr 6\n",
      "F1:  0.9084816896092619\n",
      "Iteration Nr 7\n",
      "F1:  0.9085027040432666\n",
      "Iteration Nr 8\n",
      "F1:  0.9102973456056371\n",
      "Iteration Nr 9\n",
      "F1:  0.9110008958361809\n",
      "Iteration Nr 10\n",
      "F1:  0.9127740182907681\n",
      "Iteration Nr 11\n",
      "F1:  0.9120986302859595\n",
      "Iteration Nr 12\n",
      "F1:  0.9117516302381724\n",
      "Iteration Nr 13\n",
      "F1:  0.9124638674320981\n",
      "Iteration Nr 14\n",
      "F1:  0.9131758605561396\n",
      "Iteration Nr 15\n",
      "F1:  0.9117963093592807\n",
      "Iteration Nr 16\n",
      "F1:  0.9111193066681382\n",
      "Iteration Nr 17\n",
      "F1:  0.9111442221033234\n",
      "Iteration Nr 18\n",
      "F1:  0.9101109119353987\n",
      "Iteration Nr 19\n",
      "F1:  0.9090774421519059\n",
      "Iteration Nr 20\n",
      "F1:  0.9080360663897529\n",
      "Iteration Nr 21\n",
      "F1:  0.9073495187479605\n",
      "Iteration Nr 22\n",
      "F1:  0.9066552576171872\n",
      "Iteration Nr 23\n",
      "F1:  0.90561388475551\n",
      "Iteration Nr 24\n",
      "F1:  0.90561388475551\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"f1_scores = []\\nlog_losses = []\\niterations = []\\n\\nfor iteration in range(1, 25):  # Change to how many iterrations you like\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    # Build logistic regression\\n    KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n        X_train_iter, y_train_iter\\n    )\\n    # KGB1 = RandomForestClassifier().fit(X_train_iter, y_train_iter)\\n\\n    # Scores\\n    f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\\\"weighted\\\")\\n    f1_scores.append(f1_stat)\\n\\n    logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\\n    log_losses.append(logloss)\\n\\n    print(\\\"F1: \\\", f1_stat)\\n\\n    # Make predictions on the rejected data\\n    pred = KGB1.predict_proba(r_dev_iter)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev_iter.index.copy(),\\n    )\\n\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.05)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev_iter[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\";\n",
       "                var nbb_formatted_code = \"f1_scores = []\\nlog_losses = []\\niterations = []\\n\\nfor iteration in range(1, 25):  # Change to how many iterrations you like\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    # Build logistic regression\\n    KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n        X_train_iter, y_train_iter\\n    )\\n    # KGB1 = RandomForestClassifier().fit(X_train_iter, y_train_iter)\\n\\n    # Scores\\n    f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\\\"weighted\\\")\\n    f1_scores.append(f1_stat)\\n\\n    logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\\n    log_losses.append(logloss)\\n\\n    print(\\\"F1: \\\", f1_stat)\\n\\n    # Make predictions on the rejected data\\n    pred = KGB1.predict_proba(r_dev_iter)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev_iter.index.copy(),\\n    )\\n\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.05)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev_iter[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1_scores = []\n",
    "log_losses = []\n",
    "iterations = []\n",
    "\n",
    "for iteration in range(1, 25):  # Change to how many iterrations you like\n",
    "    print(\"Iteration Nr {}\".format(iteration))\n",
    "    # Build logistic regression\n",
    "    KGB1 = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(\n",
    "        X_train_iter, y_train_iter\n",
    "    )\n",
    "    # KGB1 = RandomForestClassifier().fit(X_train_iter, y_train_iter)\n",
    "\n",
    "    # Scores\n",
    "    f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\"weighted\")\n",
    "    f1_scores.append(f1_stat)\n",
    "\n",
    "    logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\n",
    "    log_losses.append(logloss)\n",
    "\n",
    "    print(\"F1: \", f1_stat)\n",
    "\n",
    "    # Make predictions on the rejected data\n",
    "    pred = KGB1.predict_proba(r_dev_iter)[:, 1]\n",
    "    pred = pd.DataFrame(\n",
    "        data=pred,\n",
    "        columns=[\"target\"],\n",
    "        index=r_dev_iter.index.copy(),\n",
    "    )\n",
    "\n",
    "    # Choose the most certain predictions\n",
    "    lq = pred[\"target\"].quantile(q=0.05)\n",
    "    uq = pred[\"target\"].quantile(q=0.95)\n",
    "    pred[\"certain\"] = pred[\"target\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\n",
    "\n",
    "    # If PD is high, apply default status\n",
    "    pred[\"target\"] = pred[\"target\"].apply(lambda x: 1 if (x > uq) else 0)\n",
    "\n",
    "    # Pick only the certain predictions and concatenate them to the dev set\n",
    "    # Y TRAIN\n",
    "    certain = pred[pred[\"certain\"] == 1]\n",
    "    certain2 = certain[\"target\"].to_frame()\n",
    "    y_train_iter = pd.concat((y_train_iter, certain2))\n",
    "\n",
    "    # Get significant columns of the rejects based on index\n",
    "    certain_features = pd.merge(\n",
    "        certain[\"target\"],\n",
    "        r_dev_iter[significant_columns],\n",
    "        how=\"inner\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    # X TRAIN\n",
    "    certain_features = certain_features.loc[:, certain_features.columns != \"target\"]\n",
    "    X_train_iter = pd.concat((X_train_iter, certain_features))\n",
    "\n",
    "    # Remove certain columns from rejected data\n",
    "    rows = certain_features.index\n",
    "    r_dev_iter = r_dev_iter.drop(rows, axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d5426813d0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3/8dcnk4UsQAIkLEkgQNhiwACRugLiUrQqilXBtlqXKq0g2t7eWvtrr/W2vbS2VkSstS21va0gVlGselFBiCIoAcISIAthCyAJa9iyf35/ZNAYAzNJJjmzfJ6Ph4/MnHO+Zz5nHOY955zvOV9RVYwxxoSeMKcLMMYY4wwLAGOMCVEWAMYYE6IsAIwxJkRZABhjTIgKd7qAlujRo4empaU5XYYxxgSUtWvXHlTVxKbTAyoA0tLSyM3NdboMY4wJKCKyq7npdgjIGGNClAWAMcaEKAsAY4wJURYAxhgToiwAjDEmRFkAGGNMiLIAMMaYEGUBYIyf2V5+grc27Xe6DBMCLACM8SMnq2q5+4U1TH9xHZ8eq3S6HBPkLACM8SM/fyOf3YdPUa/wet5ep8sxQc6rABCRiSJSICLFIvJIM/MTRGSRiGwUkU9EJLPRvHkiUiYim5u0+W/38nki8o6I9Gn75hgTuN7atJ+FuaVMvzydUX3jeWVdKTZin2lPHgNARFzAXOAaIAOYKiIZTRZ7FMhT1RHAHcDsRvNeACY2s+onVHWEqmYB/wZ+1vLyjQkO+4+d5sevbuL81HgevGIQN41KofDACfL3VThdmgli3uwBjAGKVbVEVauBBcCkJstkAEsBVHUbkCYiPd3Pc4DDTVeqqo0/2bGA/dQxIam+Xvn+Sxuoqatn9m1ZRLjCuH5EbyJcwqvr7DCQaT/eBEAysKfR81L3tMY2AJMBRGQM0A9I8bRiEfmliOwBvsFZ9gBE5D4RyRWR3PLyci/KNSaw/OmDElaVHOKxG84jrUcsAPExkVwxtCeLN+ylpq7e4QpNsPImAKSZaU1/rc8CEkQkD5gBrAdqPa1YVX+iqqnAP4HpZ1nmeVXNVtXsxMQv3c7amIC2ee8xfvtOAdcO78Uto7/4m2nyqGQOnqjmgyL74WPahzcBUAqkNnqeAuxrvICqVqjqXe7j+XcAicCOFtTxInBzC5Y3JuCdqq7lwQXr6R4bxa9uGo7IF39rjR+SREJMBK/YYSDTTrwJgDXAIBHpLyKRwBRgceMFRCTePQ/gXiCnyTH+LxGRQY2e3gBs875sYwLfL97cyo6DJ3nytvOJj4n80vzI8DBuOL8P7245wLHTNQ5UaIKdxwBQ1VoaDs8sAbYCC1U1X0Smicg092LDgHwR2UZDb6GZZ9qLyHxgFTBEREpF5B73rFkisllENgJXN25jTLB7J/9TXvx4N/eNHcDFA3ucdbnJo1Korq3nbbsy2LQDCaR+xtnZ2WpDQprGXllbytPLinjpvovo1bWT0+V4payikq8+lUNyQjSvfvcSIsPP/jtMVbnyyRV0j41i4bSLOrBKE0xEZK2qZjedblcCm4C2aP1edh06xYML1lMbAL1l6uuVH7y8gdM1dTx128hzfvkDiAiTR6Xwyc7D7D50qoOqNKHCAsAErJNVtXyy4zBDe3Xmkx2Heeq9IqdL8uivH+3kg6KD/PS6DNKT4rxqc+PIZEQaws4YX7IAMAFr1fZDVNfV89PrMrgtO5W5y4tZUei/XSa37q/g129v48phPbl9TF+v2yXHR3PRgO68ut5uDWF8ywLABKzlhWXERLrITkvgsRvOY3BSZx5+Kc8v76JZWVPHzAXr6RoTwa9v/nKXT08mj0ph16FTrNt9pJ0qNKHIAsAEJFVleUE5Fw/sQVS4i+hIF3O/MYrKmjq/PB8w6+1tFB44wW9vOZ/ucVEtbj8xsxfRES67JsD4lAWACUjby09SeuQ044d8fnV4elIcv7wp0+/OB7y/rYwXPtrJ3Zf0Z9zg1l3NHhcVzsTMXvx7wz4qa+p8XKEJVRYAJiAtLygD+EIAANw0MsWvzgccPFHFD/+1gaG9OvOfE4e0aV2TRyVTUVnLsm1lPqrOhDoLABOQlheUk54UR0pCzJfmnTkf8P2X8jhQ4dz5AFXlP/+1kYrKWmZPGUmnCFeb1nfxwB707BLFq+tKfVShCXUWACbgnOn+efmQ5g+nNJwPGMmp6joenO/c+YB/rN7Fsm1l/PiaoQzp1bnN63OFCTeOTGZ5QTkHT1T5oEIT6iwATMA50/1z/JCksy6TntSZX9yYycc7DjN7acefDyg6cJxfvLmVcYMT+fbFaT5b7+SRKdTWK29s2Od5YWM8sAAwAadx989zuXl0Crdmp/DM+8XkdOD5gKraOh5ckEdcVDhP3DKixV0+z2VIr85kJnexgWKMT1gAmIDStPunJz+/IZNBSXE83IHnA367pICt+yv4zddHkNTZ9/cnmjwyhU17j1F04LjP121CiwWACSjNdf88l+hIF89+Y1SHnQ/4sOggf/pgB9+6sB9XDOvZLq9xQ1YfXGHCq3ZrCNNGFgAmoJyt++e5dNT5gCMnq/nBy3mkJ8Xx6LXD2u11esRFMX5wIq+t30tdvd0awrSeBYAJKCsKz97981xuHp3CLaMbzge0xxCLqsojr27k8MlqZk/JIjqybV0+PZk8KoX9xypZXXKoXV/HBDcLABMwTlXX8nHJYca38mraxyc1nA94aIHvzwcszN3DkvwD/OdXh3Jen64+XXdzrhiWROdO4bxi1wSYNrAAMAHjo2LP3T/PJTrSxdzbPz8fUOOj8wEl5Sd4bPEWLknvzj2X9vfJOj3pFOHiuhF9+L/Nn3KyqrZDXtMEH68CQEQmikiBiBSLyCPNzE8QkUUislFEPhGRzEbz5olImYhsbtLmCRHZ5m6zSETi2745Jpid6f55Qf9zd/88l0E9Pz8fcNOzKylsY0+amrp6Hnopj6iIMH53SxZhYb7r8unJzaOSOVVdx5L8TzvsNU1w8RgAIuIC5tIw1m8GMFVEMpos9iiQp6ojgDuA2Y3mvQBMbGbV7wKZ7jaFwI9bXL0JGS3t/nkuN49O4Y/fGs3+o5VcN+dDns/Z3uqTqU+9V8jG0mPMmjyiw4ekHN0vgb7dYuyaANNq3uwBjAGKVbVEVauBBcCkJstkAEsBVHUbkCYiPd3Pc4DDTVeqqu+4B5wHWA2ktG4TTChoafdPT756Xi+WPDyW8YMT+dVb25j6/OoWD7n4cckhnl2+nSkXpDIxs5dP6mqJhuEik1m5/SD7j53u8Nc3gc+bAEgG9jR6Xuqe1tgGYDKAiIwB+tGyL/S7gbebmyEi94lIrojklpc7f3dH44zWdP/0pEdcFH/81mh+d8v5bN1fwcTZObz48W6vRt06drqGh1/KI617LD+9rukOcceZPDIFVXhtvd0awrScNwHQ3EHNpv9CZgEJIpIHzADWA16dmRKRn7iX/Wdz81X1eVXNVtXsxETf/eM3gaW13T89ERFuHp3C/z08lpF943l00SbuemENZefoJaSq/GTRJsqOV/HUbVnERoX7tKaW6Ns9hgvSEnh1nQ0XaVrOmwAoBVIbPU8BvvBzQ1UrVPUuVc2i4RxAIrDD04pF5E7gOuAbap9ecxZt7f7pjeT4aP737q/w2PUZrC45xNVP5Zz1hmuL1u/l3xv38/BVgzk/1fm+C5NHpVBUdoLNeyucLsUEGG8CYA0wSET6i0gkMAVY3HgBEYl3zwO4F8hR1XN+GkVkIvAj4AZVbdnBVxNSvLn7py+EhQnfvqQ/bz54Gf26xzJj/npmzF/P0VPVny2z+9ApfvZ6PmP6d2PauIHtWo+3rh3em8jwMLsmwLSYxwBwn6idDiwBtgILVTVfRKaJyDT3YsOAfBHZRkNvoZln2ovIfGAVMERESkXkHvesZ4DOwLsikiciz/lsq0xQWV5Q3ubuny0xMDGOV6ZdxA+uGszbm/Zz9e9zeL+gjNq6eh56aT0i8PvbsnB1YJfPc+kaHcFVGT1ZvGGfz65tMKFBAunIS3Z2tubm5jpdhulAqsplv3mfob068+c7L+jw19+89xjfX5hH4YETDE/uyqa9x5gzdSTXn9+nw2s5l5zCcu6Y9wkzJqTzg6vbNvSkCT4islZVs5tOtyuBjV870/1zXDsf/jmbzOSuLJ5+KfePHcDmfceYPCrZ7778AcYOTvxs7IP2uNeRCU4WAMavfdb9sx1PAHvSKcLFj68dxoc/msBvbh7hWB2enBn74KEFeefsxWTMGRYAxq+d6f6Z2s233T9bIzk+mnCX//6T+cK9jhast1tFG4/899NsQl5HdP8MNoN6dua/b8xkdYkzYyGbwGIBYPxWR3X/DDZfH53C10enMGdZESuLDzpdjvFjFgDGb3V0989g8vik80hPjGPmgjzKjtv5ANM8CwDjl1SV5YVlXDywe5vv/hmKYiLDmfuNUZyoquGhBXl2PsA0ywLA+KWSgyfZc9i57p/BYHDPzjw+KZOPth9izjI7H2C+zALA+KXlBQ192e0EcNvcMjqFySOTmb20iI+22/kA80UWAMYvLS8oY2BirF90/wxkIsJ/35jJgB6xzFyQR/nxKqdLMn7EAsD4nc+6f9rhH5+IjWo4H1DhHsPAzgeYMywAjN/5vPunHf7xlaG9uvD4pPP4sPggz75f7HQ5xk9YABi/s7ygnOgIF2P6d3O6lKBya3YqN2b14ffvFbK65JDT5Rg/YAFg/MqZ7p+XpFv3T18TEX5x03DSusfy4Pz1HDxh5wNCnQWA8SvW/bN9xbnPB5wZ07jezgeENOcGMzWmGdb9s/0N692F/7r+PB5dtIk/rNjOA5enf2G+qlJZU8+JqlpOVde6/9ZxoqqWk1W1nKqq4ysDutGve6xDW2B8xQLA+BXr/tkxpo5JZXXJIX73TgFL8j/lZFUtJ6vqGv5W1+JpxyCjdxfefPBSRPxjVDTTOl4FgHv83tmAC/izqs5qMj8BmAcMBCqBu1V1s3vePBoGfi9T1cxGbW4BHqNhOMkxqmpDfYW409V1fLzjMN+6sJ/TpQQ9EeFXk4cTHiYcPlVNarcYYiNdxEaFExsZTmxUOHFRLmLcj2OjPp+3svggj/97C8u2lXHFsJ5Ob4ppA48BICIuYC5wFVAKrBGRxaq6pdFijwJ5qnqTiAx1L3+Fe94LNIz/+/cmq94MTAb+2KYtMEFjVclBqmut+2dHiYsK58nbslrcbkBiLPNW7uDppUVMGJpkewEBzJuTwGOAYlUtUdVqYAEwqckyGcBSAFXdBqSJSE/38xzgcNOVqupWVS1oS/EmuLy3tcy6fwaACFcY3xufzobSY+QU2e0lApk3AZAM7Gn0vNQ9rbENNPyaR0TGAP2AFF8UKCL3iUiuiOSWl9tYp8Fqw56jLFyzh2uH97bunwHg5tHJ9OnaiaeXFqFqPYkClTcB0Nz+XdP/47OABBHJA2YA64HaNtbW8EKqz6tqtqpmJybaoYFgdKKqlpkL1pPUOYqfXZfhdDnGC1HhLqaNH8jaXUdYtd0uKgtU3gRAKZDa6HkKsK/xAqpaoap3qWoWcAeQCOzwWZUmqD22OJ/dh0/x1JSRdI2JcLoc46Vbs1NJ6hzF03ar6YDlTQCsAQaJSH8RiQSmAIsbLyAi8e55APcCOapa4dtSTTBavGEf/1pbyvTL0+3Yf4DpFOHi/nEDWV1ymE92fOk0nwkAHgNAVWuB6cASYCuwUFXzRWSaiExzLzYMyBeRbcA1wMwz7UVkPrAKGCIipSJyj3v6TSJSClwEvCkiS3y5Ycb/7Tl8ip+8uolRfeN58IpBTpdjWuH2MX3pERdpA84EKK+uA1DVt4C3mkx7rtHjVUCz/4JVdepZpi8CFnldqQkqtXX1PPRSHgCzp4wk3GV3JQlE0ZEuvnPZAP7n7W2s232EUX1t/OZAYv/qjCPmLCtm7a4j/OKmTLvqN8B988J+JMREMGep7QUEGgsA0+HW7DzMnGVFTB6VzKSspj2KTaCJjQrn3ssG8H5BOZtKjzldjmkBCwDToY6druGhBXmkJMTw+KRMzw1MQLjjon506RRuPYICjAWA6TCqyqOLNnGgopKnp44kLsruRRgsOneK4O5L+/PulgNs2WcdAAOFBYDpMC+vLeXNjft5+KrBZKXGO12O8bG7Lu5PXFQ4z7xvewGBwgLAdIiS8hM8tjifCwd0Y9q4gU6XY9pB15gIvn1xGm9v/pSiA8edLsd4wQLAtLvq2npmLsgjMjyM39+WhSvM7h4ZrO6+tD/RES6esYHnA4IFgGl3v3u3gE17jzFr8gh6d412uhzTjrrFRvKti/rxxoZ9lJSfcLoc44EFgGlXHxYd5I8rSrj9K32ZmNnL6XJMB/jOZQOIDA9j7vvbnS7FeGABYNrNoRNVfH9hHgMTY/np1+wun6GiR1wU3/hKP17L28vuQ6ecLsecgwWAaReqyo9e2cjRUzU8PXUk0ZF2j/9Qcv/YAbjChGeX27kAf2YBYNrFP1bv4r2tZfzomqGc16er0+WYDpbUpRNTLkjllXWllB6xvQB/ZQFgfK6ypo5Zb2/jskE9uOviNKfLMQ450933uRV2LsBfWQAYn8vdeYST1XV8++I0wqzLZ8jqEx/N10ensnBNKZ8eq3S6HNMMCwDjc8sLyoh0hXHRwO5Ol2Ic9r3xA6lX5Y85thfgjywAjM+tKCxnTP9uxETavX5CXWq3GG4amcyLH++m7LjtBfgbCwDjU3uPnqao7ATjBic6XYrxEw9cnk5NXT1//sCGCfc3XgWAiEwUkQIRKRaRR5qZnyAii0Rko4h8IiKZjebNE5EyEdncpE03EXlXRIrcf20ooSCQU1gOwLghFgCmQVqPWCZlJfO/q3Zx6ESV0+WYRjwGgIi4gLk0jPWbAUwVkaZX9TwK5KnqCOAOYHajeS8AE5tZ9SPAUlUdBCx1PzcBbkVBOX26dmJQUpzTpRg/8sDl6VTW1vGXD20vwJ94swcwBihW1RJVrQYWAJOaLJNBw5c4qroNSBORnu7nOcDhZtY7Cfib+/HfgBtbXr7xJzV19awsPsi4IYmIWO8f87n0pDi+Nrw3f1+1i6Onqp0ux7h5EwDJwJ5Gz0vd0xrbAEwGEJExQD8gxcN6e6rqfgD336TmFhKR+0QkV0Ryy8vLvSjXOGXdriMcr6q14/+mWdMnpHOiqpZ5K3c6XYpx8yYAmvspp02ezwISRCQPmAGsB2rbWFvDC6k+r6rZqpqdmGhfLP5sRWE5rjDh4vQeTpdi/NDQXl2YeF4v/rpyBxWVNU6XY/AuAEqB1EbPU4B9jRdQ1QpVvUtVs2g4B5AIeDrYd0BEegO4/5Z5XbXxSysKyxndN4EunSKcLsX4qekT0jleWcvfbC/AL3gTAGuAQSLSX0QigSnA4sYLiEi8ex7AvUCOqnoaGHQxcKf78Z3A696XbfxN2fFK8vdVWO8fc06ZyV25YmgSf1m5gxNVPjlIYNrAYwCoai0wHVgCbAUWqmq+iEwTkWnuxYYB+SKyjYbeQjPPtBeR+cAqYIiIlIrIPe5Zs4CrRKQIuMr93ASonMKDAHb833g044pBHD1Vwz9W73K6lJDn1aWaqvoW8FaTac81erwKGHSWtlPPMv0QcIXXlRq/tqKwnB5xUWT07uJ0KcbPZaXGM3ZwIn/KKeGOi/rZFeMOsiuBTZvV1SsfFJUzdnAPu/mb8crMK9I5dLKaFz/e7XQpIc0CwLTZxtKjHD1Vw/ghzfbkNeZLRvfrxsUDu/PHnBIqa+qcLidkWQCYNlteUI4IXGbdP00LzJgwiPLjVby0Zo/nhU27sAAwbbaisJzzU+JJiI30vLAxbhcO6MaYtG48t2I7VbW2F+AECwDTJkdOVrOh9Kj1/jEtJiLMuCKd/ccq+dfaUqfLCUkWAKZNPig+iCqMt/7/phUuTe9BVmo8f1i+nZq6eqfLCTkWAKZNVhSUEx8TwYiUeKdLMQFIRJh5xSBKj5xm0fq9TpcTciwATKvV1ysrCsu5bFAiLuv+aVpp/JBEhid3Ze77xdTaXkCHsgAwrbZlfwUHT1TZ8X/TJiLCjAnp7Dp0ijc27vPcwPiMBYBptRXu0b/GDrbun6ZtrsroydBenZmzrJi6+qY3GzbtxQLAtNqKwnLO69OFpM6dnC7FBLiGvYBBlJSf5K1N+50uJ2RYAJhWqaisYd2uI3b4x/jMNZm9GJQUxzPLiqm3vYAOYQFgWuWj4oPU1qsFgPGZsDBh+oR0Cg4c550tnzpdTkiwADCtsqKwnM5R4Yzql+B0KSaIXDeiD/17xPL00mJUbS+gvVkAmBZTVVYUlHNJeg8iXPYRMr7jChMeuDydLfsrWLrVBglsb/av17RYcdkJ9h2rtNG/TLuYlNWH1G7RzFlWZHsB7cwCwLTY8oIz3T8tAIzvRbjC+N74dDaUHiOn6KDT5QQ1rwJARCaKSIGIFIvII83MTxCRRSKyUUQ+EZFMT21F5HwRWSUim0TkDRGxoaQCxIrCcgYlxZEcH+10KSZI3TwqhT5dO/H0UtsLaE8eA0BEXMBcGsb6zQCmikhGk8UeBfJUdQRwBzDbi7Z/Bh5R1eHAIuCHbd8c095OVdfyyY7D1vvHtKvI8DC+O34ga3cdYdX2Q06XE7S82QMYAxSraomqVgMLgElNlskAlgKo6jYgTUR6emg7BMhxP34XuLlNW2I6xOqSQ1TX1dvoX6bd3ZKdSlLnKOYsK3a6lKDlTQAkA42H7Cl1T2tsAzAZQETGAP2AFA9tNwM3uB/fAqQ29+Iicp+I5IpIbnl5uRflmva0oqCc6AgX2WnW/dO0r04RLu4bO4BVJYfI3XnY6XKCkjcB0NxtHpselJsFJIhIHjADWA/Uemh7N/CAiKwFOgPVzb24qj6vqtmqmp2YaIcdnLa8sJyLBnanU4TL6VJMCLj9K33pHhtpewHtxJsAKOWLv85TgC/csk9VK1T1LlXNouEcQCKw41xtVXWbql6tqqOB+cD2Vm+F6RA7D55k16FTdvzfdJiYyHDuuaw/KwrL2Vh61Olygo43AbAGGCQi/UUkEpgCLG68gIjEu+cB3AvkqGrFudqKSJL7bxjw/4DnfLFBpv2cufunjf5lOtK3LuxH1+gI2wtoB+GeFlDVWhGZDiwBXMA8Vc0XkWnu+c8Bw4C/i0gdsAW451xt3aueKiIPuB+/CvzVh9v1Bds+raD08On2Wn2bKVBXr9TU1VNbX09NrVJTX09tXcO0Gvff2rp6quuU2rp6aurqGZgUx+1j+hLeQVfjrigsJ617DP26x3bI6xkD0LlTBHddksZT7xWxdX8Fw3pbj3FfkUDqY5udna25ubktbvfT1zbzv6t3tUNFHS/SFUaES3CFCRWVtYxI6coTXz+fIb06t+vrVtbUMfLxd7k1O4WfT8r03MAYHzp2qoZLfr2McUMSmXv7KKfLCTgislZVs5tO97gHEAymjR/IrdnNdjLyG64wIcIlRLjCCHf/PfM40hVGeFjDl77I5+fV39y4n5++vpnr53zIzCsHcf/YAe22N7Bm52FO19TZ7R+MI7rGRHDHRf34w4rtFJedID0pzumSgkJIBEByfHRQXrX6tRG9uXBAN362OJ8nlhTwf5s/5YlbRjC0l+93kVcUlBPpCuPCAd19vm5jvHHPpf3568qdPPt+MU/eluV0OUHB7gUU4LrHRTH39lH84Ruj2H/sNNfP+ZCnlxZR4+PBtVcUlvOVAd2IiQyJ3wzGD3WPi+IbX+nL6xv2sevQSafLCQoWAEHimuG9eefhcUzM7M2T7xZy49yVbNlX4ZN17z16mqKyE9b90zjuvrEDcIUJf1huvcZ9wQIgiHSLjWTO1JE8983RHKio4oZnPuSp9wqprm3b3kCOu/unBYBxWlKXTky5IJVX1pWy96j/9uwLFBYAQWhiZi/efXgs143ozVPvFTFp7kry9x1r9fqWF5TRp2snO/Fm/ML94wYC8PwK2wtoKwuAIJUQG8lTU0by/LdGc/BEFZOeWcmT7za/N1BbV09FZQ0HKirZefAkW/ZVsHbXET4sOsg7+Z+ysvgQ44YkfaEHkjFOSY6P5uZRKcxfs4eyikqnywlodkYvyF19Xi/G9O/G429s4emlRSxcs4foSBenqms5XV3H6Zo6auo8XwtydUbPDqjWGO98b3w6L68t5U8flPCTrzW9O73xlgVACIiPieTJ27K4dnhvXllXSrgrjJgIF9GRDf81fhwd4SIm0kWnCBcxkeHERLroGh1BarcYpzfDmM/07R7DpPP78I/Vu5k2biDd46KcLikgWQCEkCszenKl/ZI3QeJ7l6ezKG8v81bu4IdfHep0OQHJzgEYYwJSelIc1w7vzd8+2sWxUzVOlxOQLACMMQFr+uXpnKiq5YWPdjpdSkCyADDGBKxhvbtwVUZP5q3cwfFK2wtoKQsAY0xAmzEhnWOna/jH6t1OlxJwLACMMQFtREo84wYn8ucPSjhdXed0OQHFAsAYE/BmTEjn0MlqXvzE9gJawgLAGBPwstO6cdGA7jyfs53KGtsL8JZXASAiE0WkQESKReSRZuYniMgiEdkoIp+ISKantiKSJSKrRSRPRHJFZIxvNskYE4pmTEjnQEUVL68tdbqUgOExAETEBcwFrgEyaBjLt+m1148Ceao6ArgDmO1F298AP1fVLOBn7ufGGNMqFw3szuh+CTy3fLvPx8MIVt7sAYwBilW1RFWrgQXApCbLZABLAVR1G5AmIj09tFXgzNBVXYF9bdoSY0xIExGmT0hn79HT/OXDHU6XExC8CYBkYE+j56XuaY1tACYDuA/l9ANSPLR9CHhCRPYAvwV+3NLijTGmsfGDE7l2eC9+u6SA9buPOF2O3/MmAJq7B3DT20fOAhJEJA+YAawHaj20/S7wsKqmAg8Df2n2xUXuc58jyC0vL/eiXGNMqBIR/mfyCHp17cSM+es5dtouDjsXbwKgFEht9DyFJodrVLVCVe9yH8+/A0gEdnhoeyfwqvvxyzQcLvoSVX1eVbNVNTsx0UakMsacW9foCOZMHcmnxyr58asbUfV8u/NQ5U0ArAEGiUh/EYkEpgCLGy8gIvHueQD3AjmqWhsFM4AAAAvESURBVOGh7T5gnPvxBKCobZtijDENRvZN4IdfHcJbmz7lnx/btQFn4/F20KpaKyLTgSWAC5inqvkiMs09/zlgGPB3EakDtgD3nKute9XfAWaLSDhQCdzn200zxoSy71w2gJXbD/H4v7cwul8Cw3p38dwoxEgg7R5lZ2drbm6u02UYYwLEwRNVXDv7Azp3CueNGZcSExmaQ6CIyFpVzW463a4ENsYErR5xUTx1WxYlB0/yX6/ne24QYiwAjDFB7eL0Hsy4vGEM4dfW73W6HL9iAWCMCXoPXjGIMWnd+MmiTew4eNLpcvyGBYAxJuiFu8KYPTWLiPAwpr+4jqpau2EcWAAYY0JE767R/Pbr55O/r4L/eWub0+X4BQsAY0zIuDKjJ3df0p8XPtrJO/mfOl2O4ywAjDEh5UfXDCEzuQs//NdG9h497XQ5jrIAMMaElKhwF89MHUVdvTJz/npqQ/jW0RYAxpiQk9Yjll/elEnuriP8/r1Cp8txjAWAMSYkTcpK5tbsFJ5dvp0Piw46XY4jLACMMSHrsRvOY2BiHA+9lEf58Sqny+lwFgDGmJAVExnO3NtHcbyyhu8vzKO+PnDujeYLFgDGmJA2pFdnfnZ9Bh8UHeRPH5Q4XU6HsgAwxoS828f05ZrMXjyxpIANe446XU6HsQAwxoQ8EWHW5BH07NIwlOTxytAYStICwBhjgK4xEcyekkXpkVP8v9c2h8RQkhYAxhjjlp3WjYeuHMzreft4ZV3w3zraAsAYYxp54PJ0LhzQjZ+9vpmS8hNOl9OuvAoAEZkoIgUiUiwijzQzP0FEFonIRhH5REQyPbUVkZdEJM/9304RyfPNJhljTOu5woSnbhtJVHgYM+avD+pbR3sMABFxAXOBa4AMYKqIZDRZ7FEgT1VHAHcAsz21VdXbVDVLVbOAV4BXfbNJxhjTNr26duIJ962jf/12gdPltBtv9gDGAMWqWqKq1cACYFKTZTKApQCqug1IE5Ge3rQVEQFuBea3aUuMMcaHrszoybcvTmPeyh0s23bA6XLahTcBkAzsafS81D2tsQ3AZAARGQP0A1K8bHsZcEBVi5p7cRG5T0RyRSS3vLzci3KNMcY3HrlmKMN6d+E/Xt7IgYpKp8vxOW8CQJqZ1rR/1CwgwX0cfwawHqj1su1UzvHrX1WfV9VsVc1OTEz0olxjjPGNThEu5kwdyenqOh5akEddkN0qwpsAKAVSGz1PAfY1XkBVK1T1Lvfx/DuARGCHp7YiEk7DnsNLrareGGPaWXpSHD+/4TxWlRziuRXbnS7Hp7wJgDXAIBHpLyKRwBRgceMFRCTePQ/gXiBHVSu8aHslsE1VS9u6IcYY015uyU7h+vP78OS7hazdddjpcnzGYwCoai0wHVgCbAUWqmq+iEwTkWnuxYYB+SKyjYYePzPP1bbR6qdgJ3+NMX5ORPjlTZn0ie/Eg/PzOHY6OG4VIYF0uXN2drbm5uY6XYYxJkSt332EW55bxVfP68Uzt4+koROj/xORtaqa3XS6XQlsjDFeGtk3gR9cPYQ3N+3npTV7PDfwcxYAxhjTAvePHcCl6T147I18ig4cd7qcNrEAMMaYFggLE5689XxiI8P5j5c3BPRdQy0AjDGmhZK6dOJH1wxlQ+kxlhcE7gWqFgDGGNMKN41MJjk+mqeXFQXsXoAFgDHGtEKEK4zvjh/I+t1H+Wj7IafLaRULAGOMaaVbslPo2SWKOcuavZWZ37MAMMaYVooKd3H/2IGsLjnMmp2Bd4WwBYAxxrTB1DF96REXyZxlxU6X0mIWAMYY0wbRkS7uvWwAOYXl5O056nQ5LWIBYIwxbfTNC/sRHxPBMwG2F2ABYIwxbRQXFc7dl/Tnva0H2LKvwulyvGYBYIwxPnDnxWl0jgpn7vuBsxdgAWCMMT7QNTqCOy9O463N+ykuC4x7BFkAGGOMj9x9aX86hbuY+35gjBxmAWCMMT7SLTaSb17Yl9fz9rLr0Emny/HIAsAYY3zoO2MHEO4K49kA2AvwKgBEZKKIFIhIsYg80sz8BBFZJCIbReQTEcn0pq2IzHDPyxeR37R9c4wxxllJnTsx9YJUXllXyt6jp50u55w8BoCIuIC5NIz1mwFMFZGMJos9CuSp6gjgDmC2p7YicjkwCRihqucBv/XJFhljjMPuHzcQEXhuuX/vBXizBzAGKFbVElWtBhbQ8MXdWAawFEBVtwFpItLTQ9vvArNUtcrdrqzNW2OMMX6gT3w0Xx+dwku5ezhQUel0OWflTQAkA40Hvyx1T2tsAzAZQETGAP2AFA9tBwOXicjHIrJCRC5o7sVF5D4RyRWR3PLywB14wRgTWr47Lp26euX5nBKnSzkrbwKguWHvm45+MAtIEJE8YAawHqj10DYcSAAuBH4ILBSRLy2vqs+raraqZicmJnpRrjHGOK9v9xgmZfXhnx/v4tCJKqfLaZY3AVAKpDZ6ngLsa7yAqlao6l2qmkXDOYBEYIeHtqXAq9rgE6Ae6NGqrTDGGD/0vfHpVNXW8+cPdzhdSrO8CYA1wCAR6S8ikcAUYHHjBUQk3j0P4F4gR1UrPLR9DZjgbj8YiAQOtnWDjDHGX6QnxfG14b35+0c7OXqq2ulyvsRjAKhqLTAdWAJsBRaqar6ITBORae7FhgH5IrKNhh4/M8/V1t1mHjBARDbTcHL4Tg3UgTWNMeYspk9I52R1HX9dudPpUr5EAuk7Nzs7W3Nzc50uwxhjWuS+v+eyuuQQKx+ZQOdOER3++iKyVlWzm063K4GNMaadzZgwiIrKWv6+apfTpXyBBYAxxrSz4SldGT8kkb98uINT1bVOl/MZCwBjjOkAMyakc/hkNS9+vNvpUj4T7nQBxhgTCkb368ZFA7rzu3cKeWnNHs8NmvjV5OFckNbNpzVZABhjTAf56XUZPLu8mPpWdL6JjnD5vB4LAGOM6SAZfbrwzO2jnC7jM3YOwBhjQpQFgDHGhCgLAGOMCVEWAMYYE6IsAIwxJkRZABhjTIiyADDGmBBlAWCMMSEqoG4HLSLlQGtvp9cDG3AG7H1ozN6LBvY+NAjm96Gfqn5pTN2ACoC2EJHc5u6HHWrsfficvRcN7H1oEIrvgx0CMsaYEGUBYIwxISqUAuB5pwvwE/Y+fM7eiwb2PjQIufchZM4BGGOM+aJQ2gMwxhjTiAWAMcaEqJAIABGZKCIFIlIsIo84XY9TRGSniGwSkTwRyXW6no4iIvNEpExENjea1k1E3hWRIvffBCdr7AhneR8eE5G97s9Enohc62SNHUFEUkXkfRHZKiL5IjLTPT3kPhNBHwAi4gLmAtcAGcBUEclwtipHXa6qWSHW3/kFYGKTaY8AS1V1ELDU/TzYvcCX3weA37s/E1mq+lYH1+SEWuAHqjoMuBB4wP2dEHKfiaAPAGAMUKyqJapaDSwAJjlck+lAqpoDHG4yeRLwN/fjvwE3dmhRDjjL+xByVHW/qq5zPz4ObAWSCcHPRCgEQDKwp9HzUve0UKTAOyKyVkTuc7oYh/VU1f3Q8IUAJDlcj5Omi8hG9yGioD/s0ZiIpAEjgY8Jwc9EKASANDMtVPu+XqKqo2g4HPaAiIx1uiDjuD8AA4EsYD/wO2fL6TgiEge8AjykqhVO1+OEUAiAUiC10fMUYJ9DtThKVfe5/5YBi2g4PBaqDohIbwD33zKH63GEqh5Q1TpVrQf+RIh8JkQkgoYv/3+q6qvuySH3mQiFAFgDDBKR/iISCUwBFjtcU4cTkVgR6XzmMXA1sPncrYLaYuBO9+M7gdcdrMUxZ77w3G4iBD4TIiLAX4Ctqvpko1kh95kIiSuB3V3bngJcwDxV/aXDJXU4ERlAw69+gHDgxVB5H0RkPjCehtv9HgD+C3gNWAj0BXYDt6hqUJ8gPcv7MJ6Gwz8K7ATuP3McPFiJyKXAB8AmoN49+VEazgOE1mciFALAGGPMl4XCISBjjDHNsAAwxpgQZQFgjDEhygLAGGNClAWAMcaEKAsAY4wJURYAxhgTov4/Jubs+fOyZEoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"plt.plot(f1_scores, label=\\\"F1 Scores\\\")\";\n",
       "                var nbb_formatted_code = \"plt.plot(f1_scores, label=\\\"F1 Scores\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(f1_scores, label=\"F1 Scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"# Save the iteration of the model where max F1 score is reached\\nmax_value = max(f1_scores)\\nmax_index = f1_scores.index(max_value)\\nprint(max_index)\";\n",
       "                var nbb_formatted_code = \"# Save the iteration of the model where max F1 score is reached\\nmax_value = max(f1_scores)\\nmax_index = f1_scores.index(max_value)\\nprint(max_index)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the iteration of the model where max F1 score is reached\n",
    "max_value = max(f1_scores)\n",
    "max_index = f1_scores.index(max_value)\n",
    "print(max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"# Save the iteration of the model where min loss is reached\\nmin_value = min(log_losses)\\nmin_index = log_losses.index(min_value)\\nprint(min_index)\";\n",
       "                var nbb_formatted_code = \"# Save the iteration of the model where min loss is reached\\nmin_value = min(log_losses)\\nmin_index = log_losses.index(min_value)\\nprint(min_index)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save the iteration of the model where min loss is reached\n",
    "min_value = min(log_losses)\n",
    "min_index = log_losses.index(min_value)\n",
    "print(min_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do only 1 iteration as baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"# Create copies of the data that can be overwritten in the function below\\nX_train_iter1 = X_train.copy()\\ny_train_iter1 = y_train.copy()\\nr_dev_iter1 = r_dev.copy()\";\n",
       "                var nbb_formatted_code = \"# Create copies of the data that can be overwritten in the function below\\nX_train_iter1 = X_train.copy()\\ny_train_iter1 = y_train.copy()\\nr_dev_iter1 = r_dev.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create copies of the data that can be overwritten in the function below\n",
    "X_train_iter1 = X_train.copy()\n",
    "y_train_iter1 = y_train.copy()\n",
    "r_dev_iter1 = r_dev.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Nr 1\n",
      "F1:  0.9088069264752435\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"# Add more scores that you want to track\\nf1_scores = []\\niterations = []\\n# log_losses = []\\n\\nfor iteration in range(1, 2):  # Change to how many iterrations you like\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    # Build logistic regression\\n    KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n        X_train_iter1, y_train_iter1\\n    )\\n    # KGB1 = RandomForestClassifier().fit(X_train_iter1, y_train_iter1)\\n\\n    # Scores\\n    f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\\\"weighted\\\")\\n    f1_scores.append(f1_stat)\\n    print(\\\"F1: \\\", f1_stat)\\n\\n    logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\\n    log_losses.append(logloss)\\n\\n    # Make predictions on the rejected data\\n    pred = KGB1.predict_proba(r_dev_iter1)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev_iter1.index.copy(),\\n    )\\n\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.05)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train_iter1 = pd.concat((y_train_iter1, certain2))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev_iter1[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train_iter1 = pd.concat((X_train_iter1, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev_iter1 = r_dev_iter1.drop(rows, axis=\\\"index\\\")\";\n",
       "                var nbb_formatted_code = \"# Add more scores that you want to track\\nf1_scores = []\\niterations = []\\n# log_losses = []\\n\\nfor iteration in range(1, 2):  # Change to how many iterrations you like\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    # Build logistic regression\\n    KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n        X_train_iter1, y_train_iter1\\n    )\\n    # KGB1 = RandomForestClassifier().fit(X_train_iter1, y_train_iter1)\\n\\n    # Scores\\n    f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\\\"weighted\\\")\\n    f1_scores.append(f1_stat)\\n    print(\\\"F1: \\\", f1_stat)\\n\\n    logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\\n    log_losses.append(logloss)\\n\\n    # Make predictions on the rejected data\\n    pred = KGB1.predict_proba(r_dev_iter1)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev_iter1.index.copy(),\\n    )\\n\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.05)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train_iter1 = pd.concat((y_train_iter1, certain2))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev_iter1[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train_iter1 = pd.concat((X_train_iter1, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev_iter1 = r_dev_iter1.drop(rows, axis=\\\"index\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add more scores that you want to track\n",
    "f1_scores = []\n",
    "iterations = []\n",
    "# log_losses = []\n",
    "\n",
    "for iteration in range(1, 2):  # Change to how many iterrations you like\n",
    "    print(\"Iteration Nr {}\".format(iteration))\n",
    "    # Build logistic regression\n",
    "    KGB1 = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(\n",
    "        X_train_iter1, y_train_iter1\n",
    "    )\n",
    "    # KGB1 = RandomForestClassifier().fit(X_train_iter1, y_train_iter1)\n",
    "\n",
    "    # Scores\n",
    "    f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\"weighted\")\n",
    "    f1_scores.append(f1_stat)\n",
    "    print(\"F1: \", f1_stat)\n",
    "\n",
    "    logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\n",
    "    log_losses.append(logloss)\n",
    "\n",
    "    # Make predictions on the rejected data\n",
    "    pred = KGB1.predict_proba(r_dev_iter1)[:, 1]\n",
    "    pred = pd.DataFrame(\n",
    "        data=pred,\n",
    "        columns=[\"target\"],\n",
    "        index=r_dev_iter1.index.copy(),\n",
    "    )\n",
    "\n",
    "    # Choose the most certain predictions\n",
    "    lq = pred[\"target\"].quantile(q=0.05)\n",
    "    uq = pred[\"target\"].quantile(q=0.95)\n",
    "    pred[\"certain\"] = pred[\"target\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\n",
    "\n",
    "    # If PD is high, apply default status\n",
    "    pred[\"target\"] = pred[\"target\"].apply(lambda x: 1 if (x > uq) else 0)\n",
    "\n",
    "    # Pick only the certain predictions and concatenate them to the dev set\n",
    "    # Y TRAIN\n",
    "    certain = pred[pred[\"certain\"] == 1]\n",
    "    certain2 = certain[\"target\"].to_frame()\n",
    "    y_train_iter1 = pd.concat((y_train_iter1, certain2))\n",
    "\n",
    "    # Get significant columns of the rejects based on index\n",
    "    certain_features = pd.merge(\n",
    "        certain[\"target\"],\n",
    "        r_dev_iter1[significant_columns],\n",
    "        how=\"inner\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    # X TRAIN\n",
    "    certain_features = certain_features.loc[:, certain_features.columns != \"target\"]\n",
    "    X_train_iter1 = pd.concat((X_train_iter1, certain_features))\n",
    "\n",
    "    # Remove certain columns from rejected data\n",
    "    rows = certain_features.index\n",
    "    r_dev_iter1 = r_dev_iter1.drop(rows, axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"def predict_rejects(model, r_dev):\\n    # Make predictions on the Train Rejects\\n    pred_test = model.predict_proba(r_dev)[:, 1]\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_dev.index.copy(),\\n    )\\n\\n    # Make binary predictions based on cutoff DR\\n    q1 = pred_test[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test[\\\"target\\\"] = pred_test[\\\"pred\\\"].apply(lambda x: 0 if (x < q1) else 1)\\n    pred_test = pred_test[\\\"target\\\"].to_frame()\\n\\n    # Add new rows to df\\n    y_train_new = pd.concat((y_train, pred_test))\\n    X_train_new = pd.concat((X_train, r_dev))\\n\\n    # Fit new model\\n    KGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n        X_train_new, y_train_new\\n    )\\n    #     KGB_baseline_new = RandomForestClassifier().fit(X_train_new, y_train_new)\\n    return KGB_baseline_new\";\n",
       "                var nbb_formatted_code = \"def predict_rejects(model, r_dev):\\n    # Make predictions on the Train Rejects\\n    pred_test = model.predict_proba(r_dev)[:, 1]\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_dev.index.copy(),\\n    )\\n\\n    # Make binary predictions based on cutoff DR\\n    q1 = pred_test[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test[\\\"target\\\"] = pred_test[\\\"pred\\\"].apply(lambda x: 0 if (x < q1) else 1)\\n    pred_test = pred_test[\\\"target\\\"].to_frame()\\n\\n    # Add new rows to df\\n    y_train_new = pd.concat((y_train, pred_test))\\n    X_train_new = pd.concat((X_train, r_dev))\\n\\n    # Fit new model\\n    KGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(\\n        X_train_new, y_train_new\\n    )\\n    #     KGB_baseline_new = RandomForestClassifier().fit(X_train_new, y_train_new)\\n    return KGB_baseline_new\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict_rejects(model, r_dev):\n",
    "    # Make predictions on the Train Rejects\n",
    "    pred_test = model.predict_proba(r_dev)[:, 1]\n",
    "    pred_test = pd.DataFrame(\n",
    "        data=pred_test,\n",
    "        columns=[\"pred\"],\n",
    "        index=r_dev.index.copy(),\n",
    "    )\n",
    "\n",
    "    # Make binary predictions based on cutoff DR\n",
    "    q1 = pred_test[\"pred\"].quantile(q=1 - conservative_dr)\n",
    "    pred_test[\"target\"] = pred_test[\"pred\"].apply(lambda x: 0 if (x < q1) else 1)\n",
    "    pred_test = pred_test[\"target\"].to_frame()\n",
    "\n",
    "    # Add new rows to df\n",
    "    y_train_new = pd.concat((y_train, pred_test))\n",
    "    X_train_new = pd.concat((X_train, r_dev))\n",
    "\n",
    "    # Fit new model\n",
    "    KGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(\n",
    "        X_train_new, y_train_new\n",
    "    )\n",
    "    #     KGB_baseline_new = RandomForestClassifier().fit(X_train_new, y_train_new)\n",
    "    return KGB_baseline_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"def evaluate_test_accepts(model, X_test):\\n    pred_test = model.predict_proba(X_test)[:, 1]\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=X_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_formatted_code = \"def evaluate_test_accepts(model, X_test):\\n    pred_test = model.predict_proba(X_test)[:, 1]\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=X_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_test_accepts(model, X_test):\n",
    "    pred_test = model.predict_proba(X_test)[:, 1]\n",
    "    pred_test = pd.DataFrame(\n",
    "        data=pred_test,\n",
    "        columns=[\"pred\"],\n",
    "        index=X_test.index.copy(),\n",
    "    )\n",
    "\n",
    "    # Merge with Target\n",
    "    pred_test2 = pd.merge(\n",
    "        pred_test[\"pred\"],\n",
    "        y_test[\"target\"],\n",
    "        how=\"inner\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    # Make binary predictions based on cutoff 50percentile of the distribution\n",
    "    q1 = pred_test2[\"pred\"].quantile(q=1 - conservative_dr)\n",
    "    pred_test2[\"prediction_baseline\"] = pred_test2[\"pred\"].apply(\n",
    "        lambda x: 0 if (x < q1) else 1\n",
    "    )\n",
    "    return pred_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"def evaluate_test_rejects(model, r_test):\\n    pred_test = model.predict_proba(r_test)[:, 1]\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_formatted_code = \"def evaluate_test_rejects(model, r_test):\\n    pred_test = model.predict_proba(r_test)[:, 1]\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_test_rejects(model, r_test):\n",
    "    pred_test = model.predict_proba(r_test)[:, 1]\n",
    "    pred_test = pd.DataFrame(\n",
    "        data=pred_test,\n",
    "        columns=[\"pred\"],\n",
    "        index=r_test.index.copy(),\n",
    "    )\n",
    "\n",
    "    # Merge with Target\n",
    "    pred_test2 = pd.merge(\n",
    "        pred_test[\"pred\"],\n",
    "        dfr_test_with_label[\"target\"],\n",
    "        how=\"inner\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    # Make binary predictions based on cutoff 50percentile of the distribution\n",
    "    q1 = pred_test2[\"pred\"].quantile(q=1 - conservative_dr)\n",
    "    pred_test2[\"prediction_baseline\"] = pred_test2[\"pred\"].apply(\n",
    "        lambda x: 0 if (x < q1) else 1\n",
    "    )\n",
    "    return pred_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"def flag_df_baseline(df):\\n\\n    # Flag kicked out bad cases (want more of these)\\n    if df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"CB\\\"\\n\\n    # Flag kicked out good cases (want less of these)\\n    elif df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"IB\\\"\\n\\n    # Flag kicked in good cases (want more of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"CG\\\"\\n\\n    # Flag kicked in bad cases (want less of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"IG\\\"\";\n",
       "                var nbb_formatted_code = \"def flag_df_baseline(df):\\n\\n    # Flag kicked out bad cases (want more of these)\\n    if df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"CB\\\"\\n\\n    # Flag kicked out good cases (want less of these)\\n    elif df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"IB\\\"\\n\\n    # Flag kicked in good cases (want more of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"CG\\\"\\n\\n    # Flag kicked in bad cases (want less of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"IG\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def flag_df_baseline(df):\n",
    "\n",
    "    # Flag kicked out bad cases (want more of these)\n",
    "    if df[\"target\"] == 1 and df[\"prediction_baseline\"] == 1:\n",
    "        return \"CB\"\n",
    "\n",
    "    # Flag kicked out good cases (want less of these)\n",
    "    elif df[\"target\"] == 1 and df[\"prediction_baseline\"] == 0:\n",
    "        return \"IB\"\n",
    "\n",
    "    # Flag kicked in good cases (want more of these)\n",
    "    elif df[\"target\"] == 0 and df[\"prediction_baseline\"] == 0:\n",
    "        return \"CG\"\n",
    "\n",
    "    # Flag kicked in bad cases (want less of these)\n",
    "    elif df[\"target\"] == 0 and df[\"prediction_baseline\"] == 1:\n",
    "        return \"IG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"def kickout_baseline(df):\\n\\n    # Counts of kickout bad and kickout good\\n    counts = df[\\\"Flag\\\"].value_counts()\\n    if \\\"CB\\\" in df.values:\\n        cb = counts.CB  # want more of these\\n    else:\\n        cb = 0\\n    if \\\"IB\\\" in df.values:\\n        ib = counts.IB  # want less of these\\n    else:\\n        ib = 0\\n\\n    if \\\"CG\\\" in df.values:\\n        cg = counts.CG  # want more of these\\n    else:\\n        cg = 0\\n\\n    if \\\"IG\\\" in df.values:\\n        ig = counts.IG  # want less of these\\n    else:\\n        ig = 0\\n\\n    # Target\\n    total_bads = df[df[\\\"target\\\"] == 1].shape[0]\\n    total_goods = df[df[\\\"target\\\"] == 0].shape[0]\\n    pb = total_bads / (total_bads + total_goods)\\n    pg = total_goods / (total_bads + total_goods)\\n\\n    kickout = (((cb / pb) - (ib / pb)) / total_bads) * (pb ** 2)\\n    kickin = (((cg / pg) - (ig / pg)) / total_goods) * (pg ** 2)\\n    weighted_total = kickout + kickin\\n    return weighted_total\";\n",
       "                var nbb_formatted_code = \"def kickout_baseline(df):\\n\\n    # Counts of kickout bad and kickout good\\n    counts = df[\\\"Flag\\\"].value_counts()\\n    if \\\"CB\\\" in df.values:\\n        cb = counts.CB  # want more of these\\n    else:\\n        cb = 0\\n    if \\\"IB\\\" in df.values:\\n        ib = counts.IB  # want less of these\\n    else:\\n        ib = 0\\n\\n    if \\\"CG\\\" in df.values:\\n        cg = counts.CG  # want more of these\\n    else:\\n        cg = 0\\n\\n    if \\\"IG\\\" in df.values:\\n        ig = counts.IG  # want less of these\\n    else:\\n        ig = 0\\n\\n    # Target\\n    total_bads = df[df[\\\"target\\\"] == 1].shape[0]\\n    total_goods = df[df[\\\"target\\\"] == 0].shape[0]\\n    pb = total_bads / (total_bads + total_goods)\\n    pg = total_goods / (total_bads + total_goods)\\n\\n    kickout = (((cb / pb) - (ib / pb)) / total_bads) * (pb ** 2)\\n    kickin = (((cg / pg) - (ig / pg)) / total_goods) * (pg ** 2)\\n    weighted_total = kickout + kickin\\n    return weighted_total\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def kickout_baseline(df):\n",
    "\n",
    "    # Counts of kickout bad and kickout good\n",
    "    counts = df[\"Flag\"].value_counts()\n",
    "    if \"CB\" in df.values:\n",
    "        cb = counts.CB  # want more of these\n",
    "    else:\n",
    "        cb = 0\n",
    "    if \"IB\" in df.values:\n",
    "        ib = counts.IB  # want less of these\n",
    "    else:\n",
    "        ib = 0\n",
    "\n",
    "    if \"CG\" in df.values:\n",
    "        cg = counts.CG  # want more of these\n",
    "    else:\n",
    "        cg = 0\n",
    "\n",
    "    if \"IG\" in df.values:\n",
    "        ig = counts.IG  # want less of these\n",
    "    else:\n",
    "        ig = 0\n",
    "\n",
    "    # Target\n",
    "    total_bads = df[df[\"target\"] == 1].shape[0]\n",
    "    total_goods = df[df[\"target\"] == 0].shape[0]\n",
    "    pb = total_bads / (total_bads + total_goods)\n",
    "    pg = total_goods / (total_bads + total_goods)\n",
    "\n",
    "    kickout = (((cb / pb) - (ib / pb)) / total_bads) * (pb ** 2)\n",
    "    kickin = (((cg / pg) - (ig / pg)) / total_goods) * (pg ** 2)\n",
    "    weighted_total = kickout + kickin\n",
    "    return weighted_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prediction before RI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: KGB Model ($m_{1}$)  <br>\n",
    "Step 2: Score Test Accepts and Test Rejects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"pred_test_a = evaluate_test_accepts(KGB1, X_test)\\npred_test_r = evaluate_test_rejects(KGB1, r_test)\";\n",
       "                var nbb_formatted_code = \"pred_test_a = evaluate_test_accepts(KGB1, X_test)\\npred_test_r = evaluate_test_rejects(KGB1, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a = evaluate_test_accepts(KGB1, X_test)\n",
    "pred_test_r = evaluate_test_rejects(KGB1, r_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_beforeRI = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_beforeRI = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a[\"Flag\"] = pred_test_a.apply(flag_df_baseline, axis=1)\n",
    "predictions_accepts_beforeRI = [round(kickout_baseline(pred_test_a).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_beforeRI = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_beforeRI = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_r[\"Flag\"] = pred_test_r.apply(flag_df_baseline, axis=1)\n",
    "predictions_rejects_beforeRI = [round(kickout_baseline(pred_test_r).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Predicions Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: KGB Model ($m_{1}$)  <br>\n",
    "Step 2: Infer status of each reject <br> \n",
    "Step 3: Redevelop KGB mdoel with inferred rejects ($m_{2}$)  <br>\n",
    "Step 4: Score Test Accepts and Test Rejects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"KGB_baseline_new = predict_rejects(KGB1, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\";\n",
       "                var nbb_formatted_code = \"KGB_baseline_new = predict_rejects(KGB1, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "KGB_baseline_new = predict_rejects(KGB1, r_dev)\n",
    "pred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\n",
    "pred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_base = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_base = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a[\"Flag\"] = pred_test_a.apply(flag_df_baseline, axis=1)\n",
    "predictions_accepts_base = [round(kickout_baseline(pred_test_a).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_base = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_base = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_r[\"Flag\"] = pred_test_r.apply(flag_df_baseline, axis=1)\n",
    "predictions_rejects_base = [round(kickout_baseline(pred_test_r).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain with the most optimal Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Nr 1\n",
      "F1:  0.9088069264752435\n",
      "Iteration Nr 2\n",
      "F1:  0.9088069264752435\n",
      "Iteration Nr 3\n",
      "F1:  0.9088069264752435\n",
      "Iteration Nr 4\n",
      "F1:  0.9088069264752435\n",
      "Iteration Nr 5\n",
      "F1:  0.9088177078673029\n",
      "Iteration Nr 6\n",
      "F1:  0.9084816896092619\n",
      "Iteration Nr 7\n",
      "F1:  0.9085027040432666\n",
      "Iteration Nr 8\n",
      "F1:  0.9102973456056371\n",
      "Iteration Nr 9\n",
      "F1:  0.9110008958361809\n",
      "Iteration Nr 10\n",
      "F1:  0.9127740182907681\n",
      "Iteration Nr 11\n",
      "F1:  0.9120986302859595\n",
      "Iteration Nr 12\n",
      "F1:  0.9117516302381724\n",
      "Iteration Nr 13\n",
      "F1:  0.9124638674320981\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Add more scores that you want to track\\nf1_scores = []\\niterations = []\\n# log_losses = []\\n\\nfor iteration in range(1, max_index + 1):  # Change to how many iterrations you like\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    # Build logistic regression\\n    KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train, y_train)\\n    # KGB1 = RandomForestClassifier().fit(X_train, y_train)\\n\\n    # Scores\\n    f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\\\"weighted\\\")\\n    f1_scores.append(f1_stat)\\n    print(\\\"F1: \\\", f1_stat)\\n\\n    logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\\n    log_losses.append(logloss)\\n\\n    # Make predictions on the rejected data\\n    pred = KGB1.predict_proba(r_dev)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev.index.copy(),\\n    )\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.05)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train = pd.concat((y_train, certain2))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train = pd.concat((X_train, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev = r_dev.drop(rows, axis=\\\"index\\\")\";\n",
       "                var nbb_formatted_code = \"# Add more scores that you want to track\\nf1_scores = []\\niterations = []\\n# log_losses = []\\n\\nfor iteration in range(1, max_index + 1):  # Change to how many iterrations you like\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    # Build logistic regression\\n    KGB1 = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train, y_train)\\n    # KGB1 = RandomForestClassifier().fit(X_train, y_train)\\n\\n    # Scores\\n    f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\\\"weighted\\\")\\n    f1_scores.append(f1_stat)\\n    print(\\\"F1: \\\", f1_stat)\\n\\n    logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\\n    log_losses.append(logloss)\\n\\n    # Make predictions on the rejected data\\n    pred = KGB1.predict_proba(r_dev)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev.index.copy(),\\n    )\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.05)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train = pd.concat((y_train, certain2))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train = pd.concat((X_train, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev = r_dev.drop(rows, axis=\\\"index\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add more scores that you want to track\n",
    "f1_scores = []\n",
    "iterations = []\n",
    "# log_losses = []\n",
    "\n",
    "for iteration in range(1, max_index + 1):  # Change to how many iterrations you like\n",
    "    print(\"Iteration Nr {}\".format(iteration))\n",
    "    # Build logistic regression\n",
    "    KGB1 = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(X_train, y_train)\n",
    "    # KGB1 = RandomForestClassifier().fit(X_train, y_train)\n",
    "\n",
    "    # Scores\n",
    "    f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\"weighted\")\n",
    "    f1_scores.append(f1_stat)\n",
    "    print(\"F1: \", f1_stat)\n",
    "\n",
    "    logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\n",
    "    log_losses.append(logloss)\n",
    "\n",
    "    # Make predictions on the rejected data\n",
    "    pred = KGB1.predict_proba(r_dev)[:, 1]\n",
    "    pred = pd.DataFrame(\n",
    "        data=pred,\n",
    "        columns=[\"target\"],\n",
    "        index=r_dev.index.copy(),\n",
    "    )\n",
    "    # Choose the most certain predictions\n",
    "    lq = pred[\"target\"].quantile(q=0.05)\n",
    "    uq = pred[\"target\"].quantile(q=0.95)\n",
    "    pred[\"certain\"] = pred[\"target\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\n",
    "\n",
    "    # If PD is high, apply default status\n",
    "    pred[\"target\"] = pred[\"target\"].apply(lambda x: 1 if (x > uq) else 0)\n",
    "\n",
    "    # Pick only the certain predictions and concatenate them to the dev set\n",
    "    # Y TRAIN\n",
    "    certain = pred[pred[\"certain\"] == 1]\n",
    "    certain2 = certain[\"target\"].to_frame()\n",
    "    y_train = pd.concat((y_train, certain2))\n",
    "\n",
    "    # Get significant columns of the rejects based on index\n",
    "    certain_features = pd.merge(\n",
    "        certain[\"target\"],\n",
    "        r_dev[significant_columns],\n",
    "        how=\"inner\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    # X TRAIN\n",
    "    certain_features = certain_features.loc[:, certain_features.columns != \"target\"]\n",
    "    X_train = pd.concat((X_train, certain_features))\n",
    "\n",
    "    # Remove certain columns from rejected data\n",
    "    rows = certain_features.index\n",
    "    r_dev = r_dev.drop(rows, axis=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. KGB model of best iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: KGB Model ($m_{1}$)  <br>\n",
    "Step 2: Infer status of each reject <br> \n",
    "Step 3: Choose the most certain predictions (0.05q and 0.95q of the predicted probailities) <br>\n",
    "Step 4: Add the most certain predictions to the training sample\n",
    "Step 5: Redevelop KGB Model ($m_{2}$)  <br>\n",
    "Step 6: Repeat Step 5 until convergence - best F1 score ($m_{i}$)  <br> \n",
    "Step 7: Score Test Accepts and Test Rejects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"pred_test_a = evaluate_test_accepts(KGB1, X_test)\\npred_test_r = evaluate_test_rejects(KGB1, r_test)\";\n",
       "                var nbb_formatted_code = \"pred_test_a = evaluate_test_accepts(KGB1, X_test)\\npred_test_r = evaluate_test_rejects(KGB1, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a = evaluate_test_accepts(KGB1, X_test)\n",
    "pred_test_r = evaluate_test_rejects(KGB1, r_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_iter = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_iter = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a[\"Flag\"] = pred_test_a.apply(flag_df_baseline, axis=1)\n",
    "predictions_accepts_iter = [round(kickout_baseline(pred_test_a).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_iter = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_iter = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_r[\"Flag\"] = pred_test_r.apply(flag_df_baseline, axis=1)\n",
    "predictions_rejects_iter = [round(kickout_baseline(pred_test_r).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. New model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: KGB Model ($m_{1}$)  <br>\n",
    "Step 2: Infer status of each reject <br> \n",
    "Step 3: Choose the most certain predictions (0.05q and 0.95q of the predicted probailities) <br>\n",
    "Step 4: Add the most certain predictions to the training sample <br>\n",
    "Step 5: Redevelop KGB Model ($m_{2}$)  <br>\n",
    "Step 6: Repeat Step 5 until convergence - best F1 score ($m_{i}$) <br> \n",
    "Step 7: Infer status of each reject with ($m_{i}$) <br> \n",
    "Step 8: Redevelop KGB mdoel with inferred rejects ($m_{final}$) <br> \n",
    "Step 9: Score Test Accepts and Test Rejects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"KGB_baseline_new = predict_rejects(KGB1, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\";\n",
       "                var nbb_formatted_code = \"KGB_baseline_new = predict_rejects(KGB1, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "KGB_baseline_new = predict_rejects(KGB1, r_dev)\n",
    "pred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\n",
    "pred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_new = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_new = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a[\"Flag\"] = pred_test_a.apply(flag_df_baseline, axis=1)\n",
    "predictions_accepts_new = [round(kickout_baseline(pred_test_a).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_new = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_new = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_r[\"Flag\"] = pred_test_r.apply(flag_df_baseline, axis=1)\n",
    "predictions_rejects_new = [round(kickout_baseline(pred_test_r).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"my_list_accepts = [\\n    predictions_accepts_beforeRI,\\n    predictions_accepts_base,\\n    predictions_accepts_iter,\\n    predictions_accepts_new,\\n]\\ndf_pred_accepts = pd.DataFrame(my_list_accepts).transpose()\\ndf_pred_accepts = df_pred_accepts.rename(\\n    columns={0: \\\"Before RI\\\", 1: \\\"Baseline\\\", 2: \\\"Iteration n\\\", 3: \\\"Self-Training\\\"},\\n)\";\n",
       "                var nbb_formatted_code = \"my_list_accepts = [\\n    predictions_accepts_beforeRI,\\n    predictions_accepts_base,\\n    predictions_accepts_iter,\\n    predictions_accepts_new,\\n]\\ndf_pred_accepts = pd.DataFrame(my_list_accepts).transpose()\\ndf_pred_accepts = df_pred_accepts.rename(\\n    columns={0: \\\"Before RI\\\", 1: \\\"Baseline\\\", 2: \\\"Iteration n\\\", 3: \\\"Self-Training\\\"},\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_list_accepts = [\n",
    "    predictions_accepts_beforeRI,\n",
    "    predictions_accepts_base,\n",
    "    predictions_accepts_iter,\n",
    "    predictions_accepts_new,\n",
    "]\n",
    "df_pred_accepts = pd.DataFrame(my_list_accepts).transpose()\n",
    "df_pred_accepts = df_pred_accepts.rename(\n",
    "    columns={0: \"Before RI\", 1: \"Baseline\", 2: \"Iteration n\", 3: \"Self-Training\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"my_list_rejects = [\\n    predictions_rejects_beforeRI,\\n    predictions_rejects_base,\\n    predictions_rejects_iter,\\n    predictions_rejects_new,\\n]\\ndf_pred_rejects = pd.DataFrame(my_list_rejects).transpose()\\ndf_pred_rejects = df_pred_rejects.rename(\\n    columns={0: \\\"Before RI\\\", 1: \\\"Baseline\\\", 2: \\\"Iteration n\\\", 3: \\\"Self-Training\\\"},\\n)\";\n",
       "                var nbb_formatted_code = \"my_list_rejects = [\\n    predictions_rejects_beforeRI,\\n    predictions_rejects_base,\\n    predictions_rejects_iter,\\n    predictions_rejects_new,\\n]\\ndf_pred_rejects = pd.DataFrame(my_list_rejects).transpose()\\ndf_pred_rejects = df_pred_rejects.rename(\\n    columns={0: \\\"Before RI\\\", 1: \\\"Baseline\\\", 2: \\\"Iteration n\\\", 3: \\\"Self-Training\\\"},\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_list_rejects = [\n",
    "    predictions_rejects_beforeRI,\n",
    "    predictions_rejects_base,\n",
    "    predictions_rejects_iter,\n",
    "    predictions_rejects_new,\n",
    "]\n",
    "df_pred_rejects = pd.DataFrame(my_list_rejects).transpose()\n",
    "df_pred_rejects = df_pred_rejects.rename(\n",
    "    columns={0: \"Before RI\", 1: \"Baseline\", 2: \"Iteration n\", 3: \"Self-Training\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Before RI</th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Iteration n</th>\n",
       "      <th>Self-Training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Before RI  Baseline  Iteration n  Self-Training\n",
       "0      0.838     0.852        0.846          0.859"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"df_pred_accepts\";\n",
       "                var nbb_formatted_code = \"df_pred_accepts\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_pred_accepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Before RI</th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Iteration n</th>\n",
       "      <th>Self-Training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.772</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Before RI  Baseline  Iteration n  Self-Training\n",
       "0      0.772     0.775        0.772          0.778"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"df_pred_rejects\";\n",
       "                var nbb_formatted_code = \"df_pred_rejects\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_pred_rejects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parcelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 123;\n",
       "                var nbb_unformatted_code = \"# Create copies of the dataframes\\nX_train_parc = X_train.copy()\\ny_train_parc = y_train.copy()\";\n",
       "                var nbb_formatted_code = \"# Create copies of the dataframes\\nX_train_parc = X_train.copy()\\ny_train_parc = y_train.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create copies of the dataframes\n",
    "X_train_parc = X_train.copy()\n",
    "y_train_parc = y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9124638674320981"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 124;\n",
       "                var nbb_unformatted_code = \"# Check how well known_col_0 discriminates goods and bads. Use as \\\"score\\\"\\nreg1 = LogisticRegression(fit_intercept=True, penalty=\\\"none\\\").fit(\\n    X_train_parc[[\\\"known_col_0\\\"]], y_train_parc\\n)\\nf1_score(y_test, KGB1.predict(X_test), average=\\\"weighted\\\")\";\n",
       "                var nbb_formatted_code = \"# Check how well known_col_0 discriminates goods and bads. Use as \\\"score\\\"\\nreg1 = LogisticRegression(fit_intercept=True, penalty=\\\"none\\\").fit(\\n    X_train_parc[[\\\"known_col_0\\\"]], y_train_parc\\n)\\nf1_score(y_test, KGB1.predict(X_test), average=\\\"weighted\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check how well known_col_0 discriminates goods and bads. Use as \"score\"\n",
    "reg1 = LogisticRegression(fit_intercept=True, penalty=\"none\").fit(\n",
    "    X_train_parc[[\"known_col_0\"]], y_train_parc\n",
    ")\n",
    "f1_score(y_test, KGB1.predict(X_test), average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 125;\n",
       "                var nbb_unformatted_code = \"# Create 10 score bands\\nX_train_parc[\\\"score_band\\\"] = pd.qcut(X_train_parc[\\\"known_col_0\\\"].values, 10)\\nX_train_parc[\\\"nr_band\\\"] = pd.qcut(X_train_parc[\\\"known_col_0\\\"].values, 10, labels=False)\";\n",
       "                var nbb_formatted_code = \"# Create 10 score bands\\nX_train_parc[\\\"score_band\\\"] = pd.qcut(X_train_parc[\\\"known_col_0\\\"].values, 10)\\nX_train_parc[\\\"nr_band\\\"] = pd.qcut(X_train_parc[\\\"known_col_0\\\"].values, 10, labels=False)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create 10 score bands\n",
    "X_train_parc[\"score_band\"] = pd.qcut(X_train_parc[\"known_col_0\"].values, 10)\n",
    "X_train_parc[\"nr_band\"] = pd.qcut(X_train_parc[\"known_col_0\"].values, 10, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 126;\n",
       "                var nbb_unformatted_code = \"# Attach target\\ndf = pd.merge(\\n    X_train_parc,\\n    y_train_parc,\\n    how=\\\"inner\\\",\\n    left_index=True,\\n    right_index=True,\\n)\";\n",
       "                var nbb_formatted_code = \"# Attach target\\ndf = pd.merge(\\n    X_train_parc,\\n    y_train_parc,\\n    how=\\\"inner\\\",\\n    left_index=True,\\n    right_index=True,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Attach target\n",
    "df = pd.merge(\n",
    "    X_train_parc,\n",
    "    y_train_parc,\n",
    "    how=\"inner\",\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 127;\n",
       "                var nbb_unformatted_code = \"# Select rows with target = 1\\ndf_bad = df[df[\\\"target\\\"] == 1]\\n# Select rows with target = 0\\ndf_good = df[df[\\\"target\\\"] == 0]\";\n",
       "                var nbb_formatted_code = \"# Select rows with target = 1\\ndf_bad = df[df[\\\"target\\\"] == 1]\\n# Select rows with target = 0\\ndf_good = df[df[\\\"target\\\"] == 0]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select rows with target = 1\n",
    "df_bad = df[df[\"target\"] == 1]\n",
    "# Select rows with target = 0\n",
    "df_good = df[df[\"target\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 128;\n",
       "                var nbb_unformatted_code = \"# Count nr of bads in each interval\\ndf_bad = df_bad.groupby(\\\"nr_band\\\").size().sort_values().reset_index(name=\\\"nr_bad\\\")\\ndf_good = df_good.groupby(\\\"nr_band\\\").size().sort_values().reset_index(name=\\\"nr_good\\\")\";\n",
       "                var nbb_formatted_code = \"# Count nr of bads in each interval\\ndf_bad = df_bad.groupby(\\\"nr_band\\\").size().sort_values().reset_index(name=\\\"nr_bad\\\")\\ndf_good = df_good.groupby(\\\"nr_band\\\").size().sort_values().reset_index(name=\\\"nr_good\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count nr of bads in each interval\n",
    "df_bad = df_bad.groupby(\"nr_band\").size().sort_values().reset_index(name=\"nr_bad\")\n",
    "df_good = df_good.groupby(\"nr_band\").size().sort_values().reset_index(name=\"nr_good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 129;\n",
       "                var nbb_unformatted_code = \"# Merge counts with original data\\ndf = pd.merge(df, df_bad, on=\\\"nr_band\\\")\\ndf = pd.merge(df, df_good, on=\\\"nr_band\\\")\";\n",
       "                var nbb_formatted_code = \"# Merge counts with original data\\ndf = pd.merge(df, df_bad, on=\\\"nr_band\\\")\\ndf = pd.merge(df, df_good, on=\\\"nr_band\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Merge counts with original data\n",
    "df = pd.merge(df, df_bad, on=\"nr_band\")\n",
    "df = pd.merge(df, df_good, on=\"nr_band\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 130;\n",
       "                var nbb_unformatted_code = \"#Calculate %good and %bads\\ndf[\\\"perc_good\\\"] = df[\\\"nr_good\\\"] / (df[\\\"nr_bad\\\"] + df[\\\"nr_good\\\"])\\ndf[\\\"perc_bad\\\"] = df[\\\"nr_bad\\\"] / (df[\\\"nr_bad\\\"] + df[\\\"nr_good\\\"])\";\n",
       "                var nbb_formatted_code = \"# Calculate %good and %bads\\ndf[\\\"perc_good\\\"] = df[\\\"nr_good\\\"] / (df[\\\"nr_bad\\\"] + df[\\\"nr_good\\\"])\\ndf[\\\"perc_bad\\\"] = df[\\\"nr_bad\\\"] / (df[\\\"nr_bad\\\"] + df[\\\"nr_good\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate %good and %bads\n",
    "df[\"perc_good\"] = df[\"nr_good\"] / (df[\"nr_bad\"] + df[\"nr_good\"])\n",
    "df[\"perc_bad\"] = df[\"nr_bad\"] / (df[\"nr_bad\"] + df[\"nr_good\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>known_col_0</th>\n",
       "      <th>known_col_1</th>\n",
       "      <th>known_col_3</th>\n",
       "      <th>known_col_4</th>\n",
       "      <th>score_band</th>\n",
       "      <th>nr_band</th>\n",
       "      <th>target</th>\n",
       "      <th>nr_bad</th>\n",
       "      <th>nr_good</th>\n",
       "      <th>perc_good</th>\n",
       "      <th>perc_bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.944822</td>\n",
       "      <td>-0.240138</td>\n",
       "      <td>0.285049</td>\n",
       "      <td>-1.993493</td>\n",
       "      <td>(-1.268, -0.829]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>721</td>\n",
       "      <td>758</td>\n",
       "      <td>0.512508</td>\n",
       "      <td>0.487492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>-2.612345</td>\n",
       "      <td>-0.372248</td>\n",
       "      <td>-0.411668</td>\n",
       "      <td>0.436406</td>\n",
       "      <td>(-4.1160000000000005, -1.268]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>679</td>\n",
       "      <td>0.459094</td>\n",
       "      <td>0.540906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>-0.259003</td>\n",
       "      <td>0.369006</td>\n",
       "      <td>0.900240</td>\n",
       "      <td>-0.403319</td>\n",
       "      <td>(-0.524, -0.247]</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>610</td>\n",
       "      <td>869</td>\n",
       "      <td>0.587559</td>\n",
       "      <td>0.412441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4437</th>\n",
       "      <td>1.849853</td>\n",
       "      <td>-1.057181</td>\n",
       "      <td>-0.474643</td>\n",
       "      <td>-0.582006</td>\n",
       "      <td>(1.297, 3.785]</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>349</td>\n",
       "      <td>1130</td>\n",
       "      <td>0.764030</td>\n",
       "      <td>0.235970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>0.183180</td>\n",
       "      <td>1.588939</td>\n",
       "      <td>-0.533480</td>\n",
       "      <td>0.422861</td>\n",
       "      <td>(0.00533, 0.262]</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>552</td>\n",
       "      <td>927</td>\n",
       "      <td>0.626775</td>\n",
       "      <td>0.373225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7395</th>\n",
       "      <td>0.790355</td>\n",
       "      <td>0.916692</td>\n",
       "      <td>-1.032540</td>\n",
       "      <td>-1.857653</td>\n",
       "      <td>(0.541, 0.839]</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>508</td>\n",
       "      <td>971</td>\n",
       "      <td>0.656525</td>\n",
       "      <td>0.343475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8874</th>\n",
       "      <td>-0.016423</td>\n",
       "      <td>-1.609411</td>\n",
       "      <td>1.324772</td>\n",
       "      <td>-0.101787</td>\n",
       "      <td>(-0.247, 0.00533]</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>612</td>\n",
       "      <td>866</td>\n",
       "      <td>0.585927</td>\n",
       "      <td>0.414073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10352</th>\n",
       "      <td>0.539017</td>\n",
       "      <td>-0.108287</td>\n",
       "      <td>0.294958</td>\n",
       "      <td>-2.054015</td>\n",
       "      <td>(0.262, 0.541]</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>517</td>\n",
       "      <td>961</td>\n",
       "      <td>0.650203</td>\n",
       "      <td>0.349797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11830</th>\n",
       "      <td>0.892448</td>\n",
       "      <td>1.821076</td>\n",
       "      <td>0.634689</td>\n",
       "      <td>0.263463</td>\n",
       "      <td>(0.839, 1.297]</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>459</td>\n",
       "      <td>1019</td>\n",
       "      <td>0.689445</td>\n",
       "      <td>0.310555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13308</th>\n",
       "      <td>-0.528900</td>\n",
       "      <td>0.054191</td>\n",
       "      <td>-0.618012</td>\n",
       "      <td>-0.635613</td>\n",
       "      <td>(-0.829, -0.524]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>631</td>\n",
       "      <td>847</td>\n",
       "      <td>0.573072</td>\n",
       "      <td>0.426928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       known_col_0  known_col_1  known_col_3  known_col_4  \\\n",
       "0        -0.944822    -0.240138     0.285049    -1.993493   \n",
       "1479     -2.612345    -0.372248    -0.411668     0.436406   \n",
       "2958     -0.259003     0.369006     0.900240    -0.403319   \n",
       "4437      1.849853    -1.057181    -0.474643    -0.582006   \n",
       "5916      0.183180     1.588939    -0.533480     0.422861   \n",
       "7395      0.790355     0.916692    -1.032540    -1.857653   \n",
       "8874     -0.016423    -1.609411     1.324772    -0.101787   \n",
       "10352     0.539017    -0.108287     0.294958    -2.054015   \n",
       "11830     0.892448     1.821076     0.634689     0.263463   \n",
       "13308    -0.528900     0.054191    -0.618012    -0.635613   \n",
       "\n",
       "                          score_band  nr_band  target  nr_bad  nr_good  \\\n",
       "0                   (-1.268, -0.829]        1       0     721      758   \n",
       "1479   (-4.1160000000000005, -1.268]        0       1     800      679   \n",
       "2958                (-0.524, -0.247]        3       0     610      869   \n",
       "4437                  (1.297, 3.785]        9       0     349     1130   \n",
       "5916                (0.00533, 0.262]        5       1     552      927   \n",
       "7395                  (0.541, 0.839]        7       0     508      971   \n",
       "8874               (-0.247, 0.00533]        4       0     612      866   \n",
       "10352                 (0.262, 0.541]        6       0     517      961   \n",
       "11830                 (0.839, 1.297]        8       1     459     1019   \n",
       "13308               (-0.829, -0.524]        2       1     631      847   \n",
       "\n",
       "       perc_good  perc_bad  \n",
       "0       0.512508  0.487492  \n",
       "1479    0.459094  0.540906  \n",
       "2958    0.587559  0.412441  \n",
       "4437    0.764030  0.235970  \n",
       "5916    0.626775  0.373225  \n",
       "7395    0.656525  0.343475  \n",
       "8874    0.585927  0.414073  \n",
       "10352   0.650203  0.349797  \n",
       "11830   0.689445  0.310555  \n",
       "13308   0.573072  0.426928  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 131;\n",
       "                var nbb_unformatted_code = \"#Get distinct score bands\\ndf.drop_duplicates(subset=[\\\"score_band\\\"])\";\n",
       "                var nbb_formatted_code = \"# Get distinct score bands\\ndf.drop_duplicates(subset=[\\\"score_band\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get distinct score bands\n",
    "df.drop_duplicates(subset=[\"score_band\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 132;\n",
       "                var nbb_unformatted_code = \"# make a copy of the r_dev data\\nr_dev_parc = r_dev.copy()\";\n",
       "                var nbb_formatted_code = \"# make a copy of the r_dev data\\nr_dev_parc = r_dev.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make a copy of the r_dev data\n",
    "r_dev_parc = r_dev.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 133;\n",
       "                var nbb_unformatted_code = \"def rej_scoring(x):\\n    if x <= -1.268:\\n        return 0\\n    elif x > -1.268 and x <= -0.829:\\n        return 1\\n    elif x > -0.829 and x <= -0.524:\\n        return 2\\n    elif x > -0.524 and x <= -0.247:\\n        return 3\\n    elif x > -0.247 and x <= 0.00533:\\n        return 4\\n    elif x > 0.00533 and x <= 0.262:\\n        return 5\\n    elif x > 0.262 and x <= 0.541:\\n        return 6\\n    elif x > 0.541 and x <= 0.839:\\n        return 7\\n    elif x > 0.839 and x <= 1.297:\\n        return 8\\n    elif x > 1.297:\\n        return 9\";\n",
       "                var nbb_formatted_code = \"def rej_scoring(x):\\n    if x <= -1.268:\\n        return 0\\n    elif x > -1.268 and x <= -0.829:\\n        return 1\\n    elif x > -0.829 and x <= -0.524:\\n        return 2\\n    elif x > -0.524 and x <= -0.247:\\n        return 3\\n    elif x > -0.247 and x <= 0.00533:\\n        return 4\\n    elif x > 0.00533 and x <= 0.262:\\n        return 5\\n    elif x > 0.262 and x <= 0.541:\\n        return 6\\n    elif x > 0.541 and x <= 0.839:\\n        return 7\\n    elif x > 0.839 and x <= 1.297:\\n        return 8\\n    elif x > 1.297:\\n        return 9\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def rej_scoring(x):\n",
    "    if x <= -1.268:\n",
    "        return 0\n",
    "    elif x > -1.268 and x <= -0.829:\n",
    "        return 1\n",
    "    elif x > -0.829 and x <= -0.524:\n",
    "        return 2\n",
    "    elif x > -0.524 and x <= -0.247:\n",
    "        return 3\n",
    "    elif x > -0.247 and x <= 0.00533:\n",
    "        return 4\n",
    "    elif x > 0.00533 and x <= 0.262:\n",
    "        return 5\n",
    "    elif x > 0.262 and x <= 0.541:\n",
    "        return 6\n",
    "    elif x > 0.541 and x <= 0.839:\n",
    "        return 7\n",
    "    elif x > 0.839 and x <= 1.297:\n",
    "        return 8\n",
    "    elif x > 1.297:\n",
    "        return 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 134;\n",
       "                var nbb_unformatted_code = \"# Apply these scores to the rejects\\nr_dev_parc[\\\"nr_band\\\"] = r_dev_parc[\\\"known_col_0\\\"].apply(rej_scoring)\";\n",
       "                var nbb_formatted_code = \"# Apply these scores to the rejects\\nr_dev_parc[\\\"nr_band\\\"] = r_dev_parc[\\\"known_col_0\\\"].apply(rej_scoring)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply these scores to the rejects\n",
    "r_dev_parc[\"nr_band\"] = r_dev_parc[\"known_col_0\"].apply(rej_scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 139;\n",
       "                var nbb_unformatted_code = \"# Count number of rejects in each band\\nr_dev_parc = (\\n    r_dev_parc.groupby(\\\"nr_band\\\").size().sort_values().reset_index(name=\\\"nr_rejects\\\")\\n)\";\n",
       "                var nbb_formatted_code = \"# Count number of rejects in each band\\nr_dev_parc = (\\n    r_dev_parc.groupby(\\\"nr_band\\\").size().sort_values().reset_index(name=\\\"nr_rejects\\\")\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count number of rejects in each band\n",
    "r_dev_parc = (\n",
    "    r_dev_parc.groupby(\"nr_band\").size().sort_values().reset_index(name=\"nr_rejects\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 140;\n",
       "                var nbb_unformatted_code = \"# attach rej. counts to original data\\ndf = pd.merge(df, r_dev_parc, on=\\\"nr_band\\\")\";\n",
       "                var nbb_formatted_code = \"# attach rej. counts to original data\\ndf = pd.merge(df, r_dev_parc, on=\\\"nr_band\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# attach rej. counts to original data\n",
    "df = pd.merge(df, r_dev_parc, on=\"nr_band\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 148;\n",
       "                var nbb_unformatted_code = \"# infer nr rejects\\ndf[\\\"inf_good\\\"] = round((df[\\\"nr_rejects\\\"] * df[\\\"perc_good\\\"]), 0)\\ndf[\\\"inf_bad\\\"] = round((df[\\\"nr_rejects\\\"] * df[\\\"perc_bad\\\"]), 0)\";\n",
       "                var nbb_formatted_code = \"# infer nr rejects\\ndf[\\\"inf_good\\\"] = round((df[\\\"nr_rejects\\\"] * df[\\\"perc_good\\\"]), 0)\\ndf[\\\"inf_bad\\\"] = round((df[\\\"nr_rejects\\\"] * df[\\\"perc_bad\\\"]), 0)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# infer nr rejects\n",
    "df[\"inf_good\"] = round((df[\"nr_rejects\"] * df[\"perc_good\"]), 0)\n",
    "df[\"inf_bad\"] = round((df[\"nr_rejects\"] * df[\"perc_bad\"]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 151;\n",
       "                var nbb_unformatted_code = \"#Augmentation factor\\n#Drop duplicates\\ndf[\\\"aug_factor\\\"] = (df[\\\"nr_bad\\\"] + df[\\\"nr_good\\\"] + df[\\\"nr_rejects\\\"]) / (df[\\\"nr_good\\\"] + df[\\\"nr_bad\\\"])\";\n",
       "                var nbb_formatted_code = \"# Augmentation factor\\n# Drop duplicates\\ndf[\\\"aug_factor\\\"] = (df[\\\"nr_bad\\\"] + df[\\\"nr_good\\\"] + df[\\\"nr_rejects\\\"]) / (\\n    df[\\\"nr_good\\\"] + df[\\\"nr_bad\\\"]\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Augmentation factor\n",
    "# Drop duplicates\n",
    "df[\"aug_factor\"] = (df[\"nr_bad\"] + df[\"nr_good\"] + df[\"nr_rejects\"]) / (\n",
    "    df[\"nr_good\"] + df[\"nr_bad\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 157;\n",
       "                var nbb_unformatted_code = \"# Create Augmented nr of good and bad\\ndf[\\\"inf_bad_aug\\\"] = round((df[\\\"inf_bad\\\"] * df[\\\"aug_factor\\\"]), 0)\\ndf[\\\"inf_good_aug\\\"] = round((df[\\\"nr_rejects\\\"] - df[\\\"inf_bad_aug\\\"]),0)\";\n",
       "                var nbb_formatted_code = \"# Create Augmented nr of good and bad\\ndf[\\\"inf_bad_aug\\\"] = round((df[\\\"inf_bad\\\"] * df[\\\"aug_factor\\\"]), 0)\\ndf[\\\"inf_good_aug\\\"] = round((df[\\\"nr_rejects\\\"] - df[\\\"inf_bad_aug\\\"]), 0)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Augmented nr of good and bad\n",
    "df[\"inf_bad_aug\"] = round((df[\"inf_bad\"] * df[\"aug_factor\"]), 0)\n",
    "df[\"inf_good_aug\"] = round((df[\"nr_rejects\"] - df[\"inf_bad_aug\"]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>known_col_0</th>\n",
       "      <th>known_col_1</th>\n",
       "      <th>known_col_3</th>\n",
       "      <th>known_col_4</th>\n",
       "      <th>score_band</th>\n",
       "      <th>nr_band</th>\n",
       "      <th>target</th>\n",
       "      <th>nr_bad</th>\n",
       "      <th>nr_good</th>\n",
       "      <th>perc_good</th>\n",
       "      <th>perc_bad</th>\n",
       "      <th>nr_rejects</th>\n",
       "      <th>inf_good</th>\n",
       "      <th>inf_bad</th>\n",
       "      <th>aug_factor</th>\n",
       "      <th>inf_bad_aug</th>\n",
       "      <th>inf_good_aug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.944822</td>\n",
       "      <td>-0.240138</td>\n",
       "      <td>0.285049</td>\n",
       "      <td>-1.993493</td>\n",
       "      <td>(-1.268, -0.829]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>721</td>\n",
       "      <td>758</td>\n",
       "      <td>0.512508</td>\n",
       "      <td>0.487492</td>\n",
       "      <td>113</td>\n",
       "      <td>58.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.076403</td>\n",
       "      <td>59.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.838393</td>\n",
       "      <td>-0.150394</td>\n",
       "      <td>-0.409478</td>\n",
       "      <td>-0.402316</td>\n",
       "      <td>(-1.268, -0.829]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>721</td>\n",
       "      <td>758</td>\n",
       "      <td>0.512508</td>\n",
       "      <td>0.487492</td>\n",
       "      <td>113</td>\n",
       "      <td>58.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.076403</td>\n",
       "      <td>59.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.902046</td>\n",
       "      <td>-2.704205</td>\n",
       "      <td>-0.511118</td>\n",
       "      <td>0.462726</td>\n",
       "      <td>(-1.268, -0.829]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>721</td>\n",
       "      <td>758</td>\n",
       "      <td>0.512508</td>\n",
       "      <td>0.487492</td>\n",
       "      <td>113</td>\n",
       "      <td>58.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.076403</td>\n",
       "      <td>59.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.078478</td>\n",
       "      <td>0.063843</td>\n",
       "      <td>1.583356</td>\n",
       "      <td>-0.265584</td>\n",
       "      <td>(-1.268, -0.829]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>721</td>\n",
       "      <td>758</td>\n",
       "      <td>0.512508</td>\n",
       "      <td>0.487492</td>\n",
       "      <td>113</td>\n",
       "      <td>58.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.076403</td>\n",
       "      <td>59.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.250110</td>\n",
       "      <td>0.040604</td>\n",
       "      <td>-0.262188</td>\n",
       "      <td>0.321271</td>\n",
       "      <td>(-1.268, -0.829]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>721</td>\n",
       "      <td>758</td>\n",
       "      <td>0.512508</td>\n",
       "      <td>0.487492</td>\n",
       "      <td>113</td>\n",
       "      <td>58.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.076403</td>\n",
       "      <td>59.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14781</th>\n",
       "      <td>-0.731921</td>\n",
       "      <td>-0.321889</td>\n",
       "      <td>-0.991577</td>\n",
       "      <td>1.502822</td>\n",
       "      <td>(-0.829, -0.524]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>631</td>\n",
       "      <td>847</td>\n",
       "      <td>0.573072</td>\n",
       "      <td>0.426928</td>\n",
       "      <td>117</td>\n",
       "      <td>67.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.079161</td>\n",
       "      <td>54.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14782</th>\n",
       "      <td>-0.573681</td>\n",
       "      <td>0.043831</td>\n",
       "      <td>0.687113</td>\n",
       "      <td>0.180703</td>\n",
       "      <td>(-0.829, -0.524]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>631</td>\n",
       "      <td>847</td>\n",
       "      <td>0.573072</td>\n",
       "      <td>0.426928</td>\n",
       "      <td>117</td>\n",
       "      <td>67.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.079161</td>\n",
       "      <td>54.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14783</th>\n",
       "      <td>-0.660596</td>\n",
       "      <td>-0.886881</td>\n",
       "      <td>-0.188630</td>\n",
       "      <td>1.519148</td>\n",
       "      <td>(-0.829, -0.524]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>631</td>\n",
       "      <td>847</td>\n",
       "      <td>0.573072</td>\n",
       "      <td>0.426928</td>\n",
       "      <td>117</td>\n",
       "      <td>67.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.079161</td>\n",
       "      <td>54.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14784</th>\n",
       "      <td>-0.539036</td>\n",
       "      <td>-0.003175</td>\n",
       "      <td>0.209170</td>\n",
       "      <td>1.672235</td>\n",
       "      <td>(-0.829, -0.524]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>631</td>\n",
       "      <td>847</td>\n",
       "      <td>0.573072</td>\n",
       "      <td>0.426928</td>\n",
       "      <td>117</td>\n",
       "      <td>67.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.079161</td>\n",
       "      <td>54.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14785</th>\n",
       "      <td>-0.672418</td>\n",
       "      <td>0.355935</td>\n",
       "      <td>0.070921</td>\n",
       "      <td>0.749058</td>\n",
       "      <td>(-0.829, -0.524]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>631</td>\n",
       "      <td>847</td>\n",
       "      <td>0.573072</td>\n",
       "      <td>0.426928</td>\n",
       "      <td>117</td>\n",
       "      <td>67.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.079161</td>\n",
       "      <td>54.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14786 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       known_col_0  known_col_1  known_col_3  known_col_4        score_band  \\\n",
       "0        -0.944822    -0.240138     0.285049    -1.993493  (-1.268, -0.829]   \n",
       "1        -0.838393    -0.150394    -0.409478    -0.402316  (-1.268, -0.829]   \n",
       "2        -0.902046    -2.704205    -0.511118     0.462726  (-1.268, -0.829]   \n",
       "3        -1.078478     0.063843     1.583356    -0.265584  (-1.268, -0.829]   \n",
       "4        -1.250110     0.040604    -0.262188     0.321271  (-1.268, -0.829]   \n",
       "...            ...          ...          ...          ...               ...   \n",
       "14781    -0.731921    -0.321889    -0.991577     1.502822  (-0.829, -0.524]   \n",
       "14782    -0.573681     0.043831     0.687113     0.180703  (-0.829, -0.524]   \n",
       "14783    -0.660596    -0.886881    -0.188630     1.519148  (-0.829, -0.524]   \n",
       "14784    -0.539036    -0.003175     0.209170     1.672235  (-0.829, -0.524]   \n",
       "14785    -0.672418     0.355935     0.070921     0.749058  (-0.829, -0.524]   \n",
       "\n",
       "       nr_band  target  nr_bad  nr_good  perc_good  perc_bad  nr_rejects  \\\n",
       "0            1       0     721      758   0.512508  0.487492         113   \n",
       "1            1       0     721      758   0.512508  0.487492         113   \n",
       "2            1       0     721      758   0.512508  0.487492         113   \n",
       "3            1       0     721      758   0.512508  0.487492         113   \n",
       "4            1       1     721      758   0.512508  0.487492         113   \n",
       "...        ...     ...     ...      ...        ...       ...         ...   \n",
       "14781        2       1     631      847   0.573072  0.426928         117   \n",
       "14782        2       0     631      847   0.573072  0.426928         117   \n",
       "14783        2       0     631      847   0.573072  0.426928         117   \n",
       "14784        2       1     631      847   0.573072  0.426928         117   \n",
       "14785        2       1     631      847   0.573072  0.426928         117   \n",
       "\n",
       "       inf_good  inf_bad  aug_factor  inf_bad_aug  inf_good_aug  \n",
       "0          58.0     55.0    1.076403         59.0          54.0  \n",
       "1          58.0     55.0    1.076403         59.0          54.0  \n",
       "2          58.0     55.0    1.076403         59.0          54.0  \n",
       "3          58.0     55.0    1.076403         59.0          54.0  \n",
       "4          58.0     55.0    1.076403         59.0          54.0  \n",
       "...         ...      ...         ...          ...           ...  \n",
       "14781      67.0     50.0    1.079161         54.0          63.0  \n",
       "14782      67.0     50.0    1.079161         54.0          63.0  \n",
       "14783      67.0     50.0    1.079161         54.0          63.0  \n",
       "14784      67.0     50.0    1.079161         54.0          63.0  \n",
       "14785      67.0     50.0    1.079161         54.0          63.0  \n",
       "\n",
       "[14786 rows x 17 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 158;\n",
       "                var nbb_unformatted_code = \"df\";\n",
       "                var nbb_formatted_code = \"df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 160;\n",
       "                var nbb_unformatted_code = \"#Assign randomly given number of bads in each interval with a bad status\";\n",
       "                var nbb_formatted_code = \"# Assign randomly given number of bads in each interval with a bad status\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assign randomly given number of bads in each interval with a bad status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 161;\n",
       "                var nbb_unformatted_code = \"# Then assign with a model\";\n",
       "                var nbb_formatted_code = \"# Then assign with a model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Then assign with a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
