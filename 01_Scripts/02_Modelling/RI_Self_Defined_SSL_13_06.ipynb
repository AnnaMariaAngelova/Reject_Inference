{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 184;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 184;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 184;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 184;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 184;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 184;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 185;\n",
       "                var nbb_unformatted_code = \"import sys\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Basic Packages\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Modelling\\n# Classification\\nimport statsmodels.api as sm\\n\\n# from sklearn import LogisticRegression\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Metrics\\nfrom sklearn.metrics import f1_score, log_loss, matthews_corrcoef, roc_auc_score\\n\\n# Visualization\\nimport matplotlib.pyplot as plt\";\n",
       "                var nbb_formatted_code = \"import sys\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Basic Packages\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Modelling\\n# Classification\\nimport statsmodels.api as sm\\n\\n# from sklearn import LogisticRegression\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Metrics\\nfrom sklearn.metrics import f1_score, log_loss, matthews_corrcoef, roc_auc_score\\n\\n# Visualization\\nimport matplotlib.pyplot as plt\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 185;\n",
       "                var nbb_unformatted_code = \"import sys\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Basic Packages\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Modelling\\n# Classification\\nimport statsmodels.api as sm\\n\\n# from sklearn import LogisticRegression\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Metrics\\nfrom sklearn.metrics import f1_score, log_loss, matthews_corrcoef, roc_auc_score\\n\\n# Visualization\\nimport matplotlib.pyplot as plt\";\n",
       "                var nbb_formatted_code = \"import sys\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Basic Packages\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Modelling\\n# Classification\\nimport statsmodels.api as sm\\n\\n# from sklearn import LogisticRegression\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Metrics\\nfrom sklearn.metrics import f1_score, log_loss, matthews_corrcoef, roc_auc_score\\n\\n# Visualization\\nimport matplotlib.pyplot as plt\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 185;\n",
       "                var nbb_unformatted_code = \"import sys\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Basic Packages\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Modelling\\n# Classification\\nimport statsmodels.api as sm\\n\\n# from sklearn import LogisticRegression\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Metrics\\nfrom sklearn.metrics import f1_score, log_loss, matthews_corrcoef, roc_auc_score\\n\\n# Visualization\\nimport matplotlib.pyplot as plt\";\n",
       "                var nbb_formatted_code = \"import sys\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Basic Packages\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Modelling\\n# Classification\\nimport statsmodels.api as sm\\n\\n# from sklearn import LogisticRegression\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Metrics\\nfrom sklearn.metrics import f1_score, log_loss, matthews_corrcoef, roc_auc_score\\n\\n# Visualization\\nimport matplotlib.pyplot as plt\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 185;\n",
       "                var nbb_unformatted_code = \"import sys\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Basic Packages\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Modelling\\n# Classification\\nimport statsmodels.api as sm\\n\\n# from sklearn import LogisticRegression\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Metrics\\nfrom sklearn.metrics import f1_score, log_loss, matthews_corrcoef, roc_auc_score\\n\\n# Visualization\\nimport matplotlib.pyplot as plt\";\n",
       "                var nbb_formatted_code = \"import sys\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Basic Packages\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Modelling\\n# Classification\\nimport statsmodels.api as sm\\n\\n# from sklearn import LogisticRegression\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Metrics\\nfrom sklearn.metrics import f1_score, log_loss, matthews_corrcoef, roc_auc_score\\n\\n# Visualization\\nimport matplotlib.pyplot as plt\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 185;\n",
       "                var nbb_unformatted_code = \"import sys\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Basic Packages\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Modelling\\n# Classification\\nimport statsmodels.api as sm\\n\\n# from sklearn import LogisticRegression\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Metrics\\nfrom sklearn.metrics import f1_score, log_loss, matthews_corrcoef, roc_auc_score\\n\\n# Visualization\\nimport matplotlib.pyplot as plt\";\n",
       "                var nbb_formatted_code = \"import sys\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Basic Packages\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Modelling\\n# Classification\\nimport statsmodels.api as sm\\n\\n# from sklearn import LogisticRegression\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Metrics\\nfrom sklearn.metrics import f1_score, log_loss, matthews_corrcoef, roc_auc_score\\n\\n# Visualization\\nimport matplotlib.pyplot as plt\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 185;\n",
       "                var nbb_unformatted_code = \"import sys\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Basic Packages\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Modelling\\n# Classification\\nimport statsmodels.api as sm\\n\\n# from sklearn import LogisticRegression\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Metrics\\nfrom sklearn.metrics import f1_score, log_loss, matthews_corrcoef, roc_auc_score\\n\\n# Visualization\\nimport matplotlib.pyplot as plt\";\n",
       "                var nbb_formatted_code = \"import sys\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Basic Packages\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\n# Modelling\\n# Classification\\nimport statsmodels.api as sm\\n\\n# from sklearn import LogisticRegression\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\n# Model Selection\\nfrom sklearn.model_selection import train_test_split\\n\\n# Metrics\\nfrom sklearn.metrics import f1_score, log_loss, matthews_corrcoef, roc_auc_score\\n\\n# Visualization\\nimport matplotlib.pyplot as plt\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Basic Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modelling\n",
    "# Classification\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# from sklearn import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import f1_score, log_loss, matthews_corrcoef, roc_auc_score\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, basic data preprocessing to obtain accepted and rejected training and test samples separately. Save rejected data in two versions: with and without lables. The rejected data without labels is needed for the semi-supervised model. The rejected data without labels is needed to perform evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 186;\n",
       "                var nbb_unformatted_code = \"def data_preprocessing(df, accepted_flag, target, train_ratio):\\n    \\\"\\\"\\\"\\n    The goal of this function is to load the original dataset, split it into accepts and rejects,\\n    add ids, which can later be used for merging. For the rejects to further perform train / test split\\n\\n    Parameters\\n    ----------\\n\\n    df : name of the original dataset in quotation marks, csv format\\n    accepted_flag: name of the accepted flag; Binary: 1 if accepted, 0 if rejected\\n    target : name of the target column\\n    train_ratio : percentage used for training; Continuous (0,1)\\n\\n    Return\\n    ------\\n    a : accepted data\\n    r : rejected data\\n    r_dev : rejected trainining data without label\\n    r_test : rejected testing data without label\\n    dfr_dev_with_label: rejected training data with label\\n    dft_test_with_label: rejected training data with label\\n\\n    \\\"\\\"\\\"\\n    # Load data\\n    data = pd.read_csv(\\\"C:/Users/Asus/Desktop/Repo/MasterThesis_RI/Sample_18_06/\\\" + df)\\n\\n    # Accepted\\n\\n    ## Create separate dataset with accepts\\n    dfa = data[data[accepted_flag] == 1]\\n    dfa = dfa.drop([accepted_flag], axis=1)\\n    ## Rename target variable as \\\"target\\\"\\n    dfa = dfa.rename(columns={target: \\\"target\\\"})\\n    ## Add id to the dataset, which can later be used for merging\\n    # dfa[\\\"id\\\"] = dfa.index.to_series().map(lambda x: uuid.uuid4())\\n\\n    # Rejected\\n\\n    ## Create separate dataset with accepts\\n    dfr = data[data[accepted_flag] == 0]\\n    dfr = dfr.drop([accepted_flag], axis=1)\\n    ## Add id to the dataset, which can later be used for merging\\n    #     dfr[\\\"id\\\"] = dfr.index.to_series().map(lambda x: uuid.uuid4())\\n    ## Train/Test Split (without labels)\\n    ### Shuffle the dataset\\n    shuffle_df = dfr.sample(frac=1, random_state=42)\\n    ### Define a size for the train set\\n    train_size = int(train_ratio * len(shuffle_df))\\n    ### Split the dataset\\n    dfr_dev = shuffle_df[:train_size]\\n    dfr_test = shuffle_df[train_size:]\\n    ## Save a copy of the rejected data with label\\n    dfr_dev_with_label = dfr_dev\\n    dfr_test_with_label = dfr_test\\n    ## Unlabel the rejects (i.e. drop the target) and save a copy of the rejeted data without label\\n    dfr_dev2 = dfr_dev_with_label.drop([target], axis=1)\\n    dfr_test2 = dfr_test_with_label.drop([target], axis=1)\\n    # Rename target variable\\n    dfr_dev_with_label = dfr_dev_with_label.rename(columns={target: \\\"target\\\"})\\n    dfr_test_with_label = dfr_test_with_label.rename(columns={target: \\\"target\\\"})\\n\\n    return dfr_dev_with_label, dfr_test_with_label, dfa, dfr, dfr_dev2, dfr_test2\";\n",
       "                var nbb_formatted_code = \"def data_preprocessing(df, accepted_flag, target, train_ratio):\\n    \\\"\\\"\\\"\\n    The goal of this function is to load the original dataset, split it into accepts and rejects,\\n    add ids, which can later be used for merging. For the rejects to further perform train / test split\\n\\n    Parameters\\n    ----------\\n\\n    df : name of the original dataset in quotation marks, csv format\\n    accepted_flag: name of the accepted flag; Binary: 1 if accepted, 0 if rejected\\n    target : name of the target column\\n    train_ratio : percentage used for training; Continuous (0,1)\\n\\n    Return\\n    ------\\n    a : accepted data\\n    r : rejected data\\n    r_dev : rejected trainining data without label\\n    r_test : rejected testing data without label\\n    dfr_dev_with_label: rejected training data with label\\n    dft_test_with_label: rejected training data with label\\n\\n    \\\"\\\"\\\"\\n    # Load data\\n    data = pd.read_csv(\\\"C:/Users/Asus/Desktop/Repo/MasterThesis_RI/Sample_18_06/\\\" + df)\\n\\n    # Accepted\\n\\n    ## Create separate dataset with accepts\\n    dfa = data[data[accepted_flag] == 1]\\n    dfa = dfa.drop([accepted_flag], axis=1)\\n    ## Rename target variable as \\\"target\\\"\\n    dfa = dfa.rename(columns={target: \\\"target\\\"})\\n    ## Add id to the dataset, which can later be used for merging\\n    # dfa[\\\"id\\\"] = dfa.index.to_series().map(lambda x: uuid.uuid4())\\n\\n    # Rejected\\n\\n    ## Create separate dataset with accepts\\n    dfr = data[data[accepted_flag] == 0]\\n    dfr = dfr.drop([accepted_flag], axis=1)\\n    ## Add id to the dataset, which can later be used for merging\\n    #     dfr[\\\"id\\\"] = dfr.index.to_series().map(lambda x: uuid.uuid4())\\n    ## Train/Test Split (without labels)\\n    ### Shuffle the dataset\\n    shuffle_df = dfr.sample(frac=1, random_state=42)\\n    ### Define a size for the train set\\n    train_size = int(train_ratio * len(shuffle_df))\\n    ### Split the dataset\\n    dfr_dev = shuffle_df[:train_size]\\n    dfr_test = shuffle_df[train_size:]\\n    ## Save a copy of the rejected data with label\\n    dfr_dev_with_label = dfr_dev\\n    dfr_test_with_label = dfr_test\\n    ## Unlabel the rejects (i.e. drop the target) and save a copy of the rejeted data without label\\n    dfr_dev2 = dfr_dev_with_label.drop([target], axis=1)\\n    dfr_test2 = dfr_test_with_label.drop([target], axis=1)\\n    # Rename target variable\\n    dfr_dev_with_label = dfr_dev_with_label.rename(columns={target: \\\"target\\\"})\\n    dfr_test_with_label = dfr_test_with_label.rename(columns={target: \\\"target\\\"})\\n\\n    return dfr_dev_with_label, dfr_test_with_label, dfa, dfr, dfr_dev2, dfr_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 186;\n",
       "                var nbb_unformatted_code = \"def data_preprocessing(df, accepted_flag, target, train_ratio):\\n    \\\"\\\"\\\"\\n    The goal of this function is to load the original dataset, split it into accepts and rejects,\\n    add ids, which can later be used for merging. For the rejects to further perform train / test split\\n\\n    Parameters\\n    ----------\\n\\n    df : name of the original dataset in quotation marks, csv format\\n    accepted_flag: name of the accepted flag; Binary: 1 if accepted, 0 if rejected\\n    target : name of the target column\\n    train_ratio : percentage used for training; Continuous (0,1)\\n\\n    Return\\n    ------\\n    a : accepted data\\n    r : rejected data\\n    r_dev : rejected trainining data without label\\n    r_test : rejected testing data without label\\n    dfr_dev_with_label: rejected training data with label\\n    dft_test_with_label: rejected training data with label\\n\\n    \\\"\\\"\\\"\\n    # Load data\\n    data = pd.read_csv(\\\"C:/Users/Asus/Desktop/Repo/MasterThesis_RI/Sample_18_06/\\\" + df)\\n\\n    # Accepted\\n\\n    ## Create separate dataset with accepts\\n    dfa = data[data[accepted_flag] == 1]\\n    dfa = dfa.drop([accepted_flag], axis=1)\\n    ## Rename target variable as \\\"target\\\"\\n    dfa = dfa.rename(columns={target: \\\"target\\\"})\\n    ## Add id to the dataset, which can later be used for merging\\n    # dfa[\\\"id\\\"] = dfa.index.to_series().map(lambda x: uuid.uuid4())\\n\\n    # Rejected\\n\\n    ## Create separate dataset with accepts\\n    dfr = data[data[accepted_flag] == 0]\\n    dfr = dfr.drop([accepted_flag], axis=1)\\n    ## Add id to the dataset, which can later be used for merging\\n    #     dfr[\\\"id\\\"] = dfr.index.to_series().map(lambda x: uuid.uuid4())\\n    ## Train/Test Split (without labels)\\n    ### Shuffle the dataset\\n    shuffle_df = dfr.sample(frac=1, random_state=42)\\n    ### Define a size for the train set\\n    train_size = int(train_ratio * len(shuffle_df))\\n    ### Split the dataset\\n    dfr_dev = shuffle_df[:train_size]\\n    dfr_test = shuffle_df[train_size:]\\n    ## Save a copy of the rejected data with label\\n    dfr_dev_with_label = dfr_dev\\n    dfr_test_with_label = dfr_test\\n    ## Unlabel the rejects (i.e. drop the target) and save a copy of the rejeted data without label\\n    dfr_dev2 = dfr_dev_with_label.drop([target], axis=1)\\n    dfr_test2 = dfr_test_with_label.drop([target], axis=1)\\n    # Rename target variable\\n    dfr_dev_with_label = dfr_dev_with_label.rename(columns={target: \\\"target\\\"})\\n    dfr_test_with_label = dfr_test_with_label.rename(columns={target: \\\"target\\\"})\\n\\n    return dfr_dev_with_label, dfr_test_with_label, dfa, dfr, dfr_dev2, dfr_test2\";\n",
       "                var nbb_formatted_code = \"def data_preprocessing(df, accepted_flag, target, train_ratio):\\n    \\\"\\\"\\\"\\n    The goal of this function is to load the original dataset, split it into accepts and rejects,\\n    add ids, which can later be used for merging. For the rejects to further perform train / test split\\n\\n    Parameters\\n    ----------\\n\\n    df : name of the original dataset in quotation marks, csv format\\n    accepted_flag: name of the accepted flag; Binary: 1 if accepted, 0 if rejected\\n    target : name of the target column\\n    train_ratio : percentage used for training; Continuous (0,1)\\n\\n    Return\\n    ------\\n    a : accepted data\\n    r : rejected data\\n    r_dev : rejected trainining data without label\\n    r_test : rejected testing data without label\\n    dfr_dev_with_label: rejected training data with label\\n    dft_test_with_label: rejected training data with label\\n\\n    \\\"\\\"\\\"\\n    # Load data\\n    data = pd.read_csv(\\\"C:/Users/Asus/Desktop/Repo/MasterThesis_RI/Sample_18_06/\\\" + df)\\n\\n    # Accepted\\n\\n    ## Create separate dataset with accepts\\n    dfa = data[data[accepted_flag] == 1]\\n    dfa = dfa.drop([accepted_flag], axis=1)\\n    ## Rename target variable as \\\"target\\\"\\n    dfa = dfa.rename(columns={target: \\\"target\\\"})\\n    ## Add id to the dataset, which can later be used for merging\\n    # dfa[\\\"id\\\"] = dfa.index.to_series().map(lambda x: uuid.uuid4())\\n\\n    # Rejected\\n\\n    ## Create separate dataset with accepts\\n    dfr = data[data[accepted_flag] == 0]\\n    dfr = dfr.drop([accepted_flag], axis=1)\\n    ## Add id to the dataset, which can later be used for merging\\n    #     dfr[\\\"id\\\"] = dfr.index.to_series().map(lambda x: uuid.uuid4())\\n    ## Train/Test Split (without labels)\\n    ### Shuffle the dataset\\n    shuffle_df = dfr.sample(frac=1, random_state=42)\\n    ### Define a size for the train set\\n    train_size = int(train_ratio * len(shuffle_df))\\n    ### Split the dataset\\n    dfr_dev = shuffle_df[:train_size]\\n    dfr_test = shuffle_df[train_size:]\\n    ## Save a copy of the rejected data with label\\n    dfr_dev_with_label = dfr_dev\\n    dfr_test_with_label = dfr_test\\n    ## Unlabel the rejects (i.e. drop the target) and save a copy of the rejeted data without label\\n    dfr_dev2 = dfr_dev_with_label.drop([target], axis=1)\\n    dfr_test2 = dfr_test_with_label.drop([target], axis=1)\\n    # Rename target variable\\n    dfr_dev_with_label = dfr_dev_with_label.rename(columns={target: \\\"target\\\"})\\n    dfr_test_with_label = dfr_test_with_label.rename(columns={target: \\\"target\\\"})\\n\\n    return dfr_dev_with_label, dfr_test_with_label, dfa, dfr, dfr_dev2, dfr_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 186;\n",
       "                var nbb_unformatted_code = \"def data_preprocessing(df, accepted_flag, target, train_ratio):\\n    \\\"\\\"\\\"\\n    The goal of this function is to load the original dataset, split it into accepts and rejects,\\n    add ids, which can later be used for merging. For the rejects to further perform train / test split\\n\\n    Parameters\\n    ----------\\n\\n    df : name of the original dataset in quotation marks, csv format\\n    accepted_flag: name of the accepted flag; Binary: 1 if accepted, 0 if rejected\\n    target : name of the target column\\n    train_ratio : percentage used for training; Continuous (0,1)\\n\\n    Return\\n    ------\\n    a : accepted data\\n    r : rejected data\\n    r_dev : rejected trainining data without label\\n    r_test : rejected testing data without label\\n    dfr_dev_with_label: rejected training data with label\\n    dft_test_with_label: rejected training data with label\\n\\n    \\\"\\\"\\\"\\n    # Load data\\n    data = pd.read_csv(\\\"C:/Users/Asus/Desktop/Repo/MasterThesis_RI/Sample_18_06/\\\" + df)\\n\\n    # Accepted\\n\\n    ## Create separate dataset with accepts\\n    dfa = data[data[accepted_flag] == 1]\\n    dfa = dfa.drop([accepted_flag], axis=1)\\n    ## Rename target variable as \\\"target\\\"\\n    dfa = dfa.rename(columns={target: \\\"target\\\"})\\n    ## Add id to the dataset, which can later be used for merging\\n    # dfa[\\\"id\\\"] = dfa.index.to_series().map(lambda x: uuid.uuid4())\\n\\n    # Rejected\\n\\n    ## Create separate dataset with accepts\\n    dfr = data[data[accepted_flag] == 0]\\n    dfr = dfr.drop([accepted_flag], axis=1)\\n    ## Add id to the dataset, which can later be used for merging\\n    #     dfr[\\\"id\\\"] = dfr.index.to_series().map(lambda x: uuid.uuid4())\\n    ## Train/Test Split (without labels)\\n    ### Shuffle the dataset\\n    shuffle_df = dfr.sample(frac=1, random_state=42)\\n    ### Define a size for the train set\\n    train_size = int(train_ratio * len(shuffle_df))\\n    ### Split the dataset\\n    dfr_dev = shuffle_df[:train_size]\\n    dfr_test = shuffle_df[train_size:]\\n    ## Save a copy of the rejected data with label\\n    dfr_dev_with_label = dfr_dev\\n    dfr_test_with_label = dfr_test\\n    ## Unlabel the rejects (i.e. drop the target) and save a copy of the rejeted data without label\\n    dfr_dev2 = dfr_dev_with_label.drop([target], axis=1)\\n    dfr_test2 = dfr_test_with_label.drop([target], axis=1)\\n    # Rename target variable\\n    dfr_dev_with_label = dfr_dev_with_label.rename(columns={target: \\\"target\\\"})\\n    dfr_test_with_label = dfr_test_with_label.rename(columns={target: \\\"target\\\"})\\n\\n    return dfr_dev_with_label, dfr_test_with_label, dfa, dfr, dfr_dev2, dfr_test2\";\n",
       "                var nbb_formatted_code = \"def data_preprocessing(df, accepted_flag, target, train_ratio):\\n    \\\"\\\"\\\"\\n    The goal of this function is to load the original dataset, split it into accepts and rejects,\\n    add ids, which can later be used for merging. For the rejects to further perform train / test split\\n\\n    Parameters\\n    ----------\\n\\n    df : name of the original dataset in quotation marks, csv format\\n    accepted_flag: name of the accepted flag; Binary: 1 if accepted, 0 if rejected\\n    target : name of the target column\\n    train_ratio : percentage used for training; Continuous (0,1)\\n\\n    Return\\n    ------\\n    a : accepted data\\n    r : rejected data\\n    r_dev : rejected trainining data without label\\n    r_test : rejected testing data without label\\n    dfr_dev_with_label: rejected training data with label\\n    dft_test_with_label: rejected training data with label\\n\\n    \\\"\\\"\\\"\\n    # Load data\\n    data = pd.read_csv(\\\"C:/Users/Asus/Desktop/Repo/MasterThesis_RI/Sample_18_06/\\\" + df)\\n\\n    # Accepted\\n\\n    ## Create separate dataset with accepts\\n    dfa = data[data[accepted_flag] == 1]\\n    dfa = dfa.drop([accepted_flag], axis=1)\\n    ## Rename target variable as \\\"target\\\"\\n    dfa = dfa.rename(columns={target: \\\"target\\\"})\\n    ## Add id to the dataset, which can later be used for merging\\n    # dfa[\\\"id\\\"] = dfa.index.to_series().map(lambda x: uuid.uuid4())\\n\\n    # Rejected\\n\\n    ## Create separate dataset with accepts\\n    dfr = data[data[accepted_flag] == 0]\\n    dfr = dfr.drop([accepted_flag], axis=1)\\n    ## Add id to the dataset, which can later be used for merging\\n    #     dfr[\\\"id\\\"] = dfr.index.to_series().map(lambda x: uuid.uuid4())\\n    ## Train/Test Split (without labels)\\n    ### Shuffle the dataset\\n    shuffle_df = dfr.sample(frac=1, random_state=42)\\n    ### Define a size for the train set\\n    train_size = int(train_ratio * len(shuffle_df))\\n    ### Split the dataset\\n    dfr_dev = shuffle_df[:train_size]\\n    dfr_test = shuffle_df[train_size:]\\n    ## Save a copy of the rejected data with label\\n    dfr_dev_with_label = dfr_dev\\n    dfr_test_with_label = dfr_test\\n    ## Unlabel the rejects (i.e. drop the target) and save a copy of the rejeted data without label\\n    dfr_dev2 = dfr_dev_with_label.drop([target], axis=1)\\n    dfr_test2 = dfr_test_with_label.drop([target], axis=1)\\n    # Rename target variable\\n    dfr_dev_with_label = dfr_dev_with_label.rename(columns={target: \\\"target\\\"})\\n    dfr_test_with_label = dfr_test_with_label.rename(columns={target: \\\"target\\\"})\\n\\n    return dfr_dev_with_label, dfr_test_with_label, dfa, dfr, dfr_dev2, dfr_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 186;\n",
       "                var nbb_unformatted_code = \"def data_preprocessing(df, accepted_flag, target, train_ratio):\\n    \\\"\\\"\\\"\\n    The goal of this function is to load the original dataset, split it into accepts and rejects,\\n    add ids, which can later be used for merging. For the rejects to further perform train / test split\\n\\n    Parameters\\n    ----------\\n\\n    df : name of the original dataset in quotation marks, csv format\\n    accepted_flag: name of the accepted flag; Binary: 1 if accepted, 0 if rejected\\n    target : name of the target column\\n    train_ratio : percentage used for training; Continuous (0,1)\\n\\n    Return\\n    ------\\n    a : accepted data\\n    r : rejected data\\n    r_dev : rejected trainining data without label\\n    r_test : rejected testing data without label\\n    dfr_dev_with_label: rejected training data with label\\n    dft_test_with_label: rejected training data with label\\n\\n    \\\"\\\"\\\"\\n    # Load data\\n    data = pd.read_csv(\\\"C:/Users/Asus/Desktop/Repo/MasterThesis_RI/Sample_18_06/\\\" + df)\\n\\n    # Accepted\\n\\n    ## Create separate dataset with accepts\\n    dfa = data[data[accepted_flag] == 1]\\n    dfa = dfa.drop([accepted_flag], axis=1)\\n    ## Rename target variable as \\\"target\\\"\\n    dfa = dfa.rename(columns={target: \\\"target\\\"})\\n    ## Add id to the dataset, which can later be used for merging\\n    # dfa[\\\"id\\\"] = dfa.index.to_series().map(lambda x: uuid.uuid4())\\n\\n    # Rejected\\n\\n    ## Create separate dataset with accepts\\n    dfr = data[data[accepted_flag] == 0]\\n    dfr = dfr.drop([accepted_flag], axis=1)\\n    ## Add id to the dataset, which can later be used for merging\\n    #     dfr[\\\"id\\\"] = dfr.index.to_series().map(lambda x: uuid.uuid4())\\n    ## Train/Test Split (without labels)\\n    ### Shuffle the dataset\\n    shuffle_df = dfr.sample(frac=1, random_state=42)\\n    ### Define a size for the train set\\n    train_size = int(train_ratio * len(shuffle_df))\\n    ### Split the dataset\\n    dfr_dev = shuffle_df[:train_size]\\n    dfr_test = shuffle_df[train_size:]\\n    ## Save a copy of the rejected data with label\\n    dfr_dev_with_label = dfr_dev\\n    dfr_test_with_label = dfr_test\\n    ## Unlabel the rejects (i.e. drop the target) and save a copy of the rejeted data without label\\n    dfr_dev2 = dfr_dev_with_label.drop([target], axis=1)\\n    dfr_test2 = dfr_test_with_label.drop([target], axis=1)\\n    # Rename target variable\\n    dfr_dev_with_label = dfr_dev_with_label.rename(columns={target: \\\"target\\\"})\\n    dfr_test_with_label = dfr_test_with_label.rename(columns={target: \\\"target\\\"})\\n\\n    return dfr_dev_with_label, dfr_test_with_label, dfa, dfr, dfr_dev2, dfr_test2\";\n",
       "                var nbb_formatted_code = \"def data_preprocessing(df, accepted_flag, target, train_ratio):\\n    \\\"\\\"\\\"\\n    The goal of this function is to load the original dataset, split it into accepts and rejects,\\n    add ids, which can later be used for merging. For the rejects to further perform train / test split\\n\\n    Parameters\\n    ----------\\n\\n    df : name of the original dataset in quotation marks, csv format\\n    accepted_flag: name of the accepted flag; Binary: 1 if accepted, 0 if rejected\\n    target : name of the target column\\n    train_ratio : percentage used for training; Continuous (0,1)\\n\\n    Return\\n    ------\\n    a : accepted data\\n    r : rejected data\\n    r_dev : rejected trainining data without label\\n    r_test : rejected testing data without label\\n    dfr_dev_with_label: rejected training data with label\\n    dft_test_with_label: rejected training data with label\\n\\n    \\\"\\\"\\\"\\n    # Load data\\n    data = pd.read_csv(\\\"C:/Users/Asus/Desktop/Repo/MasterThesis_RI/Sample_18_06/\\\" + df)\\n\\n    # Accepted\\n\\n    ## Create separate dataset with accepts\\n    dfa = data[data[accepted_flag] == 1]\\n    dfa = dfa.drop([accepted_flag], axis=1)\\n    ## Rename target variable as \\\"target\\\"\\n    dfa = dfa.rename(columns={target: \\\"target\\\"})\\n    ## Add id to the dataset, which can later be used for merging\\n    # dfa[\\\"id\\\"] = dfa.index.to_series().map(lambda x: uuid.uuid4())\\n\\n    # Rejected\\n\\n    ## Create separate dataset with accepts\\n    dfr = data[data[accepted_flag] == 0]\\n    dfr = dfr.drop([accepted_flag], axis=1)\\n    ## Add id to the dataset, which can later be used for merging\\n    #     dfr[\\\"id\\\"] = dfr.index.to_series().map(lambda x: uuid.uuid4())\\n    ## Train/Test Split (without labels)\\n    ### Shuffle the dataset\\n    shuffle_df = dfr.sample(frac=1, random_state=42)\\n    ### Define a size for the train set\\n    train_size = int(train_ratio * len(shuffle_df))\\n    ### Split the dataset\\n    dfr_dev = shuffle_df[:train_size]\\n    dfr_test = shuffle_df[train_size:]\\n    ## Save a copy of the rejected data with label\\n    dfr_dev_with_label = dfr_dev\\n    dfr_test_with_label = dfr_test\\n    ## Unlabel the rejects (i.e. drop the target) and save a copy of the rejeted data without label\\n    dfr_dev2 = dfr_dev_with_label.drop([target], axis=1)\\n    dfr_test2 = dfr_test_with_label.drop([target], axis=1)\\n    # Rename target variable\\n    dfr_dev_with_label = dfr_dev_with_label.rename(columns={target: \\\"target\\\"})\\n    dfr_test_with_label = dfr_test_with_label.rename(columns={target: \\\"target\\\"})\\n\\n    return dfr_dev_with_label, dfr_test_with_label, dfa, dfr, dfr_dev2, dfr_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 186;\n",
       "                var nbb_unformatted_code = \"def data_preprocessing(df, accepted_flag, target, train_ratio):\\n    \\\"\\\"\\\"\\n    The goal of this function is to load the original dataset, split it into accepts and rejects,\\n    add ids, which can later be used for merging. For the rejects to further perform train / test split\\n\\n    Parameters\\n    ----------\\n\\n    df : name of the original dataset in quotation marks, csv format\\n    accepted_flag: name of the accepted flag; Binary: 1 if accepted, 0 if rejected\\n    target : name of the target column\\n    train_ratio : percentage used for training; Continuous (0,1)\\n\\n    Return\\n    ------\\n    a : accepted data\\n    r : rejected data\\n    r_dev : rejected trainining data without label\\n    r_test : rejected testing data without label\\n    dfr_dev_with_label: rejected training data with label\\n    dft_test_with_label: rejected training data with label\\n\\n    \\\"\\\"\\\"\\n    # Load data\\n    data = pd.read_csv(\\\"C:/Users/Asus/Desktop/Repo/MasterThesis_RI/Sample_18_06/\\\" + df)\\n\\n    # Accepted\\n\\n    ## Create separate dataset with accepts\\n    dfa = data[data[accepted_flag] == 1]\\n    dfa = dfa.drop([accepted_flag], axis=1)\\n    ## Rename target variable as \\\"target\\\"\\n    dfa = dfa.rename(columns={target: \\\"target\\\"})\\n    ## Add id to the dataset, which can later be used for merging\\n    # dfa[\\\"id\\\"] = dfa.index.to_series().map(lambda x: uuid.uuid4())\\n\\n    # Rejected\\n\\n    ## Create separate dataset with accepts\\n    dfr = data[data[accepted_flag] == 0]\\n    dfr = dfr.drop([accepted_flag], axis=1)\\n    ## Add id to the dataset, which can later be used for merging\\n    #     dfr[\\\"id\\\"] = dfr.index.to_series().map(lambda x: uuid.uuid4())\\n    ## Train/Test Split (without labels)\\n    ### Shuffle the dataset\\n    shuffle_df = dfr.sample(frac=1, random_state=42)\\n    ### Define a size for the train set\\n    train_size = int(train_ratio * len(shuffle_df))\\n    ### Split the dataset\\n    dfr_dev = shuffle_df[:train_size]\\n    dfr_test = shuffle_df[train_size:]\\n    ## Save a copy of the rejected data with label\\n    dfr_dev_with_label = dfr_dev\\n    dfr_test_with_label = dfr_test\\n    ## Unlabel the rejects (i.e. drop the target) and save a copy of the rejeted data without label\\n    dfr_dev2 = dfr_dev_with_label.drop([target], axis=1)\\n    dfr_test2 = dfr_test_with_label.drop([target], axis=1)\\n    # Rename target variable\\n    dfr_dev_with_label = dfr_dev_with_label.rename(columns={target: \\\"target\\\"})\\n    dfr_test_with_label = dfr_test_with_label.rename(columns={target: \\\"target\\\"})\\n\\n    return dfr_dev_with_label, dfr_test_with_label, dfa, dfr, dfr_dev2, dfr_test2\";\n",
       "                var nbb_formatted_code = \"def data_preprocessing(df, accepted_flag, target, train_ratio):\\n    \\\"\\\"\\\"\\n    The goal of this function is to load the original dataset, split it into accepts and rejects,\\n    add ids, which can later be used for merging. For the rejects to further perform train / test split\\n\\n    Parameters\\n    ----------\\n\\n    df : name of the original dataset in quotation marks, csv format\\n    accepted_flag: name of the accepted flag; Binary: 1 if accepted, 0 if rejected\\n    target : name of the target column\\n    train_ratio : percentage used for training; Continuous (0,1)\\n\\n    Return\\n    ------\\n    a : accepted data\\n    r : rejected data\\n    r_dev : rejected trainining data without label\\n    r_test : rejected testing data without label\\n    dfr_dev_with_label: rejected training data with label\\n    dft_test_with_label: rejected training data with label\\n\\n    \\\"\\\"\\\"\\n    # Load data\\n    data = pd.read_csv(\\\"C:/Users/Asus/Desktop/Repo/MasterThesis_RI/Sample_18_06/\\\" + df)\\n\\n    # Accepted\\n\\n    ## Create separate dataset with accepts\\n    dfa = data[data[accepted_flag] == 1]\\n    dfa = dfa.drop([accepted_flag], axis=1)\\n    ## Rename target variable as \\\"target\\\"\\n    dfa = dfa.rename(columns={target: \\\"target\\\"})\\n    ## Add id to the dataset, which can later be used for merging\\n    # dfa[\\\"id\\\"] = dfa.index.to_series().map(lambda x: uuid.uuid4())\\n\\n    # Rejected\\n\\n    ## Create separate dataset with accepts\\n    dfr = data[data[accepted_flag] == 0]\\n    dfr = dfr.drop([accepted_flag], axis=1)\\n    ## Add id to the dataset, which can later be used for merging\\n    #     dfr[\\\"id\\\"] = dfr.index.to_series().map(lambda x: uuid.uuid4())\\n    ## Train/Test Split (without labels)\\n    ### Shuffle the dataset\\n    shuffle_df = dfr.sample(frac=1, random_state=42)\\n    ### Define a size for the train set\\n    train_size = int(train_ratio * len(shuffle_df))\\n    ### Split the dataset\\n    dfr_dev = shuffle_df[:train_size]\\n    dfr_test = shuffle_df[train_size:]\\n    ## Save a copy of the rejected data with label\\n    dfr_dev_with_label = dfr_dev\\n    dfr_test_with_label = dfr_test\\n    ## Unlabel the rejects (i.e. drop the target) and save a copy of the rejeted data without label\\n    dfr_dev2 = dfr_dev_with_label.drop([target], axis=1)\\n    dfr_test2 = dfr_test_with_label.drop([target], axis=1)\\n    # Rename target variable\\n    dfr_dev_with_label = dfr_dev_with_label.rename(columns={target: \\\"target\\\"})\\n    dfr_test_with_label = dfr_test_with_label.rename(columns={target: \\\"target\\\"})\\n\\n    return dfr_dev_with_label, dfr_test_with_label, dfa, dfr, dfr_dev2, dfr_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 186;\n",
       "                var nbb_unformatted_code = \"def data_preprocessing(df, accepted_flag, target, train_ratio):\\n    \\\"\\\"\\\"\\n    The goal of this function is to load the original dataset, split it into accepts and rejects,\\n    add ids, which can later be used for merging. For the rejects to further perform train / test split\\n\\n    Parameters\\n    ----------\\n\\n    df : name of the original dataset in quotation marks, csv format\\n    accepted_flag: name of the accepted flag; Binary: 1 if accepted, 0 if rejected\\n    target : name of the target column\\n    train_ratio : percentage used for training; Continuous (0,1)\\n\\n    Return\\n    ------\\n    a : accepted data\\n    r : rejected data\\n    r_dev : rejected trainining data without label\\n    r_test : rejected testing data without label\\n    dfr_dev_with_label: rejected training data with label\\n    dft_test_with_label: rejected training data with label\\n\\n    \\\"\\\"\\\"\\n    # Load data\\n    data = pd.read_csv(\\\"C:/Users/Asus/Desktop/Repo/MasterThesis_RI/Sample_18_06/\\\" + df)\\n\\n    # Accepted\\n\\n    ## Create separate dataset with accepts\\n    dfa = data[data[accepted_flag] == 1]\\n    dfa = dfa.drop([accepted_flag], axis=1)\\n    ## Rename target variable as \\\"target\\\"\\n    dfa = dfa.rename(columns={target: \\\"target\\\"})\\n    ## Add id to the dataset, which can later be used for merging\\n    # dfa[\\\"id\\\"] = dfa.index.to_series().map(lambda x: uuid.uuid4())\\n\\n    # Rejected\\n\\n    ## Create separate dataset with accepts\\n    dfr = data[data[accepted_flag] == 0]\\n    dfr = dfr.drop([accepted_flag], axis=1)\\n    ## Add id to the dataset, which can later be used for merging\\n    #     dfr[\\\"id\\\"] = dfr.index.to_series().map(lambda x: uuid.uuid4())\\n    ## Train/Test Split (without labels)\\n    ### Shuffle the dataset\\n    shuffle_df = dfr.sample(frac=1, random_state=42)\\n    ### Define a size for the train set\\n    train_size = int(train_ratio * len(shuffle_df))\\n    ### Split the dataset\\n    dfr_dev = shuffle_df[:train_size]\\n    dfr_test = shuffle_df[train_size:]\\n    ## Save a copy of the rejected data with label\\n    dfr_dev_with_label = dfr_dev\\n    dfr_test_with_label = dfr_test\\n    ## Unlabel the rejects (i.e. drop the target) and save a copy of the rejeted data without label\\n    dfr_dev2 = dfr_dev_with_label.drop([target], axis=1)\\n    dfr_test2 = dfr_test_with_label.drop([target], axis=1)\\n    # Rename target variable\\n    dfr_dev_with_label = dfr_dev_with_label.rename(columns={target: \\\"target\\\"})\\n    dfr_test_with_label = dfr_test_with_label.rename(columns={target: \\\"target\\\"})\\n\\n    return dfr_dev_with_label, dfr_test_with_label, dfa, dfr, dfr_dev2, dfr_test2\";\n",
       "                var nbb_formatted_code = \"def data_preprocessing(df, accepted_flag, target, train_ratio):\\n    \\\"\\\"\\\"\\n    The goal of this function is to load the original dataset, split it into accepts and rejects,\\n    add ids, which can later be used for merging. For the rejects to further perform train / test split\\n\\n    Parameters\\n    ----------\\n\\n    df : name of the original dataset in quotation marks, csv format\\n    accepted_flag: name of the accepted flag; Binary: 1 if accepted, 0 if rejected\\n    target : name of the target column\\n    train_ratio : percentage used for training; Continuous (0,1)\\n\\n    Return\\n    ------\\n    a : accepted data\\n    r : rejected data\\n    r_dev : rejected trainining data without label\\n    r_test : rejected testing data without label\\n    dfr_dev_with_label: rejected training data with label\\n    dft_test_with_label: rejected training data with label\\n\\n    \\\"\\\"\\\"\\n    # Load data\\n    data = pd.read_csv(\\\"C:/Users/Asus/Desktop/Repo/MasterThesis_RI/Sample_18_06/\\\" + df)\\n\\n    # Accepted\\n\\n    ## Create separate dataset with accepts\\n    dfa = data[data[accepted_flag] == 1]\\n    dfa = dfa.drop([accepted_flag], axis=1)\\n    ## Rename target variable as \\\"target\\\"\\n    dfa = dfa.rename(columns={target: \\\"target\\\"})\\n    ## Add id to the dataset, which can later be used for merging\\n    # dfa[\\\"id\\\"] = dfa.index.to_series().map(lambda x: uuid.uuid4())\\n\\n    # Rejected\\n\\n    ## Create separate dataset with accepts\\n    dfr = data[data[accepted_flag] == 0]\\n    dfr = dfr.drop([accepted_flag], axis=1)\\n    ## Add id to the dataset, which can later be used for merging\\n    #     dfr[\\\"id\\\"] = dfr.index.to_series().map(lambda x: uuid.uuid4())\\n    ## Train/Test Split (without labels)\\n    ### Shuffle the dataset\\n    shuffle_df = dfr.sample(frac=1, random_state=42)\\n    ### Define a size for the train set\\n    train_size = int(train_ratio * len(shuffle_df))\\n    ### Split the dataset\\n    dfr_dev = shuffle_df[:train_size]\\n    dfr_test = shuffle_df[train_size:]\\n    ## Save a copy of the rejected data with label\\n    dfr_dev_with_label = dfr_dev\\n    dfr_test_with_label = dfr_test\\n    ## Unlabel the rejects (i.e. drop the target) and save a copy of the rejeted data without label\\n    dfr_dev2 = dfr_dev_with_label.drop([target], axis=1)\\n    dfr_test2 = dfr_test_with_label.drop([target], axis=1)\\n    # Rename target variable\\n    dfr_dev_with_label = dfr_dev_with_label.rename(columns={target: \\\"target\\\"})\\n    dfr_test_with_label = dfr_test_with_label.rename(columns={target: \\\"target\\\"})\\n\\n    return dfr_dev_with_label, dfr_test_with_label, dfa, dfr, dfr_dev2, dfr_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def data_preprocessing(df, accepted_flag, target, train_ratio):\n",
    "    \"\"\"\n",
    "    The goal of this function is to load the original dataset, split it into accepts and rejects,\n",
    "    add ids, which can later be used for merging. For the rejects to further perform train / test split\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    df : name of the original dataset in quotation marks, csv format\n",
    "    accepted_flag: name of the accepted flag; Binary: 1 if accepted, 0 if rejected\n",
    "    target : name of the target column\n",
    "    train_ratio : percentage used for training; Continuous (0,1)\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    a : accepted data\n",
    "    r : rejected data\n",
    "    r_dev : rejected trainining data without label\n",
    "    r_test : rejected testing data without label\n",
    "    dfr_dev_with_label: rejected training data with label\n",
    "    dft_test_with_label: rejected training data with label\n",
    "\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    data = pd.read_csv(\"C:/Users/Asus/Desktop/Repo/MasterThesis_RI/Sample_18_06/\" + df)\n",
    "\n",
    "    # Accepted\n",
    "\n",
    "    ## Create separate dataset with accepts\n",
    "    dfa = data[data[accepted_flag] == 1]\n",
    "    dfa = dfa.drop([accepted_flag], axis=1)\n",
    "    ## Rename target variable as \"target\"\n",
    "    dfa = dfa.rename(columns={target: \"target\"})\n",
    "    ## Add id to the dataset, which can later be used for merging\n",
    "    # dfa[\"id\"] = dfa.index.to_series().map(lambda x: uuid.uuid4())\n",
    "\n",
    "    # Rejected\n",
    "\n",
    "    ## Create separate dataset with accepts\n",
    "    dfr = data[data[accepted_flag] == 0]\n",
    "    dfr = dfr.drop([accepted_flag], axis=1)\n",
    "    ## Add id to the dataset, which can later be used for merging\n",
    "    #     dfr[\"id\"] = dfr.index.to_series().map(lambda x: uuid.uuid4())\n",
    "    ## Train/Test Split (without labels)\n",
    "    ### Shuffle the dataset\n",
    "    shuffle_df = dfr.sample(frac=1, random_state=42)\n",
    "    ### Define a size for the train set\n",
    "    train_size = int(train_ratio * len(shuffle_df))\n",
    "    ### Split the dataset\n",
    "    dfr_dev = shuffle_df[:train_size]\n",
    "    dfr_test = shuffle_df[train_size:]\n",
    "    ## Save a copy of the rejected data with label\n",
    "    dfr_dev_with_label = dfr_dev\n",
    "    dfr_test_with_label = dfr_test\n",
    "    ## Unlabel the rejects (i.e. drop the target) and save a copy of the rejeted data without label\n",
    "    dfr_dev2 = dfr_dev_with_label.drop([target], axis=1)\n",
    "    dfr_test2 = dfr_test_with_label.drop([target], axis=1)\n",
    "    # Rename target variable\n",
    "    dfr_dev_with_label = dfr_dev_with_label.rename(columns={target: \"target\"})\n",
    "    dfr_test_with_label = dfr_test_with_label.rename(columns={target: \"target\"})\n",
    "\n",
    "    return dfr_dev_with_label, dfr_test_with_label, dfa, dfr, dfr_dev2, dfr_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 187;\n",
       "                var nbb_unformatted_code = \"dfr_dev_with_label, dfr_test_with_label, a, r, r_dev, r_test = data_preprocessing(\\n    \\\"linear_10dr_20rr.csv\\\", \\\"is_selected\\\", \\\"y\\\", 0.8\\n)\";\n",
       "                var nbb_formatted_code = \"dfr_dev_with_label, dfr_test_with_label, a, r, r_dev, r_test = data_preprocessing(\\n    \\\"linear_10dr_20rr.csv\\\", \\\"is_selected\\\", \\\"y\\\", 0.8\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 187;\n",
       "                var nbb_unformatted_code = \"dfr_dev_with_label, dfr_test_with_label, a, r, r_dev, r_test = data_preprocessing(\\n    \\\"linear_10dr_20rr.csv\\\", \\\"is_selected\\\", \\\"y\\\", 0.8\\n)\";\n",
       "                var nbb_formatted_code = \"dfr_dev_with_label, dfr_test_with_label, a, r, r_dev, r_test = data_preprocessing(\\n    \\\"linear_10dr_20rr.csv\\\", \\\"is_selected\\\", \\\"y\\\", 0.8\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 187;\n",
       "                var nbb_unformatted_code = \"dfr_dev_with_label, dfr_test_with_label, a, r, r_dev, r_test = data_preprocessing(\\n    \\\"linear_10dr_20rr.csv\\\", \\\"is_selected\\\", \\\"y\\\", 0.8\\n)\";\n",
       "                var nbb_formatted_code = \"dfr_dev_with_label, dfr_test_with_label, a, r, r_dev, r_test = data_preprocessing(\\n    \\\"linear_10dr_20rr.csv\\\", \\\"is_selected\\\", \\\"y\\\", 0.8\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 187;\n",
       "                var nbb_unformatted_code = \"dfr_dev_with_label, dfr_test_with_label, a, r, r_dev, r_test = data_preprocessing(\\n    \\\"linear_10dr_20rr.csv\\\", \\\"is_selected\\\", \\\"y\\\", 0.8\\n)\";\n",
       "                var nbb_formatted_code = \"dfr_dev_with_label, dfr_test_with_label, a, r, r_dev, r_test = data_preprocessing(\\n    \\\"linear_10dr_20rr.csv\\\", \\\"is_selected\\\", \\\"y\\\", 0.8\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 187;\n",
       "                var nbb_unformatted_code = \"dfr_dev_with_label, dfr_test_with_label, a, r, r_dev, r_test = data_preprocessing(\\n    \\\"linear_10dr_20rr.csv\\\", \\\"is_selected\\\", \\\"y\\\", 0.8\\n)\";\n",
       "                var nbb_formatted_code = \"dfr_dev_with_label, dfr_test_with_label, a, r, r_dev, r_test = data_preprocessing(\\n    \\\"linear_10dr_20rr.csv\\\", \\\"is_selected\\\", \\\"y\\\", 0.8\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 187;\n",
       "                var nbb_unformatted_code = \"dfr_dev_with_label, dfr_test_with_label, a, r, r_dev, r_test = data_preprocessing(\\n    \\\"linear_10dr_20rr.csv\\\", \\\"is_selected\\\", \\\"y\\\", 0.8\\n)\";\n",
       "                var nbb_formatted_code = \"dfr_dev_with_label, dfr_test_with_label, a, r, r_dev, r_test = data_preprocessing(\\n    \\\"linear_10dr_20rr.csv\\\", \\\"is_selected\\\", \\\"y\\\", 0.8\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfr_dev_with_label, dfr_test_with_label, a, r, r_dev, r_test = data_preprocessing(\n",
    "    \"linear_10dr_20rr.csv\", \"is_selected\", \"y\", 0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below two functions continue the data preprocessing. Used to create feature and target data and to split into train and test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 188;\n",
       "                var nbb_unformatted_code = \"def create_X_y(data):\\n    \\\"\\\"\\\"\\n    Undersample the data\\n\\n    Parameters\\n    ----------\\n    data : Dataframe\\n\\n    Return\\n    ------\\n    X_res : undersampled data; Dataframe\\n    y_res : undersampled labels; Dataframe\\n\\n    \\\"\\\"\\\"\\n    # Create X and y\\n    X = data.loc[:, data.columns != \\\"target\\\"]\\n    y = data.loc[:, data.columns == \\\"target\\\"]\\n\\n    return X, y\";\n",
       "                var nbb_formatted_code = \"def create_X_y(data):\\n    \\\"\\\"\\\"\\n    Undersample the data\\n\\n    Parameters\\n    ----------\\n    data : Dataframe\\n\\n    Return\\n    ------\\n    X_res : undersampled data; Dataframe\\n    y_res : undersampled labels; Dataframe\\n\\n    \\\"\\\"\\\"\\n    # Create X and y\\n    X = data.loc[:, data.columns != \\\"target\\\"]\\n    y = data.loc[:, data.columns == \\\"target\\\"]\\n\\n    return X, y\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 188;\n",
       "                var nbb_unformatted_code = \"def create_X_y(data):\\n    \\\"\\\"\\\"\\n    Undersample the data\\n\\n    Parameters\\n    ----------\\n    data : Dataframe\\n\\n    Return\\n    ------\\n    X_res : undersampled data; Dataframe\\n    y_res : undersampled labels; Dataframe\\n\\n    \\\"\\\"\\\"\\n    # Create X and y\\n    X = data.loc[:, data.columns != \\\"target\\\"]\\n    y = data.loc[:, data.columns == \\\"target\\\"]\\n\\n    return X, y\";\n",
       "                var nbb_formatted_code = \"def create_X_y(data):\\n    \\\"\\\"\\\"\\n    Undersample the data\\n\\n    Parameters\\n    ----------\\n    data : Dataframe\\n\\n    Return\\n    ------\\n    X_res : undersampled data; Dataframe\\n    y_res : undersampled labels; Dataframe\\n\\n    \\\"\\\"\\\"\\n    # Create X and y\\n    X = data.loc[:, data.columns != \\\"target\\\"]\\n    y = data.loc[:, data.columns == \\\"target\\\"]\\n\\n    return X, y\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 188;\n",
       "                var nbb_unformatted_code = \"def create_X_y(data):\\n    \\\"\\\"\\\"\\n    Undersample the data\\n\\n    Parameters\\n    ----------\\n    data : Dataframe\\n\\n    Return\\n    ------\\n    X_res : undersampled data; Dataframe\\n    y_res : undersampled labels; Dataframe\\n\\n    \\\"\\\"\\\"\\n    # Create X and y\\n    X = data.loc[:, data.columns != \\\"target\\\"]\\n    y = data.loc[:, data.columns == \\\"target\\\"]\\n\\n    return X, y\";\n",
       "                var nbb_formatted_code = \"def create_X_y(data):\\n    \\\"\\\"\\\"\\n    Undersample the data\\n\\n    Parameters\\n    ----------\\n    data : Dataframe\\n\\n    Return\\n    ------\\n    X_res : undersampled data; Dataframe\\n    y_res : undersampled labels; Dataframe\\n\\n    \\\"\\\"\\\"\\n    # Create X and y\\n    X = data.loc[:, data.columns != \\\"target\\\"]\\n    y = data.loc[:, data.columns == \\\"target\\\"]\\n\\n    return X, y\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 188;\n",
       "                var nbb_unformatted_code = \"def create_X_y(data):\\n    \\\"\\\"\\\"\\n    Undersample the data\\n\\n    Parameters\\n    ----------\\n    data : Dataframe\\n\\n    Return\\n    ------\\n    X_res : undersampled data; Dataframe\\n    y_res : undersampled labels; Dataframe\\n\\n    \\\"\\\"\\\"\\n    # Create X and y\\n    X = data.loc[:, data.columns != \\\"target\\\"]\\n    y = data.loc[:, data.columns == \\\"target\\\"]\\n\\n    return X, y\";\n",
       "                var nbb_formatted_code = \"def create_X_y(data):\\n    \\\"\\\"\\\"\\n    Undersample the data\\n\\n    Parameters\\n    ----------\\n    data : Dataframe\\n\\n    Return\\n    ------\\n    X_res : undersampled data; Dataframe\\n    y_res : undersampled labels; Dataframe\\n\\n    \\\"\\\"\\\"\\n    # Create X and y\\n    X = data.loc[:, data.columns != \\\"target\\\"]\\n    y = data.loc[:, data.columns == \\\"target\\\"]\\n\\n    return X, y\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 188;\n",
       "                var nbb_unformatted_code = \"def create_X_y(data):\\n    \\\"\\\"\\\"\\n    Undersample the data\\n\\n    Parameters\\n    ----------\\n    data : Dataframe\\n\\n    Return\\n    ------\\n    X_res : undersampled data; Dataframe\\n    y_res : undersampled labels; Dataframe\\n\\n    \\\"\\\"\\\"\\n    # Create X and y\\n    X = data.loc[:, data.columns != \\\"target\\\"]\\n    y = data.loc[:, data.columns == \\\"target\\\"]\\n\\n    return X, y\";\n",
       "                var nbb_formatted_code = \"def create_X_y(data):\\n    \\\"\\\"\\\"\\n    Undersample the data\\n\\n    Parameters\\n    ----------\\n    data : Dataframe\\n\\n    Return\\n    ------\\n    X_res : undersampled data; Dataframe\\n    y_res : undersampled labels; Dataframe\\n\\n    \\\"\\\"\\\"\\n    # Create X and y\\n    X = data.loc[:, data.columns != \\\"target\\\"]\\n    y = data.loc[:, data.columns == \\\"target\\\"]\\n\\n    return X, y\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 188;\n",
       "                var nbb_unformatted_code = \"def create_X_y(data):\\n    \\\"\\\"\\\"\\n    Undersample the data\\n\\n    Parameters\\n    ----------\\n    data : Dataframe\\n\\n    Return\\n    ------\\n    X_res : undersampled data; Dataframe\\n    y_res : undersampled labels; Dataframe\\n\\n    \\\"\\\"\\\"\\n    # Create X and y\\n    X = data.loc[:, data.columns != \\\"target\\\"]\\n    y = data.loc[:, data.columns == \\\"target\\\"]\\n\\n    return X, y\";\n",
       "                var nbb_formatted_code = \"def create_X_y(data):\\n    \\\"\\\"\\\"\\n    Undersample the data\\n\\n    Parameters\\n    ----------\\n    data : Dataframe\\n\\n    Return\\n    ------\\n    X_res : undersampled data; Dataframe\\n    y_res : undersampled labels; Dataframe\\n\\n    \\\"\\\"\\\"\\n    # Create X and y\\n    X = data.loc[:, data.columns != \\\"target\\\"]\\n    y = data.loc[:, data.columns == \\\"target\\\"]\\n\\n    return X, y\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_X_y(data):\n",
    "    \"\"\"\n",
    "    Undersample the data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Dataframe\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    X_res : undersampled data; Dataframe\n",
    "    y_res : undersampled labels; Dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    # Create X and y\n",
    "    X = data.loc[:, data.columns != \"target\"]\n",
    "    y = data.loc[:, data.columns == \"target\"]\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 189;\n",
       "                var nbb_unformatted_code = \"def split(X, y):\\n    \\\"\\\"\\\"\\n    Split the data into training and testing sample\\n\\n    Parameters\\n    ----------\\n    X : data\\n    y : labels\\n\\n    Return\\n    ------\\n    X_train : training modelling fields\\n    X_test : test modelling fields\\n    y_train : training labels\\n    y_test : testing labels\\n\\n    \\\"\\\"\\\"\\n    # Train-Test Split\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        X_res, y_res, test_size=0.2, random_state=42\\n    )\\n    columns = X_train.columns\\n\\n    # Columns\\n    X_train = pd.DataFrame(data=X_train, columns=columns)\\n    y_train = pd.DataFrame(data=y_train, columns=[\\\"target\\\"])\\n\\n    return X_train, X_test, y_train, y_test\";\n",
       "                var nbb_formatted_code = \"def split(X, y):\\n    \\\"\\\"\\\"\\n    Split the data into training and testing sample\\n\\n    Parameters\\n    ----------\\n    X : data\\n    y : labels\\n\\n    Return\\n    ------\\n    X_train : training modelling fields\\n    X_test : test modelling fields\\n    y_train : training labels\\n    y_test : testing labels\\n\\n    \\\"\\\"\\\"\\n    # Train-Test Split\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        X_res, y_res, test_size=0.2, random_state=42\\n    )\\n    columns = X_train.columns\\n\\n    # Columns\\n    X_train = pd.DataFrame(data=X_train, columns=columns)\\n    y_train = pd.DataFrame(data=y_train, columns=[\\\"target\\\"])\\n\\n    return X_train, X_test, y_train, y_test\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 189;\n",
       "                var nbb_unformatted_code = \"def split(X, y):\\n    \\\"\\\"\\\"\\n    Split the data into training and testing sample\\n\\n    Parameters\\n    ----------\\n    X : data\\n    y : labels\\n\\n    Return\\n    ------\\n    X_train : training modelling fields\\n    X_test : test modelling fields\\n    y_train : training labels\\n    y_test : testing labels\\n\\n    \\\"\\\"\\\"\\n    # Train-Test Split\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        X_res, y_res, test_size=0.2, random_state=42\\n    )\\n    columns = X_train.columns\\n\\n    # Columns\\n    X_train = pd.DataFrame(data=X_train, columns=columns)\\n    y_train = pd.DataFrame(data=y_train, columns=[\\\"target\\\"])\\n\\n    return X_train, X_test, y_train, y_test\";\n",
       "                var nbb_formatted_code = \"def split(X, y):\\n    \\\"\\\"\\\"\\n    Split the data into training and testing sample\\n\\n    Parameters\\n    ----------\\n    X : data\\n    y : labels\\n\\n    Return\\n    ------\\n    X_train : training modelling fields\\n    X_test : test modelling fields\\n    y_train : training labels\\n    y_test : testing labels\\n\\n    \\\"\\\"\\\"\\n    # Train-Test Split\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        X_res, y_res, test_size=0.2, random_state=42\\n    )\\n    columns = X_train.columns\\n\\n    # Columns\\n    X_train = pd.DataFrame(data=X_train, columns=columns)\\n    y_train = pd.DataFrame(data=y_train, columns=[\\\"target\\\"])\\n\\n    return X_train, X_test, y_train, y_test\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 189;\n",
       "                var nbb_unformatted_code = \"def split(X, y):\\n    \\\"\\\"\\\"\\n    Split the data into training and testing sample\\n\\n    Parameters\\n    ----------\\n    X : data\\n    y : labels\\n\\n    Return\\n    ------\\n    X_train : training modelling fields\\n    X_test : test modelling fields\\n    y_train : training labels\\n    y_test : testing labels\\n\\n    \\\"\\\"\\\"\\n    # Train-Test Split\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        X_res, y_res, test_size=0.2, random_state=42\\n    )\\n    columns = X_train.columns\\n\\n    # Columns\\n    X_train = pd.DataFrame(data=X_train, columns=columns)\\n    y_train = pd.DataFrame(data=y_train, columns=[\\\"target\\\"])\\n\\n    return X_train, X_test, y_train, y_test\";\n",
       "                var nbb_formatted_code = \"def split(X, y):\\n    \\\"\\\"\\\"\\n    Split the data into training and testing sample\\n\\n    Parameters\\n    ----------\\n    X : data\\n    y : labels\\n\\n    Return\\n    ------\\n    X_train : training modelling fields\\n    X_test : test modelling fields\\n    y_train : training labels\\n    y_test : testing labels\\n\\n    \\\"\\\"\\\"\\n    # Train-Test Split\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        X_res, y_res, test_size=0.2, random_state=42\\n    )\\n    columns = X_train.columns\\n\\n    # Columns\\n    X_train = pd.DataFrame(data=X_train, columns=columns)\\n    y_train = pd.DataFrame(data=y_train, columns=[\\\"target\\\"])\\n\\n    return X_train, X_test, y_train, y_test\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 189;\n",
       "                var nbb_unformatted_code = \"def split(X, y):\\n    \\\"\\\"\\\"\\n    Split the data into training and testing sample\\n\\n    Parameters\\n    ----------\\n    X : data\\n    y : labels\\n\\n    Return\\n    ------\\n    X_train : training modelling fields\\n    X_test : test modelling fields\\n    y_train : training labels\\n    y_test : testing labels\\n\\n    \\\"\\\"\\\"\\n    # Train-Test Split\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        X_res, y_res, test_size=0.2, random_state=42\\n    )\\n    columns = X_train.columns\\n\\n    # Columns\\n    X_train = pd.DataFrame(data=X_train, columns=columns)\\n    y_train = pd.DataFrame(data=y_train, columns=[\\\"target\\\"])\\n\\n    return X_train, X_test, y_train, y_test\";\n",
       "                var nbb_formatted_code = \"def split(X, y):\\n    \\\"\\\"\\\"\\n    Split the data into training and testing sample\\n\\n    Parameters\\n    ----------\\n    X : data\\n    y : labels\\n\\n    Return\\n    ------\\n    X_train : training modelling fields\\n    X_test : test modelling fields\\n    y_train : training labels\\n    y_test : testing labels\\n\\n    \\\"\\\"\\\"\\n    # Train-Test Split\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        X_res, y_res, test_size=0.2, random_state=42\\n    )\\n    columns = X_train.columns\\n\\n    # Columns\\n    X_train = pd.DataFrame(data=X_train, columns=columns)\\n    y_train = pd.DataFrame(data=y_train, columns=[\\\"target\\\"])\\n\\n    return X_train, X_test, y_train, y_test\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 189;\n",
       "                var nbb_unformatted_code = \"def split(X, y):\\n    \\\"\\\"\\\"\\n    Split the data into training and testing sample\\n\\n    Parameters\\n    ----------\\n    X : data\\n    y : labels\\n\\n    Return\\n    ------\\n    X_train : training modelling fields\\n    X_test : test modelling fields\\n    y_train : training labels\\n    y_test : testing labels\\n\\n    \\\"\\\"\\\"\\n    # Train-Test Split\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        X_res, y_res, test_size=0.2, random_state=42\\n    )\\n    columns = X_train.columns\\n\\n    # Columns\\n    X_train = pd.DataFrame(data=X_train, columns=columns)\\n    y_train = pd.DataFrame(data=y_train, columns=[\\\"target\\\"])\\n\\n    return X_train, X_test, y_train, y_test\";\n",
       "                var nbb_formatted_code = \"def split(X, y):\\n    \\\"\\\"\\\"\\n    Split the data into training and testing sample\\n\\n    Parameters\\n    ----------\\n    X : data\\n    y : labels\\n\\n    Return\\n    ------\\n    X_train : training modelling fields\\n    X_test : test modelling fields\\n    y_train : training labels\\n    y_test : testing labels\\n\\n    \\\"\\\"\\\"\\n    # Train-Test Split\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        X_res, y_res, test_size=0.2, random_state=42\\n    )\\n    columns = X_train.columns\\n\\n    # Columns\\n    X_train = pd.DataFrame(data=X_train, columns=columns)\\n    y_train = pd.DataFrame(data=y_train, columns=[\\\"target\\\"])\\n\\n    return X_train, X_test, y_train, y_test\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 189;\n",
       "                var nbb_unformatted_code = \"def split(X, y):\\n    \\\"\\\"\\\"\\n    Split the data into training and testing sample\\n\\n    Parameters\\n    ----------\\n    X : data\\n    y : labels\\n\\n    Return\\n    ------\\n    X_train : training modelling fields\\n    X_test : test modelling fields\\n    y_train : training labels\\n    y_test : testing labels\\n\\n    \\\"\\\"\\\"\\n    # Train-Test Split\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        X_res, y_res, test_size=0.2, random_state=42\\n    )\\n    columns = X_train.columns\\n\\n    # Columns\\n    X_train = pd.DataFrame(data=X_train, columns=columns)\\n    y_train = pd.DataFrame(data=y_train, columns=[\\\"target\\\"])\\n\\n    return X_train, X_test, y_train, y_test\";\n",
       "                var nbb_formatted_code = \"def split(X, y):\\n    \\\"\\\"\\\"\\n    Split the data into training and testing sample\\n\\n    Parameters\\n    ----------\\n    X : data\\n    y : labels\\n\\n    Return\\n    ------\\n    X_train : training modelling fields\\n    X_test : test modelling fields\\n    y_train : training labels\\n    y_test : testing labels\\n\\n    \\\"\\\"\\\"\\n    # Train-Test Split\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        X_res, y_res, test_size=0.2, random_state=42\\n    )\\n    columns = X_train.columns\\n\\n    # Columns\\n    X_train = pd.DataFrame(data=X_train, columns=columns)\\n    y_train = pd.DataFrame(data=y_train, columns=[\\\"target\\\"])\\n\\n    return X_train, X_test, y_train, y_test\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def split(X, y):\n",
    "    \"\"\"\n",
    "    Split the data into training and testing sample\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : data\n",
    "    y : labels\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    X_train : training modelling fields\n",
    "    X_test : test modelling fields\n",
    "    y_train : training labels\n",
    "    y_test : testing labels\n",
    "\n",
    "    \"\"\"\n",
    "    # Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_res, y_res, test_size=0.2, random_state=42\n",
    "    )\n",
    "    columns = X_train.columns\n",
    "\n",
    "    # Columns\n",
    "    X_train = pd.DataFrame(data=X_train, columns=columns)\n",
    "    y_train = pd.DataFrame(data=y_train, columns=[\"target\"])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 190;\n",
       "                var nbb_unformatted_code = \"X_res, y_res = create_X_y(a)\\nX_train, X_test, y_train, y_test = split(X_res, y_res)\\ndfr_test_with_label_X = dfr_test_with_label.loc[:, dfr_test_with_label.columns != \\\"y\\\"]\\ndfr_test_with_label_y = dfr_test_with_label.loc[:, dfr_test_with_label.columns == \\\"y\\\"]\";\n",
       "                var nbb_formatted_code = \"X_res, y_res = create_X_y(a)\\nX_train, X_test, y_train, y_test = split(X_res, y_res)\\ndfr_test_with_label_X = dfr_test_with_label.loc[:, dfr_test_with_label.columns != \\\"y\\\"]\\ndfr_test_with_label_y = dfr_test_with_label.loc[:, dfr_test_with_label.columns == \\\"y\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 190;\n",
       "                var nbb_unformatted_code = \"X_res, y_res = create_X_y(a)\\nX_train, X_test, y_train, y_test = split(X_res, y_res)\\ndfr_test_with_label_X = dfr_test_with_label.loc[:, dfr_test_with_label.columns != \\\"y\\\"]\\ndfr_test_with_label_y = dfr_test_with_label.loc[:, dfr_test_with_label.columns == \\\"y\\\"]\";\n",
       "                var nbb_formatted_code = \"X_res, y_res = create_X_y(a)\\nX_train, X_test, y_train, y_test = split(X_res, y_res)\\ndfr_test_with_label_X = dfr_test_with_label.loc[:, dfr_test_with_label.columns != \\\"y\\\"]\\ndfr_test_with_label_y = dfr_test_with_label.loc[:, dfr_test_with_label.columns == \\\"y\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 190;\n",
       "                var nbb_unformatted_code = \"X_res, y_res = create_X_y(a)\\nX_train, X_test, y_train, y_test = split(X_res, y_res)\\ndfr_test_with_label_X = dfr_test_with_label.loc[:, dfr_test_with_label.columns != \\\"y\\\"]\\ndfr_test_with_label_y = dfr_test_with_label.loc[:, dfr_test_with_label.columns == \\\"y\\\"]\";\n",
       "                var nbb_formatted_code = \"X_res, y_res = create_X_y(a)\\nX_train, X_test, y_train, y_test = split(X_res, y_res)\\ndfr_test_with_label_X = dfr_test_with_label.loc[:, dfr_test_with_label.columns != \\\"y\\\"]\\ndfr_test_with_label_y = dfr_test_with_label.loc[:, dfr_test_with_label.columns == \\\"y\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 190;\n",
       "                var nbb_unformatted_code = \"X_res, y_res = create_X_y(a)\\nX_train, X_test, y_train, y_test = split(X_res, y_res)\\ndfr_test_with_label_X = dfr_test_with_label.loc[:, dfr_test_with_label.columns != \\\"y\\\"]\\ndfr_test_with_label_y = dfr_test_with_label.loc[:, dfr_test_with_label.columns == \\\"y\\\"]\";\n",
       "                var nbb_formatted_code = \"X_res, y_res = create_X_y(a)\\nX_train, X_test, y_train, y_test = split(X_res, y_res)\\ndfr_test_with_label_X = dfr_test_with_label.loc[:, dfr_test_with_label.columns != \\\"y\\\"]\\ndfr_test_with_label_y = dfr_test_with_label.loc[:, dfr_test_with_label.columns == \\\"y\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 190;\n",
       "                var nbb_unformatted_code = \"X_res, y_res = create_X_y(a)\\nX_train, X_test, y_train, y_test = split(X_res, y_res)\\ndfr_test_with_label_X = dfr_test_with_label.loc[:, dfr_test_with_label.columns != \\\"y\\\"]\\ndfr_test_with_label_y = dfr_test_with_label.loc[:, dfr_test_with_label.columns == \\\"y\\\"]\";\n",
       "                var nbb_formatted_code = \"X_res, y_res = create_X_y(a)\\nX_train, X_test, y_train, y_test = split(X_res, y_res)\\ndfr_test_with_label_X = dfr_test_with_label.loc[:, dfr_test_with_label.columns != \\\"y\\\"]\\ndfr_test_with_label_y = dfr_test_with_label.loc[:, dfr_test_with_label.columns == \\\"y\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 190;\n",
       "                var nbb_unformatted_code = \"X_res, y_res = create_X_y(a)\\nX_train, X_test, y_train, y_test = split(X_res, y_res)\\ndfr_test_with_label_X = dfr_test_with_label.loc[:, dfr_test_with_label.columns != \\\"y\\\"]\\ndfr_test_with_label_y = dfr_test_with_label.loc[:, dfr_test_with_label.columns == \\\"y\\\"]\";\n",
       "                var nbb_formatted_code = \"X_res, y_res = create_X_y(a)\\nX_train, X_test, y_train, y_test = split(X_res, y_res)\\ndfr_test_with_label_X = dfr_test_with_label.loc[:, dfr_test_with_label.columns != \\\"y\\\"]\\ndfr_test_with_label_y = dfr_test_with_label.loc[:, dfr_test_with_label.columns == \\\"y\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_res, y_res = create_X_y(a)\n",
    "X_train, X_test, y_train, y_test = split(X_res, y_res)\n",
    "dfr_test_with_label_X = dfr_test_with_label.loc[:, dfr_test_with_label.columns != \"y\"]\n",
    "dfr_test_with_label_y = dfr_test_with_label.loc[:, dfr_test_with_label.columns == \"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we select the features that will end up in the model. The selection of columns below is subject to iteration based on the modelling outcomes from the logistic regression, i.e. significance (p-values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 191;\n",
       "                var nbb_unformatted_code = \"significant_columns = [\\\"col_0\\\", \\\"col_1\\\"]\";\n",
       "                var nbb_formatted_code = \"significant_columns = [\\\"col_0\\\", \\\"col_1\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 191;\n",
       "                var nbb_unformatted_code = \"significant_columns = [\\\"col_0\\\", \\\"col_1\\\"]\";\n",
       "                var nbb_formatted_code = \"significant_columns = [\\\"col_0\\\", \\\"col_1\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 191;\n",
       "                var nbb_unformatted_code = \"significant_columns = [\\\"col_0\\\", \\\"col_1\\\"]\";\n",
       "                var nbb_formatted_code = \"significant_columns = [\\\"col_0\\\", \\\"col_1\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 191;\n",
       "                var nbb_unformatted_code = \"significant_columns = [\\\"col_0\\\", \\\"col_1\\\"]\";\n",
       "                var nbb_formatted_code = \"significant_columns = [\\\"col_0\\\", \\\"col_1\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 191;\n",
       "                var nbb_unformatted_code = \"significant_columns = [\\\"col_0\\\", \\\"col_1\\\"]\";\n",
       "                var nbb_formatted_code = \"significant_columns = [\\\"col_0\\\", \\\"col_1\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 191;\n",
       "                var nbb_unformatted_code = \"significant_columns = [\\\"col_0\\\", \\\"col_1\\\"]\";\n",
       "                var nbb_formatted_code = \"significant_columns = [\\\"col_0\\\", \\\"col_1\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "significant_columns = [\"col_0\", \"col_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 192;\n",
       "                var nbb_unformatted_code = \"X_train2 = X_train.copy()\\ny_train2 = y_train.copy()\\nX_test2 = X_test.copy()\\ny_test2 = y_test.copy()\\nr_dev2 = r_dev.copy()\\nr_test2 = r_test.copy()\";\n",
       "                var nbb_formatted_code = \"X_train2 = X_train.copy()\\ny_train2 = y_train.copy()\\nX_test2 = X_test.copy()\\ny_test2 = y_test.copy()\\nr_dev2 = r_dev.copy()\\nr_test2 = r_test.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 192;\n",
       "                var nbb_unformatted_code = \"X_train2 = X_train.copy()\\ny_train2 = y_train.copy()\\nX_test2 = X_test.copy()\\ny_test2 = y_test.copy()\\nr_dev2 = r_dev.copy()\\nr_test2 = r_test.copy()\";\n",
       "                var nbb_formatted_code = \"X_train2 = X_train.copy()\\ny_train2 = y_train.copy()\\nX_test2 = X_test.copy()\\ny_test2 = y_test.copy()\\nr_dev2 = r_dev.copy()\\nr_test2 = r_test.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 192;\n",
       "                var nbb_unformatted_code = \"X_train2 = X_train.copy()\\ny_train2 = y_train.copy()\\nX_test2 = X_test.copy()\\ny_test2 = y_test.copy()\\nr_dev2 = r_dev.copy()\\nr_test2 = r_test.copy()\";\n",
       "                var nbb_formatted_code = \"X_train2 = X_train.copy()\\ny_train2 = y_train.copy()\\nX_test2 = X_test.copy()\\ny_test2 = y_test.copy()\\nr_dev2 = r_dev.copy()\\nr_test2 = r_test.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 192;\n",
       "                var nbb_unformatted_code = \"X_train2 = X_train.copy()\\ny_train2 = y_train.copy()\\nX_test2 = X_test.copy()\\ny_test2 = y_test.copy()\\nr_dev2 = r_dev.copy()\\nr_test2 = r_test.copy()\";\n",
       "                var nbb_formatted_code = \"X_train2 = X_train.copy()\\ny_train2 = y_train.copy()\\nX_test2 = X_test.copy()\\ny_test2 = y_test.copy()\\nr_dev2 = r_dev.copy()\\nr_test2 = r_test.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 192;\n",
       "                var nbb_unformatted_code = \"X_train2 = X_train.copy()\\ny_train2 = y_train.copy()\\nX_test2 = X_test.copy()\\ny_test2 = y_test.copy()\\nr_dev2 = r_dev.copy()\\nr_test2 = r_test.copy()\";\n",
       "                var nbb_formatted_code = \"X_train2 = X_train.copy()\\ny_train2 = y_train.copy()\\nX_test2 = X_test.copy()\\ny_test2 = y_test.copy()\\nr_dev2 = r_dev.copy()\\nr_test2 = r_test.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 192;\n",
       "                var nbb_unformatted_code = \"X_train2 = X_train.copy()\\ny_train2 = y_train.copy()\\nX_test2 = X_test.copy()\\ny_test2 = y_test.copy()\\nr_dev2 = r_dev.copy()\\nr_test2 = r_test.copy()\";\n",
       "                var nbb_formatted_code = \"X_train2 = X_train.copy()\\ny_train2 = y_train.copy()\\nX_test2 = X_test.copy()\\ny_test2 = y_test.copy()\\nr_dev2 = r_dev.copy()\\nr_test2 = r_test.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train2 = X_train.copy()\n",
    "y_train2 = y_train.copy()\n",
    "X_test2 = X_test.copy()\n",
    "y_test2 = y_test.copy()\n",
    "r_dev2 = r_dev.copy()\n",
    "r_test2 = r_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 193;\n",
       "                var nbb_unformatted_code = \"# Primary datasets\\nX_train = X_train[significant_columns]\\nX_test = X_test[significant_columns]\\nr_dev = r_dev[significant_columns]\\nr_test = r_test[significant_columns]\";\n",
       "                var nbb_formatted_code = \"# Primary datasets\\nX_train = X_train[significant_columns]\\nX_test = X_test[significant_columns]\\nr_dev = r_dev[significant_columns]\\nr_test = r_test[significant_columns]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 193;\n",
       "                var nbb_unformatted_code = \"# Primary datasets\\nX_train = X_train[significant_columns]\\nX_test = X_test[significant_columns]\\nr_dev = r_dev[significant_columns]\\nr_test = r_test[significant_columns]\";\n",
       "                var nbb_formatted_code = \"# Primary datasets\\nX_train = X_train[significant_columns]\\nX_test = X_test[significant_columns]\\nr_dev = r_dev[significant_columns]\\nr_test = r_test[significant_columns]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 193;\n",
       "                var nbb_unformatted_code = \"# Primary datasets\\nX_train = X_train[significant_columns]\\nX_test = X_test[significant_columns]\\nr_dev = r_dev[significant_columns]\\nr_test = r_test[significant_columns]\";\n",
       "                var nbb_formatted_code = \"# Primary datasets\\nX_train = X_train[significant_columns]\\nX_test = X_test[significant_columns]\\nr_dev = r_dev[significant_columns]\\nr_test = r_test[significant_columns]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 193;\n",
       "                var nbb_unformatted_code = \"# Primary datasets\\nX_train = X_train[significant_columns]\\nX_test = X_test[significant_columns]\\nr_dev = r_dev[significant_columns]\\nr_test = r_test[significant_columns]\";\n",
       "                var nbb_formatted_code = \"# Primary datasets\\nX_train = X_train[significant_columns]\\nX_test = X_test[significant_columns]\\nr_dev = r_dev[significant_columns]\\nr_test = r_test[significant_columns]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 193;\n",
       "                var nbb_unformatted_code = \"# Primary datasets\\nX_train = X_train[significant_columns]\\nX_test = X_test[significant_columns]\\nr_dev = r_dev[significant_columns]\\nr_test = r_test[significant_columns]\";\n",
       "                var nbb_formatted_code = \"# Primary datasets\\nX_train = X_train[significant_columns]\\nX_test = X_test[significant_columns]\\nr_dev = r_dev[significant_columns]\\nr_test = r_test[significant_columns]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 193;\n",
       "                var nbb_unformatted_code = \"# Primary datasets\\nX_train = X_train[significant_columns]\\nX_test = X_test[significant_columns]\\nr_dev = r_dev[significant_columns]\\nr_test = r_test[significant_columns]\";\n",
       "                var nbb_formatted_code = \"# Primary datasets\\nX_train = X_train[significant_columns]\\nX_test = X_test[significant_columns]\\nr_dev = r_dev[significant_columns]\\nr_test = r_test[significant_columns]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Primary datasets\n",
    "X_train = X_train[significant_columns]\n",
    "X_test = X_test[significant_columns]\n",
    "r_dev = r_dev[significant_columns]\n",
    "r_test = r_test[significant_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.122138\n",
      "         Iterations 10\n",
      "                         Results: Logit\n",
      "================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.422    \n",
      "Dependent Variable: target           AIC:              3132.7362\n",
      "Date:               2021-06-20 16:19 BIC:              3155.1078\n",
      "No. Observations:   12800            Log-Likelihood:   -1563.4  \n",
      "Df Model:           2                LL-Null:          -2706.2  \n",
      "Df Residuals:       12797            LLR p-value:      0.0000   \n",
      "Converged:          1.0000           Scale:            1.0000   \n",
      "No. Iterations:     10.0000                                     \n",
      "------------------------------------------------------------------\n",
      "         Coef.    Std.Err.      z       P>|z|     [0.025    0.975]\n",
      "------------------------------------------------------------------\n",
      "const   -7.9963     0.3191   -25.0550   0.0000   -8.6218   -7.3708\n",
      "col_0   -5.4237     0.2767   -19.6020   0.0000   -5.9660   -4.8814\n",
      "col_1   11.0741     0.3946    28.0612   0.0000   10.3006   11.8476\n",
      "================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 194;\n",
       "                var nbb_unformatted_code = \"# Build Logistic regression\\n# Statmodels\\nX_in = sm.add_constant(X_train.astype(float))\\nlogit_model = sm.Logit(y_train, X_in)\\nresult3 = logit_model.fit()\\nprint(result3.summary2())\";\n",
       "                var nbb_formatted_code = \"# Build Logistic regression\\n# Statmodels\\nX_in = sm.add_constant(X_train.astype(float))\\nlogit_model = sm.Logit(y_train, X_in)\\nresult3 = logit_model.fit()\\nprint(result3.summary2())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 194;\n",
       "                var nbb_unformatted_code = \"# Build Logistic regression\\n# Statmodels\\nX_in = sm.add_constant(X_train.astype(float))\\nlogit_model = sm.Logit(y_train, X_in)\\nresult3 = logit_model.fit()\\nprint(result3.summary2())\";\n",
       "                var nbb_formatted_code = \"# Build Logistic regression\\n# Statmodels\\nX_in = sm.add_constant(X_train.astype(float))\\nlogit_model = sm.Logit(y_train, X_in)\\nresult3 = logit_model.fit()\\nprint(result3.summary2())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 194;\n",
       "                var nbb_unformatted_code = \"# Build Logistic regression\\n# Statmodels\\nX_in = sm.add_constant(X_train.astype(float))\\nlogit_model = sm.Logit(y_train, X_in)\\nresult3 = logit_model.fit()\\nprint(result3.summary2())\";\n",
       "                var nbb_formatted_code = \"# Build Logistic regression\\n# Statmodels\\nX_in = sm.add_constant(X_train.astype(float))\\nlogit_model = sm.Logit(y_train, X_in)\\nresult3 = logit_model.fit()\\nprint(result3.summary2())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 194;\n",
       "                var nbb_unformatted_code = \"# Build Logistic regression\\n# Statmodels\\nX_in = sm.add_constant(X_train.astype(float))\\nlogit_model = sm.Logit(y_train, X_in)\\nresult3 = logit_model.fit()\\nprint(result3.summary2())\";\n",
       "                var nbb_formatted_code = \"# Build Logistic regression\\n# Statmodels\\nX_in = sm.add_constant(X_train.astype(float))\\nlogit_model = sm.Logit(y_train, X_in)\\nresult3 = logit_model.fit()\\nprint(result3.summary2())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 194;\n",
       "                var nbb_unformatted_code = \"# Build Logistic regression\\n# Statmodels\\nX_in = sm.add_constant(X_train.astype(float))\\nlogit_model = sm.Logit(y_train, X_in)\\nresult3 = logit_model.fit()\\nprint(result3.summary2())\";\n",
       "                var nbb_formatted_code = \"# Build Logistic regression\\n# Statmodels\\nX_in = sm.add_constant(X_train.astype(float))\\nlogit_model = sm.Logit(y_train, X_in)\\nresult3 = logit_model.fit()\\nprint(result3.summary2())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 194;\n",
       "                var nbb_unformatted_code = \"# Build Logistic regression\\n# Statmodels\\nX_in = sm.add_constant(X_train.astype(float))\\nlogit_model = sm.Logit(y_train, X_in)\\nresult3 = logit_model.fit()\\nprint(result3.summary2())\";\n",
       "                var nbb_formatted_code = \"# Build Logistic regression\\n# Statmodels\\nX_in = sm.add_constant(X_train.astype(float))\\nlogit_model = sm.Logit(y_train, X_in)\\nresult3 = logit_model.fit()\\nprint(result3.summary2())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build Logistic regression\n",
    "# Statmodels\n",
    "X_in = sm.add_constant(X_train.astype(float))\n",
    "logit_model = sm.Logit(y_train, X_in)\n",
    "result3 = logit_model.fit()\n",
    "print(result3.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 195;\n",
       "                var nbb_unformatted_code = \"# Calculate Default Rates\\ndr = len(y_test[y_test[\\\"target\\\"] == 1]) / (\\n    len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0])\\n)\\nconservative_dr = (\\n    1.25\\n    * len(y_test[y_test[\\\"target\\\"] == 1])\\n    / (len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0]))\\n)\";\n",
       "                var nbb_formatted_code = \"# Calculate Default Rates\\ndr = len(y_test[y_test[\\\"target\\\"] == 1]) / (\\n    len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0])\\n)\\nconservative_dr = (\\n    1.25\\n    * len(y_test[y_test[\\\"target\\\"] == 1])\\n    / (len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0]))\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 195;\n",
       "                var nbb_unformatted_code = \"# Calculate Default Rates\\ndr = len(y_test[y_test[\\\"target\\\"] == 1]) / (\\n    len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0])\\n)\\nconservative_dr = (\\n    1.25\\n    * len(y_test[y_test[\\\"target\\\"] == 1])\\n    / (len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0]))\\n)\";\n",
       "                var nbb_formatted_code = \"# Calculate Default Rates\\ndr = len(y_test[y_test[\\\"target\\\"] == 1]) / (\\n    len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0])\\n)\\nconservative_dr = (\\n    1.25\\n    * len(y_test[y_test[\\\"target\\\"] == 1])\\n    / (len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0]))\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 195;\n",
       "                var nbb_unformatted_code = \"# Calculate Default Rates\\ndr = len(y_test[y_test[\\\"target\\\"] == 1]) / (\\n    len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0])\\n)\\nconservative_dr = (\\n    1.25\\n    * len(y_test[y_test[\\\"target\\\"] == 1])\\n    / (len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0]))\\n)\";\n",
       "                var nbb_formatted_code = \"# Calculate Default Rates\\ndr = len(y_test[y_test[\\\"target\\\"] == 1]) / (\\n    len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0])\\n)\\nconservative_dr = (\\n    1.25\\n    * len(y_test[y_test[\\\"target\\\"] == 1])\\n    / (len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0]))\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 195;\n",
       "                var nbb_unformatted_code = \"# Calculate Default Rates\\ndr = len(y_test[y_test[\\\"target\\\"] == 1]) / (\\n    len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0])\\n)\\nconservative_dr = (\\n    1.25\\n    * len(y_test[y_test[\\\"target\\\"] == 1])\\n    / (len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0]))\\n)\";\n",
       "                var nbb_formatted_code = \"# Calculate Default Rates\\ndr = len(y_test[y_test[\\\"target\\\"] == 1]) / (\\n    len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0])\\n)\\nconservative_dr = (\\n    1.25\\n    * len(y_test[y_test[\\\"target\\\"] == 1])\\n    / (len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0]))\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 195;\n",
       "                var nbb_unformatted_code = \"# Calculate Default Rates\\ndr = len(y_test[y_test[\\\"target\\\"] == 1]) / (\\n    len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0])\\n)\\nconservative_dr = (\\n    1.25\\n    * len(y_test[y_test[\\\"target\\\"] == 1])\\n    / (len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0]))\\n)\";\n",
       "                var nbb_formatted_code = \"# Calculate Default Rates\\ndr = len(y_test[y_test[\\\"target\\\"] == 1]) / (\\n    len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0])\\n)\\nconservative_dr = (\\n    1.25\\n    * len(y_test[y_test[\\\"target\\\"] == 1])\\n    / (len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0]))\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 195;\n",
       "                var nbb_unformatted_code = \"# Calculate Default Rates\\ndr = len(y_test[y_test[\\\"target\\\"] == 1]) / (\\n    len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0])\\n)\\nconservative_dr = (\\n    1.25\\n    * len(y_test[y_test[\\\"target\\\"] == 1])\\n    / (len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0]))\\n)\";\n",
       "                var nbb_formatted_code = \"# Calculate Default Rates\\ndr = len(y_test[y_test[\\\"target\\\"] == 1]) / (\\n    len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0])\\n)\\nconservative_dr = (\\n    1.25\\n    * len(y_test[y_test[\\\"target\\\"] == 1])\\n    / (len(y_test[y_test[\\\"target\\\"] == 1]) + len(y_test[y_test[\\\"target\\\"] == 0]))\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate Default Rates\n",
    "dr = len(y_test[y_test[\"target\"] == 1]) / (\n",
    "    len(y_test[y_test[\"target\"] == 1]) + len(y_test[y_test[\"target\"] == 0])\n",
    ")\n",
    "conservative_dr = (\n",
    "    1.25\n",
    "    * len(y_test[y_test[\"target\"] == 1])\n",
    "    / (len(y_test[y_test[\"target\"] == 1]) + len(y_test[y_test[\"target\"] == 0]))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For rejects, another step of data preporcessing is applied via Isolation Forest model. The goal is to remove outliers. The isolation forest is trained on all accepts and is used to evaluate the similarity of the rejects. Then the rejects that are found to be the most and least similar to the accepts are dropped. The contaimination parameter determines how many observations are excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 196;\n",
       "                var nbb_unformatted_code = \"# def isolation_forest(X_train, r_dev, r_test):\\n#     \\\"\\\"\\\"\\n#     The goal of this function is to filter the outliers from the rejected sample.\\n\\n#     Parameters\\n#     ----------\\n#     X_train: accepts training data; Dataframe\\n#     r_dev_mod: rejects modelling data prior outlier treatment; Dataframe\\n#     r_test_mod: rejects testinf data prior outlier treatment; Dataframe\\n\\n#     Return\\n#     ------\\n#     r_dev_mod: rejects modelling data post outlier treatment; Dataframe\\n#     r_test_mod: rejects training data prior outlier treatment; Dataframe\\n\\n#     \\\"\\\"\\\"\\n\\n#     # Build Isolation forest model\\n#     isf = IsolationForest(\\n#         n_estimators=50,\\n#         max_samples=\\\"auto\\\",\\n#         contamination=float(0.005),\\n#         max_features=1.0,\\n#     )\\n#     isf.fit(X_train)\\n#     rej_isf = isf.predict(r_dev)\\n#     # Add scores and anomaly columns to rejected train\\n#     r_dev[\\\"scores\\\"] = isf.decision_function(r_dev)\\n#     r_dev[\\\"anomaly\\\"] = isf.predict(r_dev[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Train. Number of non-outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Train. Number of outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_dev = r_dev[r_dev.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_dev = r_dev[significant_columns]\\n\\n#     # Add scores and anomaly columns to rejected test\\n#     r_test[\\\"scores\\\"] = isf.decision_function(r_test)\\n#     r_test[\\\"anomaly\\\"] = isf.predict(r_test[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Test. Number of non-outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Test. Number of outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_test = r_test[r_test.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_test = r_test[significant_columns]\\n\\n#     return r_dev, r_test\";\n",
       "                var nbb_formatted_code = \"# def isolation_forest(X_train, r_dev, r_test):\\n#     \\\"\\\"\\\"\\n#     The goal of this function is to filter the outliers from the rejected sample.\\n\\n#     Parameters\\n#     ----------\\n#     X_train: accepts training data; Dataframe\\n#     r_dev_mod: rejects modelling data prior outlier treatment; Dataframe\\n#     r_test_mod: rejects testinf data prior outlier treatment; Dataframe\\n\\n#     Return\\n#     ------\\n#     r_dev_mod: rejects modelling data post outlier treatment; Dataframe\\n#     r_test_mod: rejects training data prior outlier treatment; Dataframe\\n\\n#     \\\"\\\"\\\"\\n\\n#     # Build Isolation forest model\\n#     isf = IsolationForest(\\n#         n_estimators=50,\\n#         max_samples=\\\"auto\\\",\\n#         contamination=float(0.005),\\n#         max_features=1.0,\\n#     )\\n#     isf.fit(X_train)\\n#     rej_isf = isf.predict(r_dev)\\n#     # Add scores and anomaly columns to rejected train\\n#     r_dev[\\\"scores\\\"] = isf.decision_function(r_dev)\\n#     r_dev[\\\"anomaly\\\"] = isf.predict(r_dev[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Train. Number of non-outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Train. Number of outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_dev = r_dev[r_dev.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_dev = r_dev[significant_columns]\\n\\n#     # Add scores and anomaly columns to rejected test\\n#     r_test[\\\"scores\\\"] = isf.decision_function(r_test)\\n#     r_test[\\\"anomaly\\\"] = isf.predict(r_test[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Test. Number of non-outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Test. Number of outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_test = r_test[r_test.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_test = r_test[significant_columns]\\n\\n#     return r_dev, r_test\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 196;\n",
       "                var nbb_unformatted_code = \"# def isolation_forest(X_train, r_dev, r_test):\\n#     \\\"\\\"\\\"\\n#     The goal of this function is to filter the outliers from the rejected sample.\\n\\n#     Parameters\\n#     ----------\\n#     X_train: accepts training data; Dataframe\\n#     r_dev_mod: rejects modelling data prior outlier treatment; Dataframe\\n#     r_test_mod: rejects testinf data prior outlier treatment; Dataframe\\n\\n#     Return\\n#     ------\\n#     r_dev_mod: rejects modelling data post outlier treatment; Dataframe\\n#     r_test_mod: rejects training data prior outlier treatment; Dataframe\\n\\n#     \\\"\\\"\\\"\\n\\n#     # Build Isolation forest model\\n#     isf = IsolationForest(\\n#         n_estimators=50,\\n#         max_samples=\\\"auto\\\",\\n#         contamination=float(0.005),\\n#         max_features=1.0,\\n#     )\\n#     isf.fit(X_train)\\n#     rej_isf = isf.predict(r_dev)\\n#     # Add scores and anomaly columns to rejected train\\n#     r_dev[\\\"scores\\\"] = isf.decision_function(r_dev)\\n#     r_dev[\\\"anomaly\\\"] = isf.predict(r_dev[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Train. Number of non-outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Train. Number of outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_dev = r_dev[r_dev.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_dev = r_dev[significant_columns]\\n\\n#     # Add scores and anomaly columns to rejected test\\n#     r_test[\\\"scores\\\"] = isf.decision_function(r_test)\\n#     r_test[\\\"anomaly\\\"] = isf.predict(r_test[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Test. Number of non-outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Test. Number of outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_test = r_test[r_test.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_test = r_test[significant_columns]\\n\\n#     return r_dev, r_test\";\n",
       "                var nbb_formatted_code = \"# def isolation_forest(X_train, r_dev, r_test):\\n#     \\\"\\\"\\\"\\n#     The goal of this function is to filter the outliers from the rejected sample.\\n\\n#     Parameters\\n#     ----------\\n#     X_train: accepts training data; Dataframe\\n#     r_dev_mod: rejects modelling data prior outlier treatment; Dataframe\\n#     r_test_mod: rejects testinf data prior outlier treatment; Dataframe\\n\\n#     Return\\n#     ------\\n#     r_dev_mod: rejects modelling data post outlier treatment; Dataframe\\n#     r_test_mod: rejects training data prior outlier treatment; Dataframe\\n\\n#     \\\"\\\"\\\"\\n\\n#     # Build Isolation forest model\\n#     isf = IsolationForest(\\n#         n_estimators=50,\\n#         max_samples=\\\"auto\\\",\\n#         contamination=float(0.005),\\n#         max_features=1.0,\\n#     )\\n#     isf.fit(X_train)\\n#     rej_isf = isf.predict(r_dev)\\n#     # Add scores and anomaly columns to rejected train\\n#     r_dev[\\\"scores\\\"] = isf.decision_function(r_dev)\\n#     r_dev[\\\"anomaly\\\"] = isf.predict(r_dev[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Train. Number of non-outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Train. Number of outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_dev = r_dev[r_dev.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_dev = r_dev[significant_columns]\\n\\n#     # Add scores and anomaly columns to rejected test\\n#     r_test[\\\"scores\\\"] = isf.decision_function(r_test)\\n#     r_test[\\\"anomaly\\\"] = isf.predict(r_test[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Test. Number of non-outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Test. Number of outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_test = r_test[r_test.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_test = r_test[significant_columns]\\n\\n#     return r_dev, r_test\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 196;\n",
       "                var nbb_unformatted_code = \"# def isolation_forest(X_train, r_dev, r_test):\\n#     \\\"\\\"\\\"\\n#     The goal of this function is to filter the outliers from the rejected sample.\\n\\n#     Parameters\\n#     ----------\\n#     X_train: accepts training data; Dataframe\\n#     r_dev_mod: rejects modelling data prior outlier treatment; Dataframe\\n#     r_test_mod: rejects testinf data prior outlier treatment; Dataframe\\n\\n#     Return\\n#     ------\\n#     r_dev_mod: rejects modelling data post outlier treatment; Dataframe\\n#     r_test_mod: rejects training data prior outlier treatment; Dataframe\\n\\n#     \\\"\\\"\\\"\\n\\n#     # Build Isolation forest model\\n#     isf = IsolationForest(\\n#         n_estimators=50,\\n#         max_samples=\\\"auto\\\",\\n#         contamination=float(0.005),\\n#         max_features=1.0,\\n#     )\\n#     isf.fit(X_train)\\n#     rej_isf = isf.predict(r_dev)\\n#     # Add scores and anomaly columns to rejected train\\n#     r_dev[\\\"scores\\\"] = isf.decision_function(r_dev)\\n#     r_dev[\\\"anomaly\\\"] = isf.predict(r_dev[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Train. Number of non-outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Train. Number of outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_dev = r_dev[r_dev.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_dev = r_dev[significant_columns]\\n\\n#     # Add scores and anomaly columns to rejected test\\n#     r_test[\\\"scores\\\"] = isf.decision_function(r_test)\\n#     r_test[\\\"anomaly\\\"] = isf.predict(r_test[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Test. Number of non-outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Test. Number of outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_test = r_test[r_test.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_test = r_test[significant_columns]\\n\\n#     return r_dev, r_test\";\n",
       "                var nbb_formatted_code = \"# def isolation_forest(X_train, r_dev, r_test):\\n#     \\\"\\\"\\\"\\n#     The goal of this function is to filter the outliers from the rejected sample.\\n\\n#     Parameters\\n#     ----------\\n#     X_train: accepts training data; Dataframe\\n#     r_dev_mod: rejects modelling data prior outlier treatment; Dataframe\\n#     r_test_mod: rejects testinf data prior outlier treatment; Dataframe\\n\\n#     Return\\n#     ------\\n#     r_dev_mod: rejects modelling data post outlier treatment; Dataframe\\n#     r_test_mod: rejects training data prior outlier treatment; Dataframe\\n\\n#     \\\"\\\"\\\"\\n\\n#     # Build Isolation forest model\\n#     isf = IsolationForest(\\n#         n_estimators=50,\\n#         max_samples=\\\"auto\\\",\\n#         contamination=float(0.005),\\n#         max_features=1.0,\\n#     )\\n#     isf.fit(X_train)\\n#     rej_isf = isf.predict(r_dev)\\n#     # Add scores and anomaly columns to rejected train\\n#     r_dev[\\\"scores\\\"] = isf.decision_function(r_dev)\\n#     r_dev[\\\"anomaly\\\"] = isf.predict(r_dev[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Train. Number of non-outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Train. Number of outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_dev = r_dev[r_dev.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_dev = r_dev[significant_columns]\\n\\n#     # Add scores and anomaly columns to rejected test\\n#     r_test[\\\"scores\\\"] = isf.decision_function(r_test)\\n#     r_test[\\\"anomaly\\\"] = isf.predict(r_test[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Test. Number of non-outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Test. Number of outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_test = r_test[r_test.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_test = r_test[significant_columns]\\n\\n#     return r_dev, r_test\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 196;\n",
       "                var nbb_unformatted_code = \"# def isolation_forest(X_train, r_dev, r_test):\\n#     \\\"\\\"\\\"\\n#     The goal of this function is to filter the outliers from the rejected sample.\\n\\n#     Parameters\\n#     ----------\\n#     X_train: accepts training data; Dataframe\\n#     r_dev_mod: rejects modelling data prior outlier treatment; Dataframe\\n#     r_test_mod: rejects testinf data prior outlier treatment; Dataframe\\n\\n#     Return\\n#     ------\\n#     r_dev_mod: rejects modelling data post outlier treatment; Dataframe\\n#     r_test_mod: rejects training data prior outlier treatment; Dataframe\\n\\n#     \\\"\\\"\\\"\\n\\n#     # Build Isolation forest model\\n#     isf = IsolationForest(\\n#         n_estimators=50,\\n#         max_samples=\\\"auto\\\",\\n#         contamination=float(0.005),\\n#         max_features=1.0,\\n#     )\\n#     isf.fit(X_train)\\n#     rej_isf = isf.predict(r_dev)\\n#     # Add scores and anomaly columns to rejected train\\n#     r_dev[\\\"scores\\\"] = isf.decision_function(r_dev)\\n#     r_dev[\\\"anomaly\\\"] = isf.predict(r_dev[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Train. Number of non-outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Train. Number of outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_dev = r_dev[r_dev.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_dev = r_dev[significant_columns]\\n\\n#     # Add scores and anomaly columns to rejected test\\n#     r_test[\\\"scores\\\"] = isf.decision_function(r_test)\\n#     r_test[\\\"anomaly\\\"] = isf.predict(r_test[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Test. Number of non-outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Test. Number of outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_test = r_test[r_test.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_test = r_test[significant_columns]\\n\\n#     return r_dev, r_test\";\n",
       "                var nbb_formatted_code = \"# def isolation_forest(X_train, r_dev, r_test):\\n#     \\\"\\\"\\\"\\n#     The goal of this function is to filter the outliers from the rejected sample.\\n\\n#     Parameters\\n#     ----------\\n#     X_train: accepts training data; Dataframe\\n#     r_dev_mod: rejects modelling data prior outlier treatment; Dataframe\\n#     r_test_mod: rejects testinf data prior outlier treatment; Dataframe\\n\\n#     Return\\n#     ------\\n#     r_dev_mod: rejects modelling data post outlier treatment; Dataframe\\n#     r_test_mod: rejects training data prior outlier treatment; Dataframe\\n\\n#     \\\"\\\"\\\"\\n\\n#     # Build Isolation forest model\\n#     isf = IsolationForest(\\n#         n_estimators=50,\\n#         max_samples=\\\"auto\\\",\\n#         contamination=float(0.005),\\n#         max_features=1.0,\\n#     )\\n#     isf.fit(X_train)\\n#     rej_isf = isf.predict(r_dev)\\n#     # Add scores and anomaly columns to rejected train\\n#     r_dev[\\\"scores\\\"] = isf.decision_function(r_dev)\\n#     r_dev[\\\"anomaly\\\"] = isf.predict(r_dev[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Train. Number of non-outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Train. Number of outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_dev = r_dev[r_dev.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_dev = r_dev[significant_columns]\\n\\n#     # Add scores and anomaly columns to rejected test\\n#     r_test[\\\"scores\\\"] = isf.decision_function(r_test)\\n#     r_test[\\\"anomaly\\\"] = isf.predict(r_test[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Test. Number of non-outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Test. Number of outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_test = r_test[r_test.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_test = r_test[significant_columns]\\n\\n#     return r_dev, r_test\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 196;\n",
       "                var nbb_unformatted_code = \"# def isolation_forest(X_train, r_dev, r_test):\\n#     \\\"\\\"\\\"\\n#     The goal of this function is to filter the outliers from the rejected sample.\\n\\n#     Parameters\\n#     ----------\\n#     X_train: accepts training data; Dataframe\\n#     r_dev_mod: rejects modelling data prior outlier treatment; Dataframe\\n#     r_test_mod: rejects testinf data prior outlier treatment; Dataframe\\n\\n#     Return\\n#     ------\\n#     r_dev_mod: rejects modelling data post outlier treatment; Dataframe\\n#     r_test_mod: rejects training data prior outlier treatment; Dataframe\\n\\n#     \\\"\\\"\\\"\\n\\n#     # Build Isolation forest model\\n#     isf = IsolationForest(\\n#         n_estimators=50,\\n#         max_samples=\\\"auto\\\",\\n#         contamination=float(0.005),\\n#         max_features=1.0,\\n#     )\\n#     isf.fit(X_train)\\n#     rej_isf = isf.predict(r_dev)\\n#     # Add scores and anomaly columns to rejected train\\n#     r_dev[\\\"scores\\\"] = isf.decision_function(r_dev)\\n#     r_dev[\\\"anomaly\\\"] = isf.predict(r_dev[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Train. Number of non-outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Train. Number of outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_dev = r_dev[r_dev.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_dev = r_dev[significant_columns]\\n\\n#     # Add scores and anomaly columns to rejected test\\n#     r_test[\\\"scores\\\"] = isf.decision_function(r_test)\\n#     r_test[\\\"anomaly\\\"] = isf.predict(r_test[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Test. Number of non-outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Test. Number of outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_test = r_test[r_test.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_test = r_test[significant_columns]\\n\\n#     return r_dev, r_test\";\n",
       "                var nbb_formatted_code = \"# def isolation_forest(X_train, r_dev, r_test):\\n#     \\\"\\\"\\\"\\n#     The goal of this function is to filter the outliers from the rejected sample.\\n\\n#     Parameters\\n#     ----------\\n#     X_train: accepts training data; Dataframe\\n#     r_dev_mod: rejects modelling data prior outlier treatment; Dataframe\\n#     r_test_mod: rejects testinf data prior outlier treatment; Dataframe\\n\\n#     Return\\n#     ------\\n#     r_dev_mod: rejects modelling data post outlier treatment; Dataframe\\n#     r_test_mod: rejects training data prior outlier treatment; Dataframe\\n\\n#     \\\"\\\"\\\"\\n\\n#     # Build Isolation forest model\\n#     isf = IsolationForest(\\n#         n_estimators=50,\\n#         max_samples=\\\"auto\\\",\\n#         contamination=float(0.005),\\n#         max_features=1.0,\\n#     )\\n#     isf.fit(X_train)\\n#     rej_isf = isf.predict(r_dev)\\n#     # Add scores and anomaly columns to rejected train\\n#     r_dev[\\\"scores\\\"] = isf.decision_function(r_dev)\\n#     r_dev[\\\"anomaly\\\"] = isf.predict(r_dev[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Train. Number of non-outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Train. Number of outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_dev = r_dev[r_dev.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_dev = r_dev[significant_columns]\\n\\n#     # Add scores and anomaly columns to rejected test\\n#     r_test[\\\"scores\\\"] = isf.decision_function(r_test)\\n#     r_test[\\\"anomaly\\\"] = isf.predict(r_test[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Test. Number of non-outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Test. Number of outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_test = r_test[r_test.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_test = r_test[significant_columns]\\n\\n#     return r_dev, r_test\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 196;\n",
       "                var nbb_unformatted_code = \"# def isolation_forest(X_train, r_dev, r_test):\\n#     \\\"\\\"\\\"\\n#     The goal of this function is to filter the outliers from the rejected sample.\\n\\n#     Parameters\\n#     ----------\\n#     X_train: accepts training data; Dataframe\\n#     r_dev_mod: rejects modelling data prior outlier treatment; Dataframe\\n#     r_test_mod: rejects testinf data prior outlier treatment; Dataframe\\n\\n#     Return\\n#     ------\\n#     r_dev_mod: rejects modelling data post outlier treatment; Dataframe\\n#     r_test_mod: rejects training data prior outlier treatment; Dataframe\\n\\n#     \\\"\\\"\\\"\\n\\n#     # Build Isolation forest model\\n#     isf = IsolationForest(\\n#         n_estimators=50,\\n#         max_samples=\\\"auto\\\",\\n#         contamination=float(0.005),\\n#         max_features=1.0,\\n#     )\\n#     isf.fit(X_train)\\n#     rej_isf = isf.predict(r_dev)\\n#     # Add scores and anomaly columns to rejected train\\n#     r_dev[\\\"scores\\\"] = isf.decision_function(r_dev)\\n#     r_dev[\\\"anomaly\\\"] = isf.predict(r_dev[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Train. Number of non-outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Train. Number of outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_dev = r_dev[r_dev.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_dev = r_dev[significant_columns]\\n\\n#     # Add scores and anomaly columns to rejected test\\n#     r_test[\\\"scores\\\"] = isf.decision_function(r_test)\\n#     r_test[\\\"anomaly\\\"] = isf.predict(r_test[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Test. Number of non-outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Test. Number of outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_test = r_test[r_test.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_test = r_test[significant_columns]\\n\\n#     return r_dev, r_test\";\n",
       "                var nbb_formatted_code = \"# def isolation_forest(X_train, r_dev, r_test):\\n#     \\\"\\\"\\\"\\n#     The goal of this function is to filter the outliers from the rejected sample.\\n\\n#     Parameters\\n#     ----------\\n#     X_train: accepts training data; Dataframe\\n#     r_dev_mod: rejects modelling data prior outlier treatment; Dataframe\\n#     r_test_mod: rejects testinf data prior outlier treatment; Dataframe\\n\\n#     Return\\n#     ------\\n#     r_dev_mod: rejects modelling data post outlier treatment; Dataframe\\n#     r_test_mod: rejects training data prior outlier treatment; Dataframe\\n\\n#     \\\"\\\"\\\"\\n\\n#     # Build Isolation forest model\\n#     isf = IsolationForest(\\n#         n_estimators=50,\\n#         max_samples=\\\"auto\\\",\\n#         contamination=float(0.005),\\n#         max_features=1.0,\\n#     )\\n#     isf.fit(X_train)\\n#     rej_isf = isf.predict(r_dev)\\n#     # Add scores and anomaly columns to rejected train\\n#     r_dev[\\\"scores\\\"] = isf.decision_function(r_dev)\\n#     r_dev[\\\"anomaly\\\"] = isf.predict(r_dev[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Train. Number of non-outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Train. Number of outliers is:\\\", np.sum(r_dev[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_dev = r_dev[r_dev.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_dev = r_dev[significant_columns]\\n\\n#     # Add scores and anomaly columns to rejected test\\n#     r_test[\\\"scores\\\"] = isf.decision_function(r_test)\\n#     r_test[\\\"anomaly\\\"] = isf.predict(r_test[significant_columns])\\n#     # Print number of non-outliers and outliers\\n#     print(\\\"Rejected Test. Number of non-outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == 1))\\n#     print(\\\"Rejected Test. Number of outliers is:\\\", np.sum(r_test[\\\"anomaly\\\"] == -1))\\n#     # Drop all outliers\\n#     r_test = r_test[r_test.anomaly != -1]\\n#     # Delete columns related to the outliers\\n#     r_test = r_test[significant_columns]\\n\\n#     return r_dev, r_test\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def isolation_forest(X_train, r_dev, r_test):\n",
    "#     \"\"\"\n",
    "#     The goal of this function is to filter the outliers from the rejected sample.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     X_train: accepts training data; Dataframe\n",
    "#     r_dev_mod: rejects modelling data prior outlier treatment; Dataframe\n",
    "#     r_test_mod: rejects testinf data prior outlier treatment; Dataframe\n",
    "\n",
    "#     Return\n",
    "#     ------\n",
    "#     r_dev_mod: rejects modelling data post outlier treatment; Dataframe\n",
    "#     r_test_mod: rejects training data prior outlier treatment; Dataframe\n",
    "\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Build Isolation forest model\n",
    "#     isf = IsolationForest(\n",
    "#         n_estimators=50,\n",
    "#         max_samples=\"auto\",\n",
    "#         contamination=float(0.005),\n",
    "#         max_features=1.0,\n",
    "#     )\n",
    "#     isf.fit(X_train)\n",
    "#     rej_isf = isf.predict(r_dev)\n",
    "#     # Add scores and anomaly columns to rejected train\n",
    "#     r_dev[\"scores\"] = isf.decision_function(r_dev)\n",
    "#     r_dev[\"anomaly\"] = isf.predict(r_dev[significant_columns])\n",
    "#     # Print number of non-outliers and outliers\n",
    "#     print(\"Rejected Train. Number of non-outliers is:\", np.sum(r_dev[\"anomaly\"] == 1))\n",
    "#     print(\"Rejected Train. Number of outliers is:\", np.sum(r_dev[\"anomaly\"] == -1))\n",
    "#     # Drop all outliers\n",
    "#     r_dev = r_dev[r_dev.anomaly != -1]\n",
    "#     # Delete columns related to the outliers\n",
    "#     r_dev = r_dev[significant_columns]\n",
    "\n",
    "#     # Add scores and anomaly columns to rejected test\n",
    "#     r_test[\"scores\"] = isf.decision_function(r_test)\n",
    "#     r_test[\"anomaly\"] = isf.predict(r_test[significant_columns])\n",
    "#     # Print number of non-outliers and outliers\n",
    "#     print(\"Rejected Test. Number of non-outliers is:\", np.sum(r_test[\"anomaly\"] == 1))\n",
    "#     print(\"Rejected Test. Number of outliers is:\", np.sum(r_test[\"anomaly\"] == -1))\n",
    "#     # Drop all outliers\n",
    "#     r_test = r_test[r_test.anomaly != -1]\n",
    "#     # Delete columns related to the outliers\n",
    "#     r_test = r_test[significant_columns]\n",
    "\n",
    "#     return r_dev, r_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 197;\n",
       "                var nbb_unformatted_code = \"# r_dev, r_test = isolation_forest(X_train, r_dev, r_test)\";\n",
       "                var nbb_formatted_code = \"# r_dev, r_test = isolation_forest(X_train, r_dev, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 197;\n",
       "                var nbb_unformatted_code = \"# r_dev, r_test = isolation_forest(X_train, r_dev, r_test)\";\n",
       "                var nbb_formatted_code = \"# r_dev, r_test = isolation_forest(X_train, r_dev, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 197;\n",
       "                var nbb_unformatted_code = \"# r_dev, r_test = isolation_forest(X_train, r_dev, r_test)\";\n",
       "                var nbb_formatted_code = \"# r_dev, r_test = isolation_forest(X_train, r_dev, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 197;\n",
       "                var nbb_unformatted_code = \"# r_dev, r_test = isolation_forest(X_train, r_dev, r_test)\";\n",
       "                var nbb_formatted_code = \"# r_dev, r_test = isolation_forest(X_train, r_dev, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 197;\n",
       "                var nbb_unformatted_code = \"# r_dev, r_test = isolation_forest(X_train, r_dev, r_test)\";\n",
       "                var nbb_formatted_code = \"# r_dev, r_test = isolation_forest(X_train, r_dev, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 197;\n",
       "                var nbb_unformatted_code = \"# r_dev, r_test = isolation_forest(X_train, r_dev, r_test)\";\n",
       "                var nbb_formatted_code = \"# r_dev, r_test = isolation_forest(X_train, r_dev, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# r_dev, r_test = isolation_forest(X_train, r_dev, r_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Training for the Most Certain examples with %DR as stopping criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 198;\n",
       "                var nbb_unformatted_code = \"X_train_iter = X_train.copy()\\ny_train_iter = y_train.copy()\\nr_dev_iter = r_dev.copy()\";\n",
       "                var nbb_formatted_code = \"X_train_iter = X_train.copy()\\ny_train_iter = y_train.copy()\\nr_dev_iter = r_dev.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 198;\n",
       "                var nbb_unformatted_code = \"X_train_iter = X_train.copy()\\ny_train_iter = y_train.copy()\\nr_dev_iter = r_dev.copy()\";\n",
       "                var nbb_formatted_code = \"X_train_iter = X_train.copy()\\ny_train_iter = y_train.copy()\\nr_dev_iter = r_dev.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 198;\n",
       "                var nbb_unformatted_code = \"X_train_iter = X_train.copy()\\ny_train_iter = y_train.copy()\\nr_dev_iter = r_dev.copy()\";\n",
       "                var nbb_formatted_code = \"X_train_iter = X_train.copy()\\ny_train_iter = y_train.copy()\\nr_dev_iter = r_dev.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 198;\n",
       "                var nbb_unformatted_code = \"X_train_iter = X_train.copy()\\ny_train_iter = y_train.copy()\\nr_dev_iter = r_dev.copy()\";\n",
       "                var nbb_formatted_code = \"X_train_iter = X_train.copy()\\ny_train_iter = y_train.copy()\\nr_dev_iter = r_dev.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 198;\n",
       "                var nbb_unformatted_code = \"X_train_iter = X_train.copy()\\ny_train_iter = y_train.copy()\\nr_dev_iter = r_dev.copy()\";\n",
       "                var nbb_formatted_code = \"X_train_iter = X_train.copy()\\ny_train_iter = y_train.copy()\\nr_dev_iter = r_dev.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 198;\n",
       "                var nbb_unformatted_code = \"X_train_iter = X_train.copy()\\ny_train_iter = y_train.copy()\\nr_dev_iter = r_dev.copy()\";\n",
       "                var nbb_formatted_code = \"X_train_iter = X_train.copy()\\ny_train_iter = y_train.copy()\\nr_dev_iter = r_dev.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_iter = X_train.copy()\n",
    "y_train_iter = y_train.copy()\n",
    "r_dev_iter = r_dev.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Nr 1\n",
      "3200\n",
      "MCC:  0.2797647164110619\n",
      "3041\n",
      "Iteration Nr 2\n",
      "3200\n",
      "MCC:  0.26297930390656493\n",
      "2449\n",
      "Iteration Nr 3\n",
      "3200\n",
      "MCC:  0.3018988042051179\n",
      "1973\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 199;\n",
       "                var nbb_unformatted_code = \"f1_scores = []\\nlog_losses = []\\nmccs = []\\niterations = []\\n\\niteration = 0\\nwhile 0.7 * len(r_dev) < len(r_dev_iter):\\n    iteration = iteration + 1\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    print(len(r_dev))\\n    # Build logistic regression\\n    KGB_new = RandomForestClassifier(random_state=42).fit(X_train_iter, y_train_iter)\\n    # KGB_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train_iter, y_train_iter)\\n\\n    # Scores\\n    mcc = matthews_corrcoef(y_test, KGB_new.predict(X_test))\\n    mccs.append(mcc)\\n\\n    print(\\\"MCC: \\\", mcc)\\n\\n    # Make predictions on the rejected data\\n    pred = KGB_new.predict_proba(r_dev_iter)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev_iter.index.copy(),\\n    )\\n\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.15)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n    # pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > np.random.uniform()) else 0)\\n\\n    # If PD is low, be conservative and apply non-default status only to some examples\\n    #     pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(\\n    #         lambda x: 0 if (x < np.random.uniform()) else 1\\n    #     )\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n    # print(len(certain))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev_iter[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\\n\\n    print(len(r_dev_iter))\";\n",
       "                var nbb_formatted_code = \"f1_scores = []\\nlog_losses = []\\nmccs = []\\niterations = []\\n\\niteration = 0\\nwhile 0.7 * len(r_dev) < len(r_dev_iter):\\n    iteration = iteration + 1\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    print(len(r_dev))\\n    # Build logistic regression\\n    KGB_new = RandomForestClassifier(random_state=42).fit(X_train_iter, y_train_iter)\\n    # KGB_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train_iter, y_train_iter)\\n\\n    # Scores\\n    mcc = matthews_corrcoef(y_test, KGB_new.predict(X_test))\\n    mccs.append(mcc)\\n\\n    print(\\\"MCC: \\\", mcc)\\n\\n    # Make predictions on the rejected data\\n    pred = KGB_new.predict_proba(r_dev_iter)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev_iter.index.copy(),\\n    )\\n\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.15)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n    # pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > np.random.uniform()) else 0)\\n\\n    # If PD is low, be conservative and apply non-default status only to some examples\\n    #     pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(\\n    #         lambda x: 0 if (x < np.random.uniform()) else 1\\n    #     )\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n    # print(len(certain))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev_iter[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\\n\\n    print(len(r_dev_iter))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 199;\n",
       "                var nbb_unformatted_code = \"f1_scores = []\\nlog_losses = []\\nmccs = []\\niterations = []\\n\\niteration = 0\\nwhile 0.7 * len(r_dev) < len(r_dev_iter):\\n    iteration = iteration + 1\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    print(len(r_dev))\\n    # Build logistic regression\\n    KGB_new = RandomForestClassifier(random_state=42).fit(X_train_iter, y_train_iter)\\n    # KGB_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train_iter, y_train_iter)\\n\\n    # Scores\\n    mcc = matthews_corrcoef(y_test, KGB_new.predict(X_test))\\n    mccs.append(mcc)\\n\\n    print(\\\"MCC: \\\", mcc)\\n\\n    # Make predictions on the rejected data\\n    pred = KGB_new.predict_proba(r_dev_iter)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev_iter.index.copy(),\\n    )\\n\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.15)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n    # pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > np.random.uniform()) else 0)\\n\\n    # If PD is low, be conservative and apply non-default status only to some examples\\n    #     pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(\\n    #         lambda x: 0 if (x < np.random.uniform()) else 1\\n    #     )\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n    # print(len(certain))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev_iter[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\\n\\n    print(len(r_dev_iter))\";\n",
       "                var nbb_formatted_code = \"f1_scores = []\\nlog_losses = []\\nmccs = []\\niterations = []\\n\\niteration = 0\\nwhile 0.7 * len(r_dev) < len(r_dev_iter):\\n    iteration = iteration + 1\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    print(len(r_dev))\\n    # Build logistic regression\\n    KGB_new = RandomForestClassifier(random_state=42).fit(X_train_iter, y_train_iter)\\n    # KGB_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train_iter, y_train_iter)\\n\\n    # Scores\\n    mcc = matthews_corrcoef(y_test, KGB_new.predict(X_test))\\n    mccs.append(mcc)\\n\\n    print(\\\"MCC: \\\", mcc)\\n\\n    # Make predictions on the rejected data\\n    pred = KGB_new.predict_proba(r_dev_iter)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev_iter.index.copy(),\\n    )\\n\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.15)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n    # pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > np.random.uniform()) else 0)\\n\\n    # If PD is low, be conservative and apply non-default status only to some examples\\n    #     pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(\\n    #         lambda x: 0 if (x < np.random.uniform()) else 1\\n    #     )\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n    # print(len(certain))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev_iter[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\\n\\n    print(len(r_dev_iter))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 199;\n",
       "                var nbb_unformatted_code = \"f1_scores = []\\nlog_losses = []\\nmccs = []\\niterations = []\\n\\niteration = 0\\nwhile 0.7 * len(r_dev) < len(r_dev_iter):\\n    iteration = iteration + 1\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    print(len(r_dev))\\n    # Build logistic regression\\n    KGB_new = RandomForestClassifier(random_state=42).fit(X_train_iter, y_train_iter)\\n    # KGB_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train_iter, y_train_iter)\\n\\n    # Scores\\n    mcc = matthews_corrcoef(y_test, KGB_new.predict(X_test))\\n    mccs.append(mcc)\\n\\n    print(\\\"MCC: \\\", mcc)\\n\\n    # Make predictions on the rejected data\\n    pred = KGB_new.predict_proba(r_dev_iter)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev_iter.index.copy(),\\n    )\\n\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.15)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n    # pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > np.random.uniform()) else 0)\\n\\n    # If PD is low, be conservative and apply non-default status only to some examples\\n    #     pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(\\n    #         lambda x: 0 if (x < np.random.uniform()) else 1\\n    #     )\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n    # print(len(certain))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev_iter[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\\n\\n    print(len(r_dev_iter))\";\n",
       "                var nbb_formatted_code = \"f1_scores = []\\nlog_losses = []\\nmccs = []\\niterations = []\\n\\niteration = 0\\nwhile 0.7 * len(r_dev) < len(r_dev_iter):\\n    iteration = iteration + 1\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    print(len(r_dev))\\n    # Build logistic regression\\n    KGB_new = RandomForestClassifier(random_state=42).fit(X_train_iter, y_train_iter)\\n    # KGB_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train_iter, y_train_iter)\\n\\n    # Scores\\n    mcc = matthews_corrcoef(y_test, KGB_new.predict(X_test))\\n    mccs.append(mcc)\\n\\n    print(\\\"MCC: \\\", mcc)\\n\\n    # Make predictions on the rejected data\\n    pred = KGB_new.predict_proba(r_dev_iter)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev_iter.index.copy(),\\n    )\\n\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.15)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n    # pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > np.random.uniform()) else 0)\\n\\n    # If PD is low, be conservative and apply non-default status only to some examples\\n    #     pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(\\n    #         lambda x: 0 if (x < np.random.uniform()) else 1\\n    #     )\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n    # print(len(certain))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev_iter[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\\n\\n    print(len(r_dev_iter))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 199;\n",
       "                var nbb_unformatted_code = \"f1_scores = []\\nlog_losses = []\\nmccs = []\\niterations = []\\n\\niteration = 0\\nwhile 0.7 * len(r_dev) < len(r_dev_iter):\\n    iteration = iteration + 1\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    print(len(r_dev))\\n    # Build logistic regression\\n    KGB_new = RandomForestClassifier(random_state=42).fit(X_train_iter, y_train_iter)\\n    # KGB_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train_iter, y_train_iter)\\n\\n    # Scores\\n    mcc = matthews_corrcoef(y_test, KGB_new.predict(X_test))\\n    mccs.append(mcc)\\n\\n    print(\\\"MCC: \\\", mcc)\\n\\n    # Make predictions on the rejected data\\n    pred = KGB_new.predict_proba(r_dev_iter)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev_iter.index.copy(),\\n    )\\n\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.15)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n    # pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > np.random.uniform()) else 0)\\n\\n    # If PD is low, be conservative and apply non-default status only to some examples\\n    #     pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(\\n    #         lambda x: 0 if (x < np.random.uniform()) else 1\\n    #     )\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n    # print(len(certain))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev_iter[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\\n\\n    print(len(r_dev_iter))\";\n",
       "                var nbb_formatted_code = \"f1_scores = []\\nlog_losses = []\\nmccs = []\\niterations = []\\n\\niteration = 0\\nwhile 0.7 * len(r_dev) < len(r_dev_iter):\\n    iteration = iteration + 1\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    print(len(r_dev))\\n    # Build logistic regression\\n    KGB_new = RandomForestClassifier(random_state=42).fit(X_train_iter, y_train_iter)\\n    # KGB_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train_iter, y_train_iter)\\n\\n    # Scores\\n    mcc = matthews_corrcoef(y_test, KGB_new.predict(X_test))\\n    mccs.append(mcc)\\n\\n    print(\\\"MCC: \\\", mcc)\\n\\n    # Make predictions on the rejected data\\n    pred = KGB_new.predict_proba(r_dev_iter)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev_iter.index.copy(),\\n    )\\n\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.15)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n    # pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > np.random.uniform()) else 0)\\n\\n    # If PD is low, be conservative and apply non-default status only to some examples\\n    #     pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(\\n    #         lambda x: 0 if (x < np.random.uniform()) else 1\\n    #     )\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n    # print(len(certain))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev_iter[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\\n\\n    print(len(r_dev_iter))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 199;\n",
       "                var nbb_unformatted_code = \"f1_scores = []\\nlog_losses = []\\nmccs = []\\niterations = []\\n\\niteration = 0\\nwhile 0.7 * len(r_dev) < len(r_dev_iter):\\n    iteration = iteration + 1\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    print(len(r_dev))\\n    # Build logistic regression\\n    KGB_new = RandomForestClassifier(random_state=42).fit(X_train_iter, y_train_iter)\\n    # KGB_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train_iter, y_train_iter)\\n\\n    # Scores\\n    mcc = matthews_corrcoef(y_test, KGB_new.predict(X_test))\\n    mccs.append(mcc)\\n\\n    print(\\\"MCC: \\\", mcc)\\n\\n    # Make predictions on the rejected data\\n    pred = KGB_new.predict_proba(r_dev_iter)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev_iter.index.copy(),\\n    )\\n\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.15)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n    # pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > np.random.uniform()) else 0)\\n\\n    # If PD is low, be conservative and apply non-default status only to some examples\\n    #     pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(\\n    #         lambda x: 0 if (x < np.random.uniform()) else 1\\n    #     )\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n    # print(len(certain))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev_iter[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\\n\\n    print(len(r_dev_iter))\";\n",
       "                var nbb_formatted_code = \"f1_scores = []\\nlog_losses = []\\nmccs = []\\niterations = []\\n\\niteration = 0\\nwhile 0.7 * len(r_dev) < len(r_dev_iter):\\n    iteration = iteration + 1\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    print(len(r_dev))\\n    # Build logistic regression\\n    KGB_new = RandomForestClassifier(random_state=42).fit(X_train_iter, y_train_iter)\\n    # KGB_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train_iter, y_train_iter)\\n\\n    # Scores\\n    mcc = matthews_corrcoef(y_test, KGB_new.predict(X_test))\\n    mccs.append(mcc)\\n\\n    print(\\\"MCC: \\\", mcc)\\n\\n    # Make predictions on the rejected data\\n    pred = KGB_new.predict_proba(r_dev_iter)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev_iter.index.copy(),\\n    )\\n\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.15)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n    # pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > np.random.uniform()) else 0)\\n\\n    # If PD is low, be conservative and apply non-default status only to some examples\\n    #     pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(\\n    #         lambda x: 0 if (x < np.random.uniform()) else 1\\n    #     )\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n    # print(len(certain))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev_iter[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\\n\\n    print(len(r_dev_iter))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 199;\n",
       "                var nbb_unformatted_code = \"f1_scores = []\\nlog_losses = []\\nmccs = []\\niterations = []\\n\\niteration = 0\\nwhile 0.7 * len(r_dev) < len(r_dev_iter):\\n    iteration = iteration + 1\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    print(len(r_dev))\\n    # Build logistic regression\\n    KGB_new = RandomForestClassifier(random_state=42).fit(X_train_iter, y_train_iter)\\n    # KGB_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train_iter, y_train_iter)\\n\\n    # Scores\\n    mcc = matthews_corrcoef(y_test, KGB_new.predict(X_test))\\n    mccs.append(mcc)\\n\\n    print(\\\"MCC: \\\", mcc)\\n\\n    # Make predictions on the rejected data\\n    pred = KGB_new.predict_proba(r_dev_iter)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev_iter.index.copy(),\\n    )\\n\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.15)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n    # pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > np.random.uniform()) else 0)\\n\\n    # If PD is low, be conservative and apply non-default status only to some examples\\n    #     pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(\\n    #         lambda x: 0 if (x < np.random.uniform()) else 1\\n    #     )\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n    # print(len(certain))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev_iter[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\\n\\n    print(len(r_dev_iter))\";\n",
       "                var nbb_formatted_code = \"f1_scores = []\\nlog_losses = []\\nmccs = []\\niterations = []\\n\\niteration = 0\\nwhile 0.7 * len(r_dev) < len(r_dev_iter):\\n    iteration = iteration + 1\\n    print(\\\"Iteration Nr {}\\\".format(iteration))\\n    print(len(r_dev))\\n    # Build logistic regression\\n    KGB_new = RandomForestClassifier(random_state=42).fit(X_train_iter, y_train_iter)\\n    # KGB_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train_iter, y_train_iter)\\n\\n    # Scores\\n    mcc = matthews_corrcoef(y_test, KGB_new.predict(X_test))\\n    mccs.append(mcc)\\n\\n    print(\\\"MCC: \\\", mcc)\\n\\n    # Make predictions on the rejected data\\n    pred = KGB_new.predict_proba(r_dev_iter)[:, 1]\\n    pred = pd.DataFrame(\\n        data=pred,\\n        columns=[\\\"target\\\"],\\n        index=r_dev_iter.index.copy(),\\n    )\\n\\n    # Choose the most certain predictions\\n    lq = pred[\\\"target\\\"].quantile(q=0.15)\\n    uq = pred[\\\"target\\\"].quantile(q=0.95)\\n    pred[\\\"certain\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\\n\\n    # If PD is high, apply default status\\n    pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > uq) else 0)\\n    # pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(lambda x: 1 if (x > np.random.uniform()) else 0)\\n\\n    # If PD is low, be conservative and apply non-default status only to some examples\\n    #     pred[\\\"target\\\"] = pred[\\\"target\\\"].apply(\\n    #         lambda x: 0 if (x < np.random.uniform()) else 1\\n    #     )\\n\\n    # Pick only the certain predictions and concatenate them to the dev set\\n    # Y TRAIN\\n    certain = pred[pred[\\\"certain\\\"] == 1]\\n    certain2 = certain[\\\"target\\\"].to_frame()\\n    y_train_iter = pd.concat((y_train_iter, certain2))\\n\\n    # print(len(certain))\\n\\n    # Get significant columns of the rejects based on index\\n    certain_features = pd.merge(\\n        certain[\\\"target\\\"],\\n        r_dev_iter[significant_columns],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # X TRAIN\\n    certain_features = certain_features.loc[:, certain_features.columns != \\\"target\\\"]\\n    X_train_iter = pd.concat((X_train_iter, certain_features))\\n\\n    # Remove certain columns from rejected data\\n    rows = certain_features.index\\n    r_dev_iter = r_dev_iter.drop(rows, axis=\\\"index\\\")\\n\\n    print(len(r_dev_iter))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1_scores = []\n",
    "log_losses = []\n",
    "mccs = []\n",
    "iterations = []\n",
    "\n",
    "iteration = 0\n",
    "while 0.7 * len(r_dev) < len(r_dev_iter):\n",
    "    iteration = iteration + 1\n",
    "    print(\"Iteration Nr {}\".format(iteration))\n",
    "    print(len(r_dev))\n",
    "    # Build logistic regression\n",
    "    KGB_new = RandomForestClassifier(random_state=42).fit(X_train_iter, y_train_iter)\n",
    "    # KGB_new = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(X_train_iter, y_train_iter)\n",
    "\n",
    "    # Scores\n",
    "    mcc = matthews_corrcoef(y_test, KGB_new.predict(X_test))\n",
    "    mccs.append(mcc)\n",
    "\n",
    "    print(\"MCC: \", mcc)\n",
    "\n",
    "    # Make predictions on the rejected data\n",
    "    pred = KGB_new.predict_proba(r_dev_iter)[:, 1]\n",
    "    pred = pd.DataFrame(\n",
    "        data=pred,\n",
    "        columns=[\"target\"],\n",
    "        index=r_dev_iter.index.copy(),\n",
    "    )\n",
    "\n",
    "    # Choose the most certain predictions\n",
    "    lq = pred[\"target\"].quantile(q=0.15)\n",
    "    uq = pred[\"target\"].quantile(q=0.95)\n",
    "    pred[\"certain\"] = pred[\"target\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\n",
    "\n",
    "    # If PD is high, apply default status\n",
    "    pred[\"target\"] = pred[\"target\"].apply(lambda x: 1 if (x > uq) else 0)\n",
    "    # pred[\"target\"] = pred[\"target\"].apply(lambda x: 1 if (x > np.random.uniform()) else 0)\n",
    "\n",
    "    # If PD is low, be conservative and apply non-default status only to some examples\n",
    "    #     pred[\"target\"] = pred[\"target\"].apply(\n",
    "    #         lambda x: 0 if (x < np.random.uniform()) else 1\n",
    "    #     )\n",
    "\n",
    "    # Pick only the certain predictions and concatenate them to the dev set\n",
    "    # Y TRAIN\n",
    "    certain = pred[pred[\"certain\"] == 1]\n",
    "    certain2 = certain[\"target\"].to_frame()\n",
    "    y_train_iter = pd.concat((y_train_iter, certain2))\n",
    "\n",
    "    # print(len(certain))\n",
    "\n",
    "    # Get significant columns of the rejects based on index\n",
    "    certain_features = pd.merge(\n",
    "        certain[\"target\"],\n",
    "        r_dev_iter[significant_columns],\n",
    "        how=\"inner\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    # X TRAIN\n",
    "    certain_features = certain_features.loc[:, certain_features.columns != \"target\"]\n",
    "    X_train_iter = pd.concat((X_train_iter, certain_features))\n",
    "\n",
    "    # Remove certain columns from rejected data\n",
    "    rows = certain_features.index\n",
    "    r_dev_iter = r_dev_iter.drop(rows, axis=\"index\")\n",
    "\n",
    "    print(len(r_dev_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do only 1 iteration as baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 200;\n",
       "                var nbb_unformatted_code = \"# Create copies of the data that can be overwritten in the function below\\nX_train_iter1 = X_train.copy()\\ny_train_iter1 = y_train.copy()\\nr_dev_iter1 = r_dev.copy()\";\n",
       "                var nbb_formatted_code = \"# Create copies of the data that can be overwritten in the function below\\nX_train_iter1 = X_train.copy()\\ny_train_iter1 = y_train.copy()\\nr_dev_iter1 = r_dev.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 200;\n",
       "                var nbb_unformatted_code = \"# Create copies of the data that can be overwritten in the function below\\nX_train_iter1 = X_train.copy()\\ny_train_iter1 = y_train.copy()\\nr_dev_iter1 = r_dev.copy()\";\n",
       "                var nbb_formatted_code = \"# Create copies of the data that can be overwritten in the function below\\nX_train_iter1 = X_train.copy()\\ny_train_iter1 = y_train.copy()\\nr_dev_iter1 = r_dev.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 200;\n",
       "                var nbb_unformatted_code = \"# Create copies of the data that can be overwritten in the function below\\nX_train_iter1 = X_train.copy()\\ny_train_iter1 = y_train.copy()\\nr_dev_iter1 = r_dev.copy()\";\n",
       "                var nbb_formatted_code = \"# Create copies of the data that can be overwritten in the function below\\nX_train_iter1 = X_train.copy()\\ny_train_iter1 = y_train.copy()\\nr_dev_iter1 = r_dev.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 200;\n",
       "                var nbb_unformatted_code = \"# Create copies of the data that can be overwritten in the function below\\nX_train_iter1 = X_train.copy()\\ny_train_iter1 = y_train.copy()\\nr_dev_iter1 = r_dev.copy()\";\n",
       "                var nbb_formatted_code = \"# Create copies of the data that can be overwritten in the function below\\nX_train_iter1 = X_train.copy()\\ny_train_iter1 = y_train.copy()\\nr_dev_iter1 = r_dev.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 200;\n",
       "                var nbb_unformatted_code = \"# Create copies of the data that can be overwritten in the function below\\nX_train_iter1 = X_train.copy()\\ny_train_iter1 = y_train.copy()\\nr_dev_iter1 = r_dev.copy()\";\n",
       "                var nbb_formatted_code = \"# Create copies of the data that can be overwritten in the function below\\nX_train_iter1 = X_train.copy()\\ny_train_iter1 = y_train.copy()\\nr_dev_iter1 = r_dev.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 200;\n",
       "                var nbb_unformatted_code = \"# Create copies of the data that can be overwritten in the function below\\nX_train_iter1 = X_train.copy()\\ny_train_iter1 = y_train.copy()\\nr_dev_iter1 = r_dev.copy()\";\n",
       "                var nbb_formatted_code = \"# Create copies of the data that can be overwritten in the function below\\nX_train_iter1 = X_train.copy()\\ny_train_iter1 = y_train.copy()\\nr_dev_iter1 = r_dev.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create copies of the data that can be overwritten in the function below\n",
    "X_train_iter1 = X_train.copy()\n",
    "y_train_iter1 = y_train.copy()\n",
    "r_dev_iter1 = r_dev.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 201;\n",
       "                var nbb_unformatted_code = \"def predict_rejects(model, r_dev):\\n    # Make predictions on the Train Rejects\\n    pred_test = model.predict_proba(r_dev)[:, 1]\\n    # pred_test = model.predict(r_dev)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_dev.index.copy(),\\n    )\\n\\n    # Make binary predictions based on cutoff DR\\n    q1 = pred_test[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test[\\\"target\\\"] = pred_test[\\\"pred\\\"].apply(lambda x: 0 if (x < q1) else 1)\\n    pred_test = pred_test[\\\"target\\\"].to_frame()\\n\\n    # Add new rows to df\\n    y_train_new = pd.concat((y_train, pred_test))\\n    X_train_new = pd.concat((X_train, r_dev))\\n\\n    # Fit new model\\n    # KGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train_new, y_train_new)\\n    # KGB_baseline_new = LinearRegression().fit(X_train_new, y_train_new)\\n    KGB_baseline_new = RandomForestClassifier(random_state=42).fit(\\n        X_train_new, y_train_new\\n    )\\n    # KGB_baseline_new = DecisionTreeClassifier().fit(X_train_iter, y_train_iter)\\n    return KGB_baseline_new\";\n",
       "                var nbb_formatted_code = \"def predict_rejects(model, r_dev):\\n    # Make predictions on the Train Rejects\\n    pred_test = model.predict_proba(r_dev)[:, 1]\\n    # pred_test = model.predict(r_dev)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_dev.index.copy(),\\n    )\\n\\n    # Make binary predictions based on cutoff DR\\n    q1 = pred_test[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test[\\\"target\\\"] = pred_test[\\\"pred\\\"].apply(lambda x: 0 if (x < q1) else 1)\\n    pred_test = pred_test[\\\"target\\\"].to_frame()\\n\\n    # Add new rows to df\\n    y_train_new = pd.concat((y_train, pred_test))\\n    X_train_new = pd.concat((X_train, r_dev))\\n\\n    # Fit new model\\n    # KGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train_new, y_train_new)\\n    # KGB_baseline_new = LinearRegression().fit(X_train_new, y_train_new)\\n    KGB_baseline_new = RandomForestClassifier(random_state=42).fit(\\n        X_train_new, y_train_new\\n    )\\n    # KGB_baseline_new = DecisionTreeClassifier().fit(X_train_iter, y_train_iter)\\n    return KGB_baseline_new\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 201;\n",
       "                var nbb_unformatted_code = \"def predict_rejects(model, r_dev):\\n    # Make predictions on the Train Rejects\\n    pred_test = model.predict_proba(r_dev)[:, 1]\\n    # pred_test = model.predict(r_dev)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_dev.index.copy(),\\n    )\\n\\n    # Make binary predictions based on cutoff DR\\n    q1 = pred_test[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test[\\\"target\\\"] = pred_test[\\\"pred\\\"].apply(lambda x: 0 if (x < q1) else 1)\\n    pred_test = pred_test[\\\"target\\\"].to_frame()\\n\\n    # Add new rows to df\\n    y_train_new = pd.concat((y_train, pred_test))\\n    X_train_new = pd.concat((X_train, r_dev))\\n\\n    # Fit new model\\n    # KGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train_new, y_train_new)\\n    # KGB_baseline_new = LinearRegression().fit(X_train_new, y_train_new)\\n    KGB_baseline_new = RandomForestClassifier(random_state=42).fit(\\n        X_train_new, y_train_new\\n    )\\n    # KGB_baseline_new = DecisionTreeClassifier().fit(X_train_iter, y_train_iter)\\n    return KGB_baseline_new\";\n",
       "                var nbb_formatted_code = \"def predict_rejects(model, r_dev):\\n    # Make predictions on the Train Rejects\\n    pred_test = model.predict_proba(r_dev)[:, 1]\\n    # pred_test = model.predict(r_dev)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_dev.index.copy(),\\n    )\\n\\n    # Make binary predictions based on cutoff DR\\n    q1 = pred_test[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test[\\\"target\\\"] = pred_test[\\\"pred\\\"].apply(lambda x: 0 if (x < q1) else 1)\\n    pred_test = pred_test[\\\"target\\\"].to_frame()\\n\\n    # Add new rows to df\\n    y_train_new = pd.concat((y_train, pred_test))\\n    X_train_new = pd.concat((X_train, r_dev))\\n\\n    # Fit new model\\n    # KGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train_new, y_train_new)\\n    # KGB_baseline_new = LinearRegression().fit(X_train_new, y_train_new)\\n    KGB_baseline_new = RandomForestClassifier(random_state=42).fit(\\n        X_train_new, y_train_new\\n    )\\n    # KGB_baseline_new = DecisionTreeClassifier().fit(X_train_iter, y_train_iter)\\n    return KGB_baseline_new\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 201;\n",
       "                var nbb_unformatted_code = \"def predict_rejects(model, r_dev):\\n    # Make predictions on the Train Rejects\\n    pred_test = model.predict_proba(r_dev)[:, 1]\\n    # pred_test = model.predict(r_dev)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_dev.index.copy(),\\n    )\\n\\n    # Make binary predictions based on cutoff DR\\n    q1 = pred_test[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test[\\\"target\\\"] = pred_test[\\\"pred\\\"].apply(lambda x: 0 if (x < q1) else 1)\\n    pred_test = pred_test[\\\"target\\\"].to_frame()\\n\\n    # Add new rows to df\\n    y_train_new = pd.concat((y_train, pred_test))\\n    X_train_new = pd.concat((X_train, r_dev))\\n\\n    # Fit new model\\n    # KGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train_new, y_train_new)\\n    # KGB_baseline_new = LinearRegression().fit(X_train_new, y_train_new)\\n    KGB_baseline_new = RandomForestClassifier(random_state=42).fit(\\n        X_train_new, y_train_new\\n    )\\n    # KGB_baseline_new = DecisionTreeClassifier().fit(X_train_iter, y_train_iter)\\n    return KGB_baseline_new\";\n",
       "                var nbb_formatted_code = \"def predict_rejects(model, r_dev):\\n    # Make predictions on the Train Rejects\\n    pred_test = model.predict_proba(r_dev)[:, 1]\\n    # pred_test = model.predict(r_dev)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_dev.index.copy(),\\n    )\\n\\n    # Make binary predictions based on cutoff DR\\n    q1 = pred_test[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test[\\\"target\\\"] = pred_test[\\\"pred\\\"].apply(lambda x: 0 if (x < q1) else 1)\\n    pred_test = pred_test[\\\"target\\\"].to_frame()\\n\\n    # Add new rows to df\\n    y_train_new = pd.concat((y_train, pred_test))\\n    X_train_new = pd.concat((X_train, r_dev))\\n\\n    # Fit new model\\n    # KGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train_new, y_train_new)\\n    # KGB_baseline_new = LinearRegression().fit(X_train_new, y_train_new)\\n    KGB_baseline_new = RandomForestClassifier(random_state=42).fit(\\n        X_train_new, y_train_new\\n    )\\n    # KGB_baseline_new = DecisionTreeClassifier().fit(X_train_iter, y_train_iter)\\n    return KGB_baseline_new\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 201;\n",
       "                var nbb_unformatted_code = \"def predict_rejects(model, r_dev):\\n    # Make predictions on the Train Rejects\\n    pred_test = model.predict_proba(r_dev)[:, 1]\\n    # pred_test = model.predict(r_dev)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_dev.index.copy(),\\n    )\\n\\n    # Make binary predictions based on cutoff DR\\n    q1 = pred_test[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test[\\\"target\\\"] = pred_test[\\\"pred\\\"].apply(lambda x: 0 if (x < q1) else 1)\\n    pred_test = pred_test[\\\"target\\\"].to_frame()\\n\\n    # Add new rows to df\\n    y_train_new = pd.concat((y_train, pred_test))\\n    X_train_new = pd.concat((X_train, r_dev))\\n\\n    # Fit new model\\n    # KGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train_new, y_train_new)\\n    # KGB_baseline_new = LinearRegression().fit(X_train_new, y_train_new)\\n    KGB_baseline_new = RandomForestClassifier(random_state=42).fit(\\n        X_train_new, y_train_new\\n    )\\n    # KGB_baseline_new = DecisionTreeClassifier().fit(X_train_iter, y_train_iter)\\n    return KGB_baseline_new\";\n",
       "                var nbb_formatted_code = \"def predict_rejects(model, r_dev):\\n    # Make predictions on the Train Rejects\\n    pred_test = model.predict_proba(r_dev)[:, 1]\\n    # pred_test = model.predict(r_dev)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_dev.index.copy(),\\n    )\\n\\n    # Make binary predictions based on cutoff DR\\n    q1 = pred_test[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test[\\\"target\\\"] = pred_test[\\\"pred\\\"].apply(lambda x: 0 if (x < q1) else 1)\\n    pred_test = pred_test[\\\"target\\\"].to_frame()\\n\\n    # Add new rows to df\\n    y_train_new = pd.concat((y_train, pred_test))\\n    X_train_new = pd.concat((X_train, r_dev))\\n\\n    # Fit new model\\n    # KGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train_new, y_train_new)\\n    # KGB_baseline_new = LinearRegression().fit(X_train_new, y_train_new)\\n    KGB_baseline_new = RandomForestClassifier(random_state=42).fit(\\n        X_train_new, y_train_new\\n    )\\n    # KGB_baseline_new = DecisionTreeClassifier().fit(X_train_iter, y_train_iter)\\n    return KGB_baseline_new\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 201;\n",
       "                var nbb_unformatted_code = \"def predict_rejects(model, r_dev):\\n    # Make predictions on the Train Rejects\\n    pred_test = model.predict_proba(r_dev)[:, 1]\\n    # pred_test = model.predict(r_dev)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_dev.index.copy(),\\n    )\\n\\n    # Make binary predictions based on cutoff DR\\n    q1 = pred_test[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test[\\\"target\\\"] = pred_test[\\\"pred\\\"].apply(lambda x: 0 if (x < q1) else 1)\\n    pred_test = pred_test[\\\"target\\\"].to_frame()\\n\\n    # Add new rows to df\\n    y_train_new = pd.concat((y_train, pred_test))\\n    X_train_new = pd.concat((X_train, r_dev))\\n\\n    # Fit new model\\n    # KGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train_new, y_train_new)\\n    # KGB_baseline_new = LinearRegression().fit(X_train_new, y_train_new)\\n    KGB_baseline_new = RandomForestClassifier(random_state=42).fit(\\n        X_train_new, y_train_new\\n    )\\n    # KGB_baseline_new = DecisionTreeClassifier().fit(X_train_iter, y_train_iter)\\n    return KGB_baseline_new\";\n",
       "                var nbb_formatted_code = \"def predict_rejects(model, r_dev):\\n    # Make predictions on the Train Rejects\\n    pred_test = model.predict_proba(r_dev)[:, 1]\\n    # pred_test = model.predict(r_dev)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_dev.index.copy(),\\n    )\\n\\n    # Make binary predictions based on cutoff DR\\n    q1 = pred_test[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test[\\\"target\\\"] = pred_test[\\\"pred\\\"].apply(lambda x: 0 if (x < q1) else 1)\\n    pred_test = pred_test[\\\"target\\\"].to_frame()\\n\\n    # Add new rows to df\\n    y_train_new = pd.concat((y_train, pred_test))\\n    X_train_new = pd.concat((X_train, r_dev))\\n\\n    # Fit new model\\n    # KGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train_new, y_train_new)\\n    # KGB_baseline_new = LinearRegression().fit(X_train_new, y_train_new)\\n    KGB_baseline_new = RandomForestClassifier(random_state=42).fit(\\n        X_train_new, y_train_new\\n    )\\n    # KGB_baseline_new = DecisionTreeClassifier().fit(X_train_iter, y_train_iter)\\n    return KGB_baseline_new\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 201;\n",
       "                var nbb_unformatted_code = \"def predict_rejects(model, r_dev):\\n    # Make predictions on the Train Rejects\\n    pred_test = model.predict_proba(r_dev)[:, 1]\\n    # pred_test = model.predict(r_dev)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_dev.index.copy(),\\n    )\\n\\n    # Make binary predictions based on cutoff DR\\n    q1 = pred_test[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test[\\\"target\\\"] = pred_test[\\\"pred\\\"].apply(lambda x: 0 if (x < q1) else 1)\\n    pred_test = pred_test[\\\"target\\\"].to_frame()\\n\\n    # Add new rows to df\\n    y_train_new = pd.concat((y_train, pred_test))\\n    X_train_new = pd.concat((X_train, r_dev))\\n\\n    # Fit new model\\n    # KGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train_new, y_train_new)\\n    # KGB_baseline_new = LinearRegression().fit(X_train_new, y_train_new)\\n    KGB_baseline_new = RandomForestClassifier(random_state=42).fit(\\n        X_train_new, y_train_new\\n    )\\n    # KGB_baseline_new = DecisionTreeClassifier().fit(X_train_iter, y_train_iter)\\n    return KGB_baseline_new\";\n",
       "                var nbb_formatted_code = \"def predict_rejects(model, r_dev):\\n    # Make predictions on the Train Rejects\\n    pred_test = model.predict_proba(r_dev)[:, 1]\\n    # pred_test = model.predict(r_dev)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_dev.index.copy(),\\n    )\\n\\n    # Make binary predictions based on cutoff DR\\n    q1 = pred_test[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test[\\\"target\\\"] = pred_test[\\\"pred\\\"].apply(lambda x: 0 if (x < q1) else 1)\\n    pred_test = pred_test[\\\"target\\\"].to_frame()\\n\\n    # Add new rows to df\\n    y_train_new = pd.concat((y_train, pred_test))\\n    X_train_new = pd.concat((X_train, r_dev))\\n\\n    # Fit new model\\n    # KGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\\\"none\\\").fit(X_train_new, y_train_new)\\n    # KGB_baseline_new = LinearRegression().fit(X_train_new, y_train_new)\\n    KGB_baseline_new = RandomForestClassifier(random_state=42).fit(\\n        X_train_new, y_train_new\\n    )\\n    # KGB_baseline_new = DecisionTreeClassifier().fit(X_train_iter, y_train_iter)\\n    return KGB_baseline_new\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict_rejects(model, r_dev):\n",
    "    # Make predictions on the Train Rejects\n",
    "    pred_test = model.predict_proba(r_dev)[:, 1]\n",
    "    # pred_test = model.predict(r_dev)\n",
    "    pred_test = pd.DataFrame(\n",
    "        data=pred_test,\n",
    "        columns=[\"pred\"],\n",
    "        index=r_dev.index.copy(),\n",
    "    )\n",
    "\n",
    "    # Make binary predictions based on cutoff DR\n",
    "    q1 = pred_test[\"pred\"].quantile(q=1 - conservative_dr)\n",
    "    pred_test[\"target\"] = pred_test[\"pred\"].apply(lambda x: 0 if (x < q1) else 1)\n",
    "    pred_test = pred_test[\"target\"].to_frame()\n",
    "\n",
    "    # Add new rows to df\n",
    "    y_train_new = pd.concat((y_train, pred_test))\n",
    "    X_train_new = pd.concat((X_train, r_dev))\n",
    "\n",
    "    # Fit new model\n",
    "    # KGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(X_train_new, y_train_new)\n",
    "    # KGB_baseline_new = LinearRegression().fit(X_train_new, y_train_new)\n",
    "    KGB_baseline_new = RandomForestClassifier(random_state=42).fit(\n",
    "        X_train_new, y_train_new\n",
    "    )\n",
    "    # KGB_baseline_new = DecisionTreeClassifier().fit(X_train_iter, y_train_iter)\n",
    "    return KGB_baseline_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 202;\n",
       "                var nbb_unformatted_code = \"def evaluate_test_accepts(model, X_test):\\n    pred_test = model.predict_proba(X_test)[:, 1]\\n    # pred_test = model.predict(X_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=X_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_formatted_code = \"def evaluate_test_accepts(model, X_test):\\n    pred_test = model.predict_proba(X_test)[:, 1]\\n    # pred_test = model.predict(X_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=X_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 202;\n",
       "                var nbb_unformatted_code = \"def evaluate_test_accepts(model, X_test):\\n    pred_test = model.predict_proba(X_test)[:, 1]\\n    # pred_test = model.predict(X_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=X_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_formatted_code = \"def evaluate_test_accepts(model, X_test):\\n    pred_test = model.predict_proba(X_test)[:, 1]\\n    # pred_test = model.predict(X_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=X_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 202;\n",
       "                var nbb_unformatted_code = \"def evaluate_test_accepts(model, X_test):\\n    pred_test = model.predict_proba(X_test)[:, 1]\\n    # pred_test = model.predict(X_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=X_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_formatted_code = \"def evaluate_test_accepts(model, X_test):\\n    pred_test = model.predict_proba(X_test)[:, 1]\\n    # pred_test = model.predict(X_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=X_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 202;\n",
       "                var nbb_unformatted_code = \"def evaluate_test_accepts(model, X_test):\\n    pred_test = model.predict_proba(X_test)[:, 1]\\n    # pred_test = model.predict(X_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=X_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_formatted_code = \"def evaluate_test_accepts(model, X_test):\\n    pred_test = model.predict_proba(X_test)[:, 1]\\n    # pred_test = model.predict(X_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=X_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 202;\n",
       "                var nbb_unformatted_code = \"def evaluate_test_accepts(model, X_test):\\n    pred_test = model.predict_proba(X_test)[:, 1]\\n    # pred_test = model.predict(X_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=X_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_formatted_code = \"def evaluate_test_accepts(model, X_test):\\n    pred_test = model.predict_proba(X_test)[:, 1]\\n    # pred_test = model.predict(X_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=X_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 202;\n",
       "                var nbb_unformatted_code = \"def evaluate_test_accepts(model, X_test):\\n    pred_test = model.predict_proba(X_test)[:, 1]\\n    # pred_test = model.predict(X_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=X_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_formatted_code = \"def evaluate_test_accepts(model, X_test):\\n    pred_test = model.predict_proba(X_test)[:, 1]\\n    # pred_test = model.predict(X_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=X_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_test_accepts(model, X_test):\n",
    "    pred_test = model.predict_proba(X_test)[:, 1]\n",
    "    # pred_test = model.predict(X_test)\n",
    "    pred_test = pd.DataFrame(\n",
    "        data=pred_test,\n",
    "        columns=[\"pred\"],\n",
    "        index=X_test.index.copy(),\n",
    "    )\n",
    "\n",
    "    # Merge with Target\n",
    "    pred_test2 = pd.merge(\n",
    "        pred_test[\"pred\"],\n",
    "        y_test[\"target\"],\n",
    "        how=\"inner\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    # Make binary predictions based on cutoff 50percentile of the distribution\n",
    "    q1 = pred_test2[\"pred\"].quantile(q=1 - conservative_dr)\n",
    "    pred_test2[\"prediction_baseline\"] = pred_test2[\"pred\"].apply(\n",
    "        lambda x: 0 if (x < q1) else 1\n",
    "    )\n",
    "    return pred_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 203;\n",
       "                var nbb_unformatted_code = \"def evaluate_test_rejects(model, r_test):\\n    pred_test = model.predict_proba(r_test)[:, 1]\\n    # pred_test = model.predict(r_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_formatted_code = \"def evaluate_test_rejects(model, r_test):\\n    pred_test = model.predict_proba(r_test)[:, 1]\\n    # pred_test = model.predict(r_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 203;\n",
       "                var nbb_unformatted_code = \"def evaluate_test_rejects(model, r_test):\\n    pred_test = model.predict_proba(r_test)[:, 1]\\n    # pred_test = model.predict(r_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_formatted_code = \"def evaluate_test_rejects(model, r_test):\\n    pred_test = model.predict_proba(r_test)[:, 1]\\n    # pred_test = model.predict(r_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 203;\n",
       "                var nbb_unformatted_code = \"def evaluate_test_rejects(model, r_test):\\n    pred_test = model.predict_proba(r_test)[:, 1]\\n    # pred_test = model.predict(r_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_formatted_code = \"def evaluate_test_rejects(model, r_test):\\n    pred_test = model.predict_proba(r_test)[:, 1]\\n    # pred_test = model.predict(r_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 203;\n",
       "                var nbb_unformatted_code = \"def evaluate_test_rejects(model, r_test):\\n    pred_test = model.predict_proba(r_test)[:, 1]\\n    # pred_test = model.predict(r_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_formatted_code = \"def evaluate_test_rejects(model, r_test):\\n    pred_test = model.predict_proba(r_test)[:, 1]\\n    # pred_test = model.predict(r_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 203;\n",
       "                var nbb_unformatted_code = \"def evaluate_test_rejects(model, r_test):\\n    pred_test = model.predict_proba(r_test)[:, 1]\\n    # pred_test = model.predict(r_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_formatted_code = \"def evaluate_test_rejects(model, r_test):\\n    pred_test = model.predict_proba(r_test)[:, 1]\\n    # pred_test = model.predict(r_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 203;\n",
       "                var nbb_unformatted_code = \"def evaluate_test_rejects(model, r_test):\\n    pred_test = model.predict_proba(r_test)[:, 1]\\n    # pred_test = model.predict(r_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_formatted_code = \"def evaluate_test_rejects(model, r_test):\\n    pred_test = model.predict_proba(r_test)[:, 1]\\n    # pred_test = model.predict(r_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=r_test.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_test_rejects(model, r_test):\n",
    "    pred_test = model.predict_proba(r_test)[:, 1]\n",
    "    # pred_test = model.predict(r_test)\n",
    "    pred_test = pd.DataFrame(\n",
    "        data=pred_test,\n",
    "        columns=[\"pred\"],\n",
    "        index=r_test.index.copy(),\n",
    "    )\n",
    "\n",
    "    # Merge with Target\n",
    "    pred_test2 = pd.merge(\n",
    "        pred_test[\"pred\"],\n",
    "        dfr_test_with_label[\"target\"],\n",
    "        how=\"inner\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    # Make binary predictions based on cutoff 50percentile of the distribution\n",
    "    q1 = pred_test2[\"pred\"].quantile(q=1 - conservative_dr)\n",
    "    pred_test2[\"prediction_baseline\"] = pred_test2[\"pred\"].apply(\n",
    "        lambda x: 0 if (x < q1) else 1\n",
    "    )\n",
    "    return pred_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 204;\n",
       "                var nbb_unformatted_code = \"def evaluate_test_combined(model, X_test, r_test):\\n    # Attach target to X_test and r_test\\n\\n    r_test_target = pd.merge(\\n        r_test,\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    X_test_target = pd.merge(\\n        X_test,\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Concatenate labels\\n    ta_tr_labels = pd.concat([X_test_target, r_test_target], axis=0)\\n\\n    # Concatenate Test Accepts and Test Rejects\\n    ta_tr = pd.concat([X_test, r_test], axis=0)\\n\\n    pred_test = model.predict_proba(ta_tr)[:, 1]\\n    # pred_test = model.predict(r_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=ta_tr.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        ta_tr_labels[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_formatted_code = \"def evaluate_test_combined(model, X_test, r_test):\\n    # Attach target to X_test and r_test\\n\\n    r_test_target = pd.merge(\\n        r_test,\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    X_test_target = pd.merge(\\n        X_test,\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Concatenate labels\\n    ta_tr_labels = pd.concat([X_test_target, r_test_target], axis=0)\\n\\n    # Concatenate Test Accepts and Test Rejects\\n    ta_tr = pd.concat([X_test, r_test], axis=0)\\n\\n    pred_test = model.predict_proba(ta_tr)[:, 1]\\n    # pred_test = model.predict(r_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=ta_tr.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        ta_tr_labels[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 204;\n",
       "                var nbb_unformatted_code = \"def evaluate_test_combined(model, X_test, r_test):\\n    # Attach target to X_test and r_test\\n\\n    r_test_target = pd.merge(\\n        r_test,\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    X_test_target = pd.merge(\\n        X_test,\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Concatenate labels\\n    ta_tr_labels = pd.concat([X_test_target, r_test_target], axis=0)\\n\\n    # Concatenate Test Accepts and Test Rejects\\n    ta_tr = pd.concat([X_test, r_test], axis=0)\\n\\n    pred_test = model.predict_proba(ta_tr)[:, 1]\\n    # pred_test = model.predict(r_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=ta_tr.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        ta_tr_labels[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_formatted_code = \"def evaluate_test_combined(model, X_test, r_test):\\n    # Attach target to X_test and r_test\\n\\n    r_test_target = pd.merge(\\n        r_test,\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    X_test_target = pd.merge(\\n        X_test,\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Concatenate labels\\n    ta_tr_labels = pd.concat([X_test_target, r_test_target], axis=0)\\n\\n    # Concatenate Test Accepts and Test Rejects\\n    ta_tr = pd.concat([X_test, r_test], axis=0)\\n\\n    pred_test = model.predict_proba(ta_tr)[:, 1]\\n    # pred_test = model.predict(r_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=ta_tr.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        ta_tr_labels[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 204;\n",
       "                var nbb_unformatted_code = \"def evaluate_test_combined(model, X_test, r_test):\\n    # Attach target to X_test and r_test\\n\\n    r_test_target = pd.merge(\\n        r_test,\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    X_test_target = pd.merge(\\n        X_test,\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Concatenate labels\\n    ta_tr_labels = pd.concat([X_test_target, r_test_target], axis=0)\\n\\n    # Concatenate Test Accepts and Test Rejects\\n    ta_tr = pd.concat([X_test, r_test], axis=0)\\n\\n    pred_test = model.predict_proba(ta_tr)[:, 1]\\n    # pred_test = model.predict(r_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=ta_tr.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        ta_tr_labels[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_formatted_code = \"def evaluate_test_combined(model, X_test, r_test):\\n    # Attach target to X_test and r_test\\n\\n    r_test_target = pd.merge(\\n        r_test,\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    X_test_target = pd.merge(\\n        X_test,\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Concatenate labels\\n    ta_tr_labels = pd.concat([X_test_target, r_test_target], axis=0)\\n\\n    # Concatenate Test Accepts and Test Rejects\\n    ta_tr = pd.concat([X_test, r_test], axis=0)\\n\\n    pred_test = model.predict_proba(ta_tr)[:, 1]\\n    # pred_test = model.predict(r_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=ta_tr.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        ta_tr_labels[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 204;\n",
       "                var nbb_unformatted_code = \"def evaluate_test_combined(model, X_test, r_test):\\n    # Attach target to X_test and r_test\\n\\n    r_test_target = pd.merge(\\n        r_test,\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    X_test_target = pd.merge(\\n        X_test,\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Concatenate labels\\n    ta_tr_labels = pd.concat([X_test_target, r_test_target], axis=0)\\n\\n    # Concatenate Test Accepts and Test Rejects\\n    ta_tr = pd.concat([X_test, r_test], axis=0)\\n\\n    pred_test = model.predict_proba(ta_tr)[:, 1]\\n    # pred_test = model.predict(r_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=ta_tr.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        ta_tr_labels[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_formatted_code = \"def evaluate_test_combined(model, X_test, r_test):\\n    # Attach target to X_test and r_test\\n\\n    r_test_target = pd.merge(\\n        r_test,\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    X_test_target = pd.merge(\\n        X_test,\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Concatenate labels\\n    ta_tr_labels = pd.concat([X_test_target, r_test_target], axis=0)\\n\\n    # Concatenate Test Accepts and Test Rejects\\n    ta_tr = pd.concat([X_test, r_test], axis=0)\\n\\n    pred_test = model.predict_proba(ta_tr)[:, 1]\\n    # pred_test = model.predict(r_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=ta_tr.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        ta_tr_labels[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 204;\n",
       "                var nbb_unformatted_code = \"def evaluate_test_combined(model, X_test, r_test):\\n    # Attach target to X_test and r_test\\n\\n    r_test_target = pd.merge(\\n        r_test,\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    X_test_target = pd.merge(\\n        X_test,\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Concatenate labels\\n    ta_tr_labels = pd.concat([X_test_target, r_test_target], axis=0)\\n\\n    # Concatenate Test Accepts and Test Rejects\\n    ta_tr = pd.concat([X_test, r_test], axis=0)\\n\\n    pred_test = model.predict_proba(ta_tr)[:, 1]\\n    # pred_test = model.predict(r_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=ta_tr.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        ta_tr_labels[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_formatted_code = \"def evaluate_test_combined(model, X_test, r_test):\\n    # Attach target to X_test and r_test\\n\\n    r_test_target = pd.merge(\\n        r_test,\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    X_test_target = pd.merge(\\n        X_test,\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Concatenate labels\\n    ta_tr_labels = pd.concat([X_test_target, r_test_target], axis=0)\\n\\n    # Concatenate Test Accepts and Test Rejects\\n    ta_tr = pd.concat([X_test, r_test], axis=0)\\n\\n    pred_test = model.predict_proba(ta_tr)[:, 1]\\n    # pred_test = model.predict(r_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=ta_tr.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        ta_tr_labels[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 204;\n",
       "                var nbb_unformatted_code = \"def evaluate_test_combined(model, X_test, r_test):\\n    # Attach target to X_test and r_test\\n\\n    r_test_target = pd.merge(\\n        r_test,\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    X_test_target = pd.merge(\\n        X_test,\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Concatenate labels\\n    ta_tr_labels = pd.concat([X_test_target, r_test_target], axis=0)\\n\\n    # Concatenate Test Accepts and Test Rejects\\n    ta_tr = pd.concat([X_test, r_test], axis=0)\\n\\n    pred_test = model.predict_proba(ta_tr)[:, 1]\\n    # pred_test = model.predict(r_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=ta_tr.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        ta_tr_labels[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_formatted_code = \"def evaluate_test_combined(model, X_test, r_test):\\n    # Attach target to X_test and r_test\\n\\n    r_test_target = pd.merge(\\n        r_test,\\n        dfr_test_with_label[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    X_test_target = pd.merge(\\n        X_test,\\n        y_test[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Concatenate labels\\n    ta_tr_labels = pd.concat([X_test_target, r_test_target], axis=0)\\n\\n    # Concatenate Test Accepts and Test Rejects\\n    ta_tr = pd.concat([X_test, r_test], axis=0)\\n\\n    pred_test = model.predict_proba(ta_tr)[:, 1]\\n    # pred_test = model.predict(r_test)\\n    pred_test = pd.DataFrame(\\n        data=pred_test,\\n        columns=[\\\"pred\\\"],\\n        index=ta_tr.index.copy(),\\n    )\\n\\n    # Merge with Target\\n    pred_test2 = pd.merge(\\n        pred_test[\\\"pred\\\"],\\n        ta_tr_labels[\\\"target\\\"],\\n        how=\\\"inner\\\",\\n        left_index=True,\\n        right_index=True,\\n    )\\n\\n    # Make binary predictions based on cutoff 50percentile of the distribution\\n    q1 = pred_test2[\\\"pred\\\"].quantile(q=1 - conservative_dr)\\n    pred_test2[\\\"prediction_baseline\\\"] = pred_test2[\\\"pred\\\"].apply(\\n        lambda x: 0 if (x < q1) else 1\\n    )\\n    return pred_test2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_test_combined(model, X_test, r_test):\n",
    "    # Attach target to X_test and r_test\n",
    "\n",
    "    r_test_target = pd.merge(\n",
    "        r_test,\n",
    "        dfr_test_with_label[\"target\"],\n",
    "        how=\"inner\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    X_test_target = pd.merge(\n",
    "        X_test,\n",
    "        y_test[\"target\"],\n",
    "        how=\"inner\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    # Concatenate labels\n",
    "    ta_tr_labels = pd.concat([X_test_target, r_test_target], axis=0)\n",
    "\n",
    "    # Concatenate Test Accepts and Test Rejects\n",
    "    ta_tr = pd.concat([X_test, r_test], axis=0)\n",
    "\n",
    "    pred_test = model.predict_proba(ta_tr)[:, 1]\n",
    "    # pred_test = model.predict(r_test)\n",
    "    pred_test = pd.DataFrame(\n",
    "        data=pred_test,\n",
    "        columns=[\"pred\"],\n",
    "        index=ta_tr.index.copy(),\n",
    "    )\n",
    "\n",
    "    # Merge with Target\n",
    "    pred_test2 = pd.merge(\n",
    "        pred_test[\"pred\"],\n",
    "        ta_tr_labels[\"target\"],\n",
    "        how=\"inner\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "\n",
    "    # Make binary predictions based on cutoff 50percentile of the distribution\n",
    "    q1 = pred_test2[\"pred\"].quantile(q=1 - conservative_dr)\n",
    "    pred_test2[\"prediction_baseline\"] = pred_test2[\"pred\"].apply(\n",
    "        lambda x: 0 if (x < q1) else 1\n",
    "    )\n",
    "    return pred_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 205;\n",
       "                var nbb_unformatted_code = \"def flag_df_baseline(df):\\n\\n    # Flag kicked out bad cases (want more of these)\\n    if df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"CB\\\"\\n\\n    # Flag kicked out good cases (want less of these)\\n    elif df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"IB\\\"\\n\\n    # Flag kicked in good cases (want more of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"CG\\\"\\n\\n    # Flag kicked in bad cases (want less of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"IG\\\"\";\n",
       "                var nbb_formatted_code = \"def flag_df_baseline(df):\\n\\n    # Flag kicked out bad cases (want more of these)\\n    if df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"CB\\\"\\n\\n    # Flag kicked out good cases (want less of these)\\n    elif df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"IB\\\"\\n\\n    # Flag kicked in good cases (want more of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"CG\\\"\\n\\n    # Flag kicked in bad cases (want less of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"IG\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 205;\n",
       "                var nbb_unformatted_code = \"def flag_df_baseline(df):\\n\\n    # Flag kicked out bad cases (want more of these)\\n    if df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"CB\\\"\\n\\n    # Flag kicked out good cases (want less of these)\\n    elif df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"IB\\\"\\n\\n    # Flag kicked in good cases (want more of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"CG\\\"\\n\\n    # Flag kicked in bad cases (want less of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"IG\\\"\";\n",
       "                var nbb_formatted_code = \"def flag_df_baseline(df):\\n\\n    # Flag kicked out bad cases (want more of these)\\n    if df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"CB\\\"\\n\\n    # Flag kicked out good cases (want less of these)\\n    elif df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"IB\\\"\\n\\n    # Flag kicked in good cases (want more of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"CG\\\"\\n\\n    # Flag kicked in bad cases (want less of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"IG\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 205;\n",
       "                var nbb_unformatted_code = \"def flag_df_baseline(df):\\n\\n    # Flag kicked out bad cases (want more of these)\\n    if df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"CB\\\"\\n\\n    # Flag kicked out good cases (want less of these)\\n    elif df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"IB\\\"\\n\\n    # Flag kicked in good cases (want more of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"CG\\\"\\n\\n    # Flag kicked in bad cases (want less of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"IG\\\"\";\n",
       "                var nbb_formatted_code = \"def flag_df_baseline(df):\\n\\n    # Flag kicked out bad cases (want more of these)\\n    if df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"CB\\\"\\n\\n    # Flag kicked out good cases (want less of these)\\n    elif df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"IB\\\"\\n\\n    # Flag kicked in good cases (want more of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"CG\\\"\\n\\n    # Flag kicked in bad cases (want less of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"IG\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 205;\n",
       "                var nbb_unformatted_code = \"def flag_df_baseline(df):\\n\\n    # Flag kicked out bad cases (want more of these)\\n    if df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"CB\\\"\\n\\n    # Flag kicked out good cases (want less of these)\\n    elif df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"IB\\\"\\n\\n    # Flag kicked in good cases (want more of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"CG\\\"\\n\\n    # Flag kicked in bad cases (want less of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"IG\\\"\";\n",
       "                var nbb_formatted_code = \"def flag_df_baseline(df):\\n\\n    # Flag kicked out bad cases (want more of these)\\n    if df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"CB\\\"\\n\\n    # Flag kicked out good cases (want less of these)\\n    elif df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"IB\\\"\\n\\n    # Flag kicked in good cases (want more of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"CG\\\"\\n\\n    # Flag kicked in bad cases (want less of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"IG\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 205;\n",
       "                var nbb_unformatted_code = \"def flag_df_baseline(df):\\n\\n    # Flag kicked out bad cases (want more of these)\\n    if df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"CB\\\"\\n\\n    # Flag kicked out good cases (want less of these)\\n    elif df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"IB\\\"\\n\\n    # Flag kicked in good cases (want more of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"CG\\\"\\n\\n    # Flag kicked in bad cases (want less of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"IG\\\"\";\n",
       "                var nbb_formatted_code = \"def flag_df_baseline(df):\\n\\n    # Flag kicked out bad cases (want more of these)\\n    if df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"CB\\\"\\n\\n    # Flag kicked out good cases (want less of these)\\n    elif df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"IB\\\"\\n\\n    # Flag kicked in good cases (want more of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"CG\\\"\\n\\n    # Flag kicked in bad cases (want less of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"IG\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 205;\n",
       "                var nbb_unformatted_code = \"def flag_df_baseline(df):\\n\\n    # Flag kicked out bad cases (want more of these)\\n    if df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"CB\\\"\\n\\n    # Flag kicked out good cases (want less of these)\\n    elif df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"IB\\\"\\n\\n    # Flag kicked in good cases (want more of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"CG\\\"\\n\\n    # Flag kicked in bad cases (want less of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"IG\\\"\";\n",
       "                var nbb_formatted_code = \"def flag_df_baseline(df):\\n\\n    # Flag kicked out bad cases (want more of these)\\n    if df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"CB\\\"\\n\\n    # Flag kicked out good cases (want less of these)\\n    elif df[\\\"target\\\"] == 1 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"IB\\\"\\n\\n    # Flag kicked in good cases (want more of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 0:\\n        return \\\"CG\\\"\\n\\n    # Flag kicked in bad cases (want less of these)\\n    elif df[\\\"target\\\"] == 0 and df[\\\"prediction_baseline\\\"] == 1:\\n        return \\\"IG\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def flag_df_baseline(df):\n",
    "\n",
    "    # Flag kicked out bad cases (want more of these)\n",
    "    if df[\"target\"] == 1 and df[\"prediction_baseline\"] == 1:\n",
    "        return \"CB\"\n",
    "\n",
    "    # Flag kicked out good cases (want less of these)\n",
    "    elif df[\"target\"] == 1 and df[\"prediction_baseline\"] == 0:\n",
    "        return \"IB\"\n",
    "\n",
    "    # Flag kicked in good cases (want more of these)\n",
    "    elif df[\"target\"] == 0 and df[\"prediction_baseline\"] == 0:\n",
    "        return \"CG\"\n",
    "\n",
    "    # Flag kicked in bad cases (want less of these)\n",
    "    elif df[\"target\"] == 0 and df[\"prediction_baseline\"] == 1:\n",
    "        return \"IG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 206;\n",
       "                var nbb_unformatted_code = \"def kickout_baseline(df):\\n\\n    # Counts of kickout bad and kickout good\\n    counts = df[\\\"Flag\\\"].value_counts()\\n    if \\\"CB\\\" in df.values:\\n        cb = counts.CB  # want more of these\\n    else:\\n        cb = 0\\n    if \\\"IB\\\" in df.values:\\n        ib = counts.IB  # want less of these\\n    else:\\n        ib = 0\\n\\n    if \\\"CG\\\" in df.values:\\n        cg = counts.CG  # want more of these\\n    else:\\n        cg = 0\\n\\n    if \\\"IG\\\" in df.values:\\n        ig = counts.IG  # want less of these\\n    else:\\n        ig = 0\\n\\n    # Target\\n    total_bads = df[df[\\\"target\\\"] == 1].shape[0]\\n    total_goods = df[df[\\\"target\\\"] == 0].shape[0]\\n    pb = total_bads / (total_bads + total_goods)\\n    pg = total_goods / (total_bads + total_goods)\\n\\n    kickout = (((cb / pb) - (ib / pb)) / total_bads) * (pb ** 2)\\n    kickin = (((cg / pg) - (ig / pg)) / total_goods) * (pg ** 2)\\n    weighted_total = kickout + kickin\\n    return weighted_total\";\n",
       "                var nbb_formatted_code = \"def kickout_baseline(df):\\n\\n    # Counts of kickout bad and kickout good\\n    counts = df[\\\"Flag\\\"].value_counts()\\n    if \\\"CB\\\" in df.values:\\n        cb = counts.CB  # want more of these\\n    else:\\n        cb = 0\\n    if \\\"IB\\\" in df.values:\\n        ib = counts.IB  # want less of these\\n    else:\\n        ib = 0\\n\\n    if \\\"CG\\\" in df.values:\\n        cg = counts.CG  # want more of these\\n    else:\\n        cg = 0\\n\\n    if \\\"IG\\\" in df.values:\\n        ig = counts.IG  # want less of these\\n    else:\\n        ig = 0\\n\\n    # Target\\n    total_bads = df[df[\\\"target\\\"] == 1].shape[0]\\n    total_goods = df[df[\\\"target\\\"] == 0].shape[0]\\n    pb = total_bads / (total_bads + total_goods)\\n    pg = total_goods / (total_bads + total_goods)\\n\\n    kickout = (((cb / pb) - (ib / pb)) / total_bads) * (pb ** 2)\\n    kickin = (((cg / pg) - (ig / pg)) / total_goods) * (pg ** 2)\\n    weighted_total = kickout + kickin\\n    return weighted_total\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 206;\n",
       "                var nbb_unformatted_code = \"def kickout_baseline(df):\\n\\n    # Counts of kickout bad and kickout good\\n    counts = df[\\\"Flag\\\"].value_counts()\\n    if \\\"CB\\\" in df.values:\\n        cb = counts.CB  # want more of these\\n    else:\\n        cb = 0\\n    if \\\"IB\\\" in df.values:\\n        ib = counts.IB  # want less of these\\n    else:\\n        ib = 0\\n\\n    if \\\"CG\\\" in df.values:\\n        cg = counts.CG  # want more of these\\n    else:\\n        cg = 0\\n\\n    if \\\"IG\\\" in df.values:\\n        ig = counts.IG  # want less of these\\n    else:\\n        ig = 0\\n\\n    # Target\\n    total_bads = df[df[\\\"target\\\"] == 1].shape[0]\\n    total_goods = df[df[\\\"target\\\"] == 0].shape[0]\\n    pb = total_bads / (total_bads + total_goods)\\n    pg = total_goods / (total_bads + total_goods)\\n\\n    kickout = (((cb / pb) - (ib / pb)) / total_bads) * (pb ** 2)\\n    kickin = (((cg / pg) - (ig / pg)) / total_goods) * (pg ** 2)\\n    weighted_total = kickout + kickin\\n    return weighted_total\";\n",
       "                var nbb_formatted_code = \"def kickout_baseline(df):\\n\\n    # Counts of kickout bad and kickout good\\n    counts = df[\\\"Flag\\\"].value_counts()\\n    if \\\"CB\\\" in df.values:\\n        cb = counts.CB  # want more of these\\n    else:\\n        cb = 0\\n    if \\\"IB\\\" in df.values:\\n        ib = counts.IB  # want less of these\\n    else:\\n        ib = 0\\n\\n    if \\\"CG\\\" in df.values:\\n        cg = counts.CG  # want more of these\\n    else:\\n        cg = 0\\n\\n    if \\\"IG\\\" in df.values:\\n        ig = counts.IG  # want less of these\\n    else:\\n        ig = 0\\n\\n    # Target\\n    total_bads = df[df[\\\"target\\\"] == 1].shape[0]\\n    total_goods = df[df[\\\"target\\\"] == 0].shape[0]\\n    pb = total_bads / (total_bads + total_goods)\\n    pg = total_goods / (total_bads + total_goods)\\n\\n    kickout = (((cb / pb) - (ib / pb)) / total_bads) * (pb ** 2)\\n    kickin = (((cg / pg) - (ig / pg)) / total_goods) * (pg ** 2)\\n    weighted_total = kickout + kickin\\n    return weighted_total\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 206;\n",
       "                var nbb_unformatted_code = \"def kickout_baseline(df):\\n\\n    # Counts of kickout bad and kickout good\\n    counts = df[\\\"Flag\\\"].value_counts()\\n    if \\\"CB\\\" in df.values:\\n        cb = counts.CB  # want more of these\\n    else:\\n        cb = 0\\n    if \\\"IB\\\" in df.values:\\n        ib = counts.IB  # want less of these\\n    else:\\n        ib = 0\\n\\n    if \\\"CG\\\" in df.values:\\n        cg = counts.CG  # want more of these\\n    else:\\n        cg = 0\\n\\n    if \\\"IG\\\" in df.values:\\n        ig = counts.IG  # want less of these\\n    else:\\n        ig = 0\\n\\n    # Target\\n    total_bads = df[df[\\\"target\\\"] == 1].shape[0]\\n    total_goods = df[df[\\\"target\\\"] == 0].shape[0]\\n    pb = total_bads / (total_bads + total_goods)\\n    pg = total_goods / (total_bads + total_goods)\\n\\n    kickout = (((cb / pb) - (ib / pb)) / total_bads) * (pb ** 2)\\n    kickin = (((cg / pg) - (ig / pg)) / total_goods) * (pg ** 2)\\n    weighted_total = kickout + kickin\\n    return weighted_total\";\n",
       "                var nbb_formatted_code = \"def kickout_baseline(df):\\n\\n    # Counts of kickout bad and kickout good\\n    counts = df[\\\"Flag\\\"].value_counts()\\n    if \\\"CB\\\" in df.values:\\n        cb = counts.CB  # want more of these\\n    else:\\n        cb = 0\\n    if \\\"IB\\\" in df.values:\\n        ib = counts.IB  # want less of these\\n    else:\\n        ib = 0\\n\\n    if \\\"CG\\\" in df.values:\\n        cg = counts.CG  # want more of these\\n    else:\\n        cg = 0\\n\\n    if \\\"IG\\\" in df.values:\\n        ig = counts.IG  # want less of these\\n    else:\\n        ig = 0\\n\\n    # Target\\n    total_bads = df[df[\\\"target\\\"] == 1].shape[0]\\n    total_goods = df[df[\\\"target\\\"] == 0].shape[0]\\n    pb = total_bads / (total_bads + total_goods)\\n    pg = total_goods / (total_bads + total_goods)\\n\\n    kickout = (((cb / pb) - (ib / pb)) / total_bads) * (pb ** 2)\\n    kickin = (((cg / pg) - (ig / pg)) / total_goods) * (pg ** 2)\\n    weighted_total = kickout + kickin\\n    return weighted_total\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 206;\n",
       "                var nbb_unformatted_code = \"def kickout_baseline(df):\\n\\n    # Counts of kickout bad and kickout good\\n    counts = df[\\\"Flag\\\"].value_counts()\\n    if \\\"CB\\\" in df.values:\\n        cb = counts.CB  # want more of these\\n    else:\\n        cb = 0\\n    if \\\"IB\\\" in df.values:\\n        ib = counts.IB  # want less of these\\n    else:\\n        ib = 0\\n\\n    if \\\"CG\\\" in df.values:\\n        cg = counts.CG  # want more of these\\n    else:\\n        cg = 0\\n\\n    if \\\"IG\\\" in df.values:\\n        ig = counts.IG  # want less of these\\n    else:\\n        ig = 0\\n\\n    # Target\\n    total_bads = df[df[\\\"target\\\"] == 1].shape[0]\\n    total_goods = df[df[\\\"target\\\"] == 0].shape[0]\\n    pb = total_bads / (total_bads + total_goods)\\n    pg = total_goods / (total_bads + total_goods)\\n\\n    kickout = (((cb / pb) - (ib / pb)) / total_bads) * (pb ** 2)\\n    kickin = (((cg / pg) - (ig / pg)) / total_goods) * (pg ** 2)\\n    weighted_total = kickout + kickin\\n    return weighted_total\";\n",
       "                var nbb_formatted_code = \"def kickout_baseline(df):\\n\\n    # Counts of kickout bad and kickout good\\n    counts = df[\\\"Flag\\\"].value_counts()\\n    if \\\"CB\\\" in df.values:\\n        cb = counts.CB  # want more of these\\n    else:\\n        cb = 0\\n    if \\\"IB\\\" in df.values:\\n        ib = counts.IB  # want less of these\\n    else:\\n        ib = 0\\n\\n    if \\\"CG\\\" in df.values:\\n        cg = counts.CG  # want more of these\\n    else:\\n        cg = 0\\n\\n    if \\\"IG\\\" in df.values:\\n        ig = counts.IG  # want less of these\\n    else:\\n        ig = 0\\n\\n    # Target\\n    total_bads = df[df[\\\"target\\\"] == 1].shape[0]\\n    total_goods = df[df[\\\"target\\\"] == 0].shape[0]\\n    pb = total_bads / (total_bads + total_goods)\\n    pg = total_goods / (total_bads + total_goods)\\n\\n    kickout = (((cb / pb) - (ib / pb)) / total_bads) * (pb ** 2)\\n    kickin = (((cg / pg) - (ig / pg)) / total_goods) * (pg ** 2)\\n    weighted_total = kickout + kickin\\n    return weighted_total\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 206;\n",
       "                var nbb_unformatted_code = \"def kickout_baseline(df):\\n\\n    # Counts of kickout bad and kickout good\\n    counts = df[\\\"Flag\\\"].value_counts()\\n    if \\\"CB\\\" in df.values:\\n        cb = counts.CB  # want more of these\\n    else:\\n        cb = 0\\n    if \\\"IB\\\" in df.values:\\n        ib = counts.IB  # want less of these\\n    else:\\n        ib = 0\\n\\n    if \\\"CG\\\" in df.values:\\n        cg = counts.CG  # want more of these\\n    else:\\n        cg = 0\\n\\n    if \\\"IG\\\" in df.values:\\n        ig = counts.IG  # want less of these\\n    else:\\n        ig = 0\\n\\n    # Target\\n    total_bads = df[df[\\\"target\\\"] == 1].shape[0]\\n    total_goods = df[df[\\\"target\\\"] == 0].shape[0]\\n    pb = total_bads / (total_bads + total_goods)\\n    pg = total_goods / (total_bads + total_goods)\\n\\n    kickout = (((cb / pb) - (ib / pb)) / total_bads) * (pb ** 2)\\n    kickin = (((cg / pg) - (ig / pg)) / total_goods) * (pg ** 2)\\n    weighted_total = kickout + kickin\\n    return weighted_total\";\n",
       "                var nbb_formatted_code = \"def kickout_baseline(df):\\n\\n    # Counts of kickout bad and kickout good\\n    counts = df[\\\"Flag\\\"].value_counts()\\n    if \\\"CB\\\" in df.values:\\n        cb = counts.CB  # want more of these\\n    else:\\n        cb = 0\\n    if \\\"IB\\\" in df.values:\\n        ib = counts.IB  # want less of these\\n    else:\\n        ib = 0\\n\\n    if \\\"CG\\\" in df.values:\\n        cg = counts.CG  # want more of these\\n    else:\\n        cg = 0\\n\\n    if \\\"IG\\\" in df.values:\\n        ig = counts.IG  # want less of these\\n    else:\\n        ig = 0\\n\\n    # Target\\n    total_bads = df[df[\\\"target\\\"] == 1].shape[0]\\n    total_goods = df[df[\\\"target\\\"] == 0].shape[0]\\n    pb = total_bads / (total_bads + total_goods)\\n    pg = total_goods / (total_bads + total_goods)\\n\\n    kickout = (((cb / pb) - (ib / pb)) / total_bads) * (pb ** 2)\\n    kickin = (((cg / pg) - (ig / pg)) / total_goods) * (pg ** 2)\\n    weighted_total = kickout + kickin\\n    return weighted_total\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 206;\n",
       "                var nbb_unformatted_code = \"def kickout_baseline(df):\\n\\n    # Counts of kickout bad and kickout good\\n    counts = df[\\\"Flag\\\"].value_counts()\\n    if \\\"CB\\\" in df.values:\\n        cb = counts.CB  # want more of these\\n    else:\\n        cb = 0\\n    if \\\"IB\\\" in df.values:\\n        ib = counts.IB  # want less of these\\n    else:\\n        ib = 0\\n\\n    if \\\"CG\\\" in df.values:\\n        cg = counts.CG  # want more of these\\n    else:\\n        cg = 0\\n\\n    if \\\"IG\\\" in df.values:\\n        ig = counts.IG  # want less of these\\n    else:\\n        ig = 0\\n\\n    # Target\\n    total_bads = df[df[\\\"target\\\"] == 1].shape[0]\\n    total_goods = df[df[\\\"target\\\"] == 0].shape[0]\\n    pb = total_bads / (total_bads + total_goods)\\n    pg = total_goods / (total_bads + total_goods)\\n\\n    kickout = (((cb / pb) - (ib / pb)) / total_bads) * (pb ** 2)\\n    kickin = (((cg / pg) - (ig / pg)) / total_goods) * (pg ** 2)\\n    weighted_total = kickout + kickin\\n    return weighted_total\";\n",
       "                var nbb_formatted_code = \"def kickout_baseline(df):\\n\\n    # Counts of kickout bad and kickout good\\n    counts = df[\\\"Flag\\\"].value_counts()\\n    if \\\"CB\\\" in df.values:\\n        cb = counts.CB  # want more of these\\n    else:\\n        cb = 0\\n    if \\\"IB\\\" in df.values:\\n        ib = counts.IB  # want less of these\\n    else:\\n        ib = 0\\n\\n    if \\\"CG\\\" in df.values:\\n        cg = counts.CG  # want more of these\\n    else:\\n        cg = 0\\n\\n    if \\\"IG\\\" in df.values:\\n        ig = counts.IG  # want less of these\\n    else:\\n        ig = 0\\n\\n    # Target\\n    total_bads = df[df[\\\"target\\\"] == 1].shape[0]\\n    total_goods = df[df[\\\"target\\\"] == 0].shape[0]\\n    pb = total_bads / (total_bads + total_goods)\\n    pg = total_goods / (total_bads + total_goods)\\n\\n    kickout = (((cb / pb) - (ib / pb)) / total_bads) * (pb ** 2)\\n    kickin = (((cg / pg) - (ig / pg)) / total_goods) * (pg ** 2)\\n    weighted_total = kickout + kickin\\n    return weighted_total\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def kickout_baseline(df):\n",
    "\n",
    "    # Counts of kickout bad and kickout good\n",
    "    counts = df[\"Flag\"].value_counts()\n",
    "    if \"CB\" in df.values:\n",
    "        cb = counts.CB  # want more of these\n",
    "    else:\n",
    "        cb = 0\n",
    "    if \"IB\" in df.values:\n",
    "        ib = counts.IB  # want less of these\n",
    "    else:\n",
    "        ib = 0\n",
    "\n",
    "    if \"CG\" in df.values:\n",
    "        cg = counts.CG  # want more of these\n",
    "    else:\n",
    "        cg = 0\n",
    "\n",
    "    if \"IG\" in df.values:\n",
    "        ig = counts.IG  # want less of these\n",
    "    else:\n",
    "        ig = 0\n",
    "\n",
    "    # Target\n",
    "    total_bads = df[df[\"target\"] == 1].shape[0]\n",
    "    total_goods = df[df[\"target\"] == 0].shape[0]\n",
    "    pb = total_bads / (total_bads + total_goods)\n",
    "    pg = total_goods / (total_bads + total_goods)\n",
    "\n",
    "    kickout = (((cb / pb) - (ib / pb)) / total_bads) * (pb ** 2)\n",
    "    kickin = (((cg / pg) - (ig / pg)) / total_goods) * (pg ** 2)\n",
    "    weighted_total = kickout + kickin\n",
    "    return weighted_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 236;\n",
       "                var nbb_unformatted_code = \"def standard_evaluation(pred_data):\\n    # Concatenate X_test and r_test\\n    ta_tr = pd.concat([X_test, r_test], axis=0)\\n    # Make predictions\\n    f1 = f1_score(pred_data[\\\"target\\\"], pred_data[\\\"prediction_baseline\\\"])\\n    auc = roc_auc_score(pred_data[\\\"target\\\"], pred_data[\\\"prediction_baseline\\\"])\\n    return f1, auc\";\n",
       "                var nbb_formatted_code = \"def standard_evaluation(pred_data):\\n    # Concatenate X_test and r_test\\n    ta_tr = pd.concat([X_test, r_test], axis=0)\\n    # Make predictions\\n    f1 = f1_score(pred_data[\\\"target\\\"], pred_data[\\\"prediction_baseline\\\"])\\n    auc = roc_auc_score(pred_data[\\\"target\\\"], pred_data[\\\"prediction_baseline\\\"])\\n    return f1, auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 236;\n",
       "                var nbb_unformatted_code = \"def standard_evaluation(pred_data):\\n    # Concatenate X_test and r_test\\n    ta_tr = pd.concat([X_test, r_test], axis=0)\\n    # Make predictions\\n    f1 = f1_score(pred_data[\\\"target\\\"], pred_data[\\\"prediction_baseline\\\"])\\n    auc = roc_auc_score(pred_data[\\\"target\\\"], pred_data[\\\"prediction_baseline\\\"])\\n    return f1, auc\";\n",
       "                var nbb_formatted_code = \"def standard_evaluation(pred_data):\\n    # Concatenate X_test and r_test\\n    ta_tr = pd.concat([X_test, r_test], axis=0)\\n    # Make predictions\\n    f1 = f1_score(pred_data[\\\"target\\\"], pred_data[\\\"prediction_baseline\\\"])\\n    auc = roc_auc_score(pred_data[\\\"target\\\"], pred_data[\\\"prediction_baseline\\\"])\\n    return f1, auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 236;\n",
       "                var nbb_unformatted_code = \"def standard_evaluation(pred_data):\\n    # Concatenate X_test and r_test\\n    ta_tr = pd.concat([X_test, r_test], axis=0)\\n    # Make predictions\\n    f1 = f1_score(pred_data[\\\"target\\\"], pred_data[\\\"prediction_baseline\\\"])\\n    auc = roc_auc_score(pred_data[\\\"target\\\"], pred_data[\\\"prediction_baseline\\\"])\\n    return f1, auc\";\n",
       "                var nbb_formatted_code = \"def standard_evaluation(pred_data):\\n    # Concatenate X_test and r_test\\n    ta_tr = pd.concat([X_test, r_test], axis=0)\\n    # Make predictions\\n    f1 = f1_score(pred_data[\\\"target\\\"], pred_data[\\\"prediction_baseline\\\"])\\n    auc = roc_auc_score(pred_data[\\\"target\\\"], pred_data[\\\"prediction_baseline\\\"])\\n    return f1, auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 236;\n",
       "                var nbb_unformatted_code = \"def standard_evaluation(pred_data):\\n    # Concatenate X_test and r_test\\n    ta_tr = pd.concat([X_test, r_test], axis=0)\\n    # Make predictions\\n    f1 = f1_score(pred_data[\\\"target\\\"], pred_data[\\\"prediction_baseline\\\"])\\n    auc = roc_auc_score(pred_data[\\\"target\\\"], pred_data[\\\"prediction_baseline\\\"])\\n    return f1, auc\";\n",
       "                var nbb_formatted_code = \"def standard_evaluation(pred_data):\\n    # Concatenate X_test and r_test\\n    ta_tr = pd.concat([X_test, r_test], axis=0)\\n    # Make predictions\\n    f1 = f1_score(pred_data[\\\"target\\\"], pred_data[\\\"prediction_baseline\\\"])\\n    auc = roc_auc_score(pred_data[\\\"target\\\"], pred_data[\\\"prediction_baseline\\\"])\\n    return f1, auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 236;\n",
       "                var nbb_unformatted_code = \"def standard_evaluation(pred_data):\\n    # Concatenate X_test and r_test\\n    ta_tr = pd.concat([X_test, r_test], axis=0)\\n    # Make predictions\\n    f1 = f1_score(pred_data[\\\"target\\\"], pred_data[\\\"prediction_baseline\\\"])\\n    auc = roc_auc_score(pred_data[\\\"target\\\"], pred_data[\\\"prediction_baseline\\\"])\\n    return f1, auc\";\n",
       "                var nbb_formatted_code = \"def standard_evaluation(pred_data):\\n    # Concatenate X_test and r_test\\n    ta_tr = pd.concat([X_test, r_test], axis=0)\\n    # Make predictions\\n    f1 = f1_score(pred_data[\\\"target\\\"], pred_data[\\\"prediction_baseline\\\"])\\n    auc = roc_auc_score(pred_data[\\\"target\\\"], pred_data[\\\"prediction_baseline\\\"])\\n    return f1, auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 236;\n",
       "                var nbb_unformatted_code = \"def standard_evaluation(pred_data):\\n    # Concatenate X_test and r_test\\n    ta_tr = pd.concat([X_test, r_test], axis=0)\\n    # Make predictions\\n    f1 = f1_score(pred_data[\\\"target\\\"], pred_data[\\\"prediction_baseline\\\"])\\n    auc = roc_auc_score(pred_data[\\\"target\\\"], pred_data[\\\"prediction_baseline\\\"])\\n    return f1, auc\";\n",
       "                var nbb_formatted_code = \"def standard_evaluation(pred_data):\\n    # Concatenate X_test and r_test\\n    ta_tr = pd.concat([X_test, r_test], axis=0)\\n    # Make predictions\\n    f1 = f1_score(pred_data[\\\"target\\\"], pred_data[\\\"prediction_baseline\\\"])\\n    auc = roc_auc_score(pred_data[\\\"target\\\"], pred_data[\\\"prediction_baseline\\\"])\\n    return f1, auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def standard_evaluation(pred_data):\n",
    "    # Concatenate X_test and r_test\n",
    "    ta_tr = pd.concat([X_test, r_test], axis=0)\n",
    "    # Make predictions\n",
    "    f1 = f1_score(pred_data[\"target\"], pred_data[\"prediction_baseline\"])\n",
    "    auc = roc_auc_score(pred_data[\"target\"], pred_data[\"prediction_baseline\"])\n",
    "    return f1, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prediction before RI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: KGB Model ($m_{1}$)  <br>\n",
    "Step 2: Score Test Accepts and Test Rejects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 248;\n",
       "                var nbb_unformatted_code = \"pred_test_a = evaluate_test_accepts(KGB1, X_test)\\npred_test_r = evaluate_test_rejects(KGB1, r_test)\\npred_test_combined = evaluate_test_combined(KGB1, X_test, r_test)\";\n",
       "                var nbb_formatted_code = \"pred_test_a = evaluate_test_accepts(KGB1, X_test)\\npred_test_r = evaluate_test_rejects(KGB1, r_test)\\npred_test_combined = evaluate_test_combined(KGB1, X_test, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 248;\n",
       "                var nbb_unformatted_code = \"pred_test_a = evaluate_test_accepts(KGB1, X_test)\\npred_test_r = evaluate_test_rejects(KGB1, r_test)\\npred_test_combined = evaluate_test_combined(KGB1, X_test, r_test)\";\n",
       "                var nbb_formatted_code = \"pred_test_a = evaluate_test_accepts(KGB1, X_test)\\npred_test_r = evaluate_test_rejects(KGB1, r_test)\\npred_test_combined = evaluate_test_combined(KGB1, X_test, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 248;\n",
       "                var nbb_unformatted_code = \"pred_test_a = evaluate_test_accepts(KGB1, X_test)\\npred_test_r = evaluate_test_rejects(KGB1, r_test)\\npred_test_combined = evaluate_test_combined(KGB1, X_test, r_test)\";\n",
       "                var nbb_formatted_code = \"pred_test_a = evaluate_test_accepts(KGB1, X_test)\\npred_test_r = evaluate_test_rejects(KGB1, r_test)\\npred_test_combined = evaluate_test_combined(KGB1, X_test, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 248;\n",
       "                var nbb_unformatted_code = \"pred_test_a = evaluate_test_accepts(KGB1, X_test)\\npred_test_r = evaluate_test_rejects(KGB1, r_test)\\npred_test_combined = evaluate_test_combined(KGB1, X_test, r_test)\";\n",
       "                var nbb_formatted_code = \"pred_test_a = evaluate_test_accepts(KGB1, X_test)\\npred_test_r = evaluate_test_rejects(KGB1, r_test)\\npred_test_combined = evaluate_test_combined(KGB1, X_test, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 248;\n",
       "                var nbb_unformatted_code = \"pred_test_a = evaluate_test_accepts(KGB1, X_test)\\npred_test_r = evaluate_test_rejects(KGB1, r_test)\\npred_test_combined = evaluate_test_combined(KGB1, X_test, r_test)\";\n",
       "                var nbb_formatted_code = \"pred_test_a = evaluate_test_accepts(KGB1, X_test)\\npred_test_r = evaluate_test_rejects(KGB1, r_test)\\npred_test_combined = evaluate_test_combined(KGB1, X_test, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 248;\n",
       "                var nbb_unformatted_code = \"pred_test_a = evaluate_test_accepts(KGB1, X_test)\\npred_test_r = evaluate_test_rejects(KGB1, r_test)\\npred_test_combined = evaluate_test_combined(KGB1, X_test, r_test)\";\n",
       "                var nbb_formatted_code = \"pred_test_a = evaluate_test_accepts(KGB1, X_test)\\npred_test_r = evaluate_test_rejects(KGB1, r_test)\\npred_test_combined = evaluate_test_combined(KGB1, X_test, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a = evaluate_test_accepts(KGB1, X_test)\n",
    "pred_test_r = evaluate_test_rejects(KGB1, r_test)\n",
    "pred_test_combined = evaluate_test_combined(KGB1, X_test, r_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 249;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\n#predictions_accepts_beforeRI = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\n# predictions_accepts_beforeRI = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 249;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\n#predictions_accepts_beforeRI = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\n# predictions_accepts_beforeRI = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 249;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\n#predictions_accepts_beforeRI = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\n# predictions_accepts_beforeRI = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 249;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\n#predictions_accepts_beforeRI = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\n# predictions_accepts_beforeRI = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 249;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\n#predictions_accepts_beforeRI = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\n# predictions_accepts_beforeRI = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 249;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\n#predictions_accepts_beforeRI = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\n# predictions_accepts_beforeRI = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a[\"Flag\"] = pred_test_a.apply(flag_df_baseline, axis=1)\n",
    "# predictions_accepts_beforeRI = [round(kickout_baseline(pred_test_a).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 250;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_beforeRI = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_beforeRI = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 250;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_beforeRI = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_beforeRI = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 250;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_beforeRI = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_beforeRI = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 250;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_beforeRI = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_beforeRI = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 250;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_beforeRI = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_beforeRI = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 250;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_beforeRI = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_beforeRI = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_r[\"Flag\"] = pred_test_r.apply(flag_df_baseline, axis=1)\n",
    "predictions_rejects_beforeRI = [round(kickout_baseline(pred_test_r).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 251;\n",
       "                var nbb_unformatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_beforeRI = [\\n    round(kickout_baseline(pred_test_combined).tolist(), 3)\\n]\";\n",
       "                var nbb_formatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_beforeRI = [\\n    round(kickout_baseline(pred_test_combined).tolist(), 3)\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 251;\n",
       "                var nbb_unformatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_beforeRI = [\\n    round(kickout_baseline(pred_test_combined).tolist(), 3)\\n]\";\n",
       "                var nbb_formatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_beforeRI = [\\n    round(kickout_baseline(pred_test_combined).tolist(), 3)\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 251;\n",
       "                var nbb_unformatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_beforeRI = [\\n    round(kickout_baseline(pred_test_combined).tolist(), 3)\\n]\";\n",
       "                var nbb_formatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_beforeRI = [\\n    round(kickout_baseline(pred_test_combined).tolist(), 3)\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 251;\n",
       "                var nbb_unformatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_beforeRI = [\\n    round(kickout_baseline(pred_test_combined).tolist(), 3)\\n]\";\n",
       "                var nbb_formatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_beforeRI = [\\n    round(kickout_baseline(pred_test_combined).tolist(), 3)\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 251;\n",
       "                var nbb_unformatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_beforeRI = [\\n    round(kickout_baseline(pred_test_combined).tolist(), 3)\\n]\";\n",
       "                var nbb_formatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_beforeRI = [\\n    round(kickout_baseline(pred_test_combined).tolist(), 3)\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 251;\n",
       "                var nbb_unformatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_beforeRI = [\\n    round(kickout_baseline(pred_test_combined).tolist(), 3)\\n]\";\n",
       "                var nbb_formatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_beforeRI = [\\n    round(kickout_baseline(pred_test_combined).tolist(), 3)\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_combined[\"Flag\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\n",
    "predictions_combined_beforeRI = [\n",
    "    round(kickout_baseline(pred_test_combined).tolist(), 3)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.865]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 252;\n",
       "                var nbb_unformatted_code = \"predictions_accepts_beforeRI\";\n",
       "                var nbb_formatted_code = \"predictions_accepts_beforeRI\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 252;\n",
       "                var nbb_unformatted_code = \"predictions_accepts_beforeRI\";\n",
       "                var nbb_formatted_code = \"predictions_accepts_beforeRI\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 252;\n",
       "                var nbb_unformatted_code = \"predictions_accepts_beforeRI\";\n",
       "                var nbb_formatted_code = \"predictions_accepts_beforeRI\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 252;\n",
       "                var nbb_unformatted_code = \"predictions_accepts_beforeRI\";\n",
       "                var nbb_formatted_code = \"predictions_accepts_beforeRI\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 252;\n",
       "                var nbb_unformatted_code = \"predictions_accepts_beforeRI\";\n",
       "                var nbb_formatted_code = \"predictions_accepts_beforeRI\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 252;\n",
       "                var nbb_unformatted_code = \"predictions_accepts_beforeRI\";\n",
       "                var nbb_formatted_code = \"predictions_accepts_beforeRI\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_accepts_beforeRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 253;\n",
       "                var nbb_unformatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_formatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 253;\n",
       "                var nbb_unformatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_formatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 253;\n",
       "                var nbb_unformatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_formatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 253;\n",
       "                var nbb_unformatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_formatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 253;\n",
       "                var nbb_unformatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_formatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 253;\n",
       "                var nbb_unformatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_formatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1, auc = standard_evaluation(pred_test_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6728601109222342"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 254;\n",
       "                var nbb_unformatted_code = \"auc\";\n",
       "                var nbb_formatted_code = \"auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 254;\n",
       "                var nbb_unformatted_code = \"auc\";\n",
       "                var nbb_formatted_code = \"auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 254;\n",
       "                var nbb_unformatted_code = \"auc\";\n",
       "                var nbb_formatted_code = \"auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 254;\n",
       "                var nbb_unformatted_code = \"auc\";\n",
       "                var nbb_formatted_code = \"auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 254;\n",
       "                var nbb_unformatted_code = \"auc\";\n",
       "                var nbb_formatted_code = \"auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 254;\n",
       "                var nbb_unformatted_code = \"auc\";\n",
       "                var nbb_formatted_code = \"auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Predicions Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: KGB Model ($m_{1}$)  <br>\n",
    "Step 2: Infer status of each reject <br> \n",
    "Step 3: Redevelop KGB mdoel with inferred rejects ($m_{2}$)  <br>\n",
    "Step 4: Score Test Accepts and Test Rejects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 255;\n",
       "                var nbb_unformatted_code = \"KGB_baseline_new = predict_rejects(KGB1, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)\";\n",
       "                var nbb_formatted_code = \"KGB_baseline_new = predict_rejects(KGB1, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 255;\n",
       "                var nbb_unformatted_code = \"KGB_baseline_new = predict_rejects(KGB1, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)\";\n",
       "                var nbb_formatted_code = \"KGB_baseline_new = predict_rejects(KGB1, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 255;\n",
       "                var nbb_unformatted_code = \"KGB_baseline_new = predict_rejects(KGB1, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)\";\n",
       "                var nbb_formatted_code = \"KGB_baseline_new = predict_rejects(KGB1, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 255;\n",
       "                var nbb_unformatted_code = \"KGB_baseline_new = predict_rejects(KGB1, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)\";\n",
       "                var nbb_formatted_code = \"KGB_baseline_new = predict_rejects(KGB1, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 255;\n",
       "                var nbb_unformatted_code = \"KGB_baseline_new = predict_rejects(KGB1, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)\";\n",
       "                var nbb_formatted_code = \"KGB_baseline_new = predict_rejects(KGB1, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 255;\n",
       "                var nbb_unformatted_code = \"KGB_baseline_new = predict_rejects(KGB1, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)\";\n",
       "                var nbb_formatted_code = \"KGB_baseline_new = predict_rejects(KGB1, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "KGB_baseline_new = predict_rejects(KGB1, r_dev)\n",
    "pred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\n",
    "pred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\n",
    "pred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 256;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_base = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_base = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 256;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_base = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_base = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 256;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_base = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_base = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 256;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_base = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_base = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 256;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_base = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_base = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 256;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_base = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_base = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a[\"Flag\"] = pred_test_a.apply(flag_df_baseline, axis=1)\n",
    "predictions_accepts_base = [round(kickout_baseline(pred_test_a).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 257;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_base = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_base = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 257;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_base = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_base = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 257;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_base = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_base = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 257;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_base = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_base = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 257;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_base = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_base = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 257;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_base = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_base = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_r[\"Flag\"] = pred_test_r.apply(flag_df_baseline, axis=1)\n",
    "predictions_rejects_base = [round(kickout_baseline(pred_test_r).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 258;\n",
       "                var nbb_unformatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_base = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_base = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 258;\n",
       "                var nbb_unformatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_base = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_base = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 258;\n",
       "                var nbb_unformatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_base = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_base = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 258;\n",
       "                var nbb_unformatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_base = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_base = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 258;\n",
       "                var nbb_unformatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_base = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_base = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 258;\n",
       "                var nbb_unformatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_base = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_base = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_combined[\"Flag\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\n",
    "predictions_combined_base = [round(kickout_baseline(pred_test_combined).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"predictions_accepts_base\";\n",
       "                var nbb_formatted_code = \"predictions_accepts_base\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_accepts_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 259;\n",
       "                var nbb_unformatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_formatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 259;\n",
       "                var nbb_unformatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_formatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 259;\n",
       "                var nbb_unformatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_formatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 259;\n",
       "                var nbb_unformatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_formatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 259;\n",
       "                var nbb_unformatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_formatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 259;\n",
       "                var nbb_unformatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_formatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1, auc = standard_evaluation(pred_test_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6229914661996256"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 260;\n",
       "                var nbb_unformatted_code = \"auc\";\n",
       "                var nbb_formatted_code = \"auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 260;\n",
       "                var nbb_unformatted_code = \"auc\";\n",
       "                var nbb_formatted_code = \"auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 260;\n",
       "                var nbb_unformatted_code = \"auc\";\n",
       "                var nbb_formatted_code = \"auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 260;\n",
       "                var nbb_unformatted_code = \"auc\";\n",
       "                var nbb_formatted_code = \"auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 260;\n",
       "                var nbb_unformatted_code = \"auc\";\n",
       "                var nbb_formatted_code = \"auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 260;\n",
       "                var nbb_unformatted_code = \"auc\";\n",
       "                var nbb_formatted_code = \"auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. KGB model of best iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: KGB Model ($m_{1}$)  <br>\n",
    "Step 2: Infer status of each reject <br> \n",
    "Step 3: Choose the most certain predictions (0.05q and 0.95q of the predicted probailities) <br>\n",
    "Step 4: Add the most certain predictions to the training sample\n",
    "Step 5: Redevelop KGB Model ($m_{2}$)  <br>\n",
    "Step 6: Repeat Step 5 until convergence - best F1 score ($m_{i}$)  <br> \n",
    "Step 7: Score Test Accepts and Test Rejects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 261;\n",
       "                var nbb_unformatted_code = \"pred_test_a = evaluate_test_accepts(KGB_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_new, X_test, r_test)\";\n",
       "                var nbb_formatted_code = \"pred_test_a = evaluate_test_accepts(KGB_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_new, X_test, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 261;\n",
       "                var nbb_unformatted_code = \"pred_test_a = evaluate_test_accepts(KGB_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_new, X_test, r_test)\";\n",
       "                var nbb_formatted_code = \"pred_test_a = evaluate_test_accepts(KGB_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_new, X_test, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 261;\n",
       "                var nbb_unformatted_code = \"pred_test_a = evaluate_test_accepts(KGB_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_new, X_test, r_test)\";\n",
       "                var nbb_formatted_code = \"pred_test_a = evaluate_test_accepts(KGB_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_new, X_test, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 261;\n",
       "                var nbb_unformatted_code = \"pred_test_a = evaluate_test_accepts(KGB_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_new, X_test, r_test)\";\n",
       "                var nbb_formatted_code = \"pred_test_a = evaluate_test_accepts(KGB_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_new, X_test, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 261;\n",
       "                var nbb_unformatted_code = \"pred_test_a = evaluate_test_accepts(KGB_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_new, X_test, r_test)\";\n",
       "                var nbb_formatted_code = \"pred_test_a = evaluate_test_accepts(KGB_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_new, X_test, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 261;\n",
       "                var nbb_unformatted_code = \"pred_test_a = evaluate_test_accepts(KGB_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_new, X_test, r_test)\";\n",
       "                var nbb_formatted_code = \"pred_test_a = evaluate_test_accepts(KGB_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_new, X_test, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a = evaluate_test_accepts(KGB_new, X_test)\n",
    "pred_test_r = evaluate_test_rejects(KGB_new, r_test)\n",
    "pred_test_combined = evaluate_test_combined(KGB_new, X_test, r_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 262;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_iter = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_iter = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 262;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_iter = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_iter = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 262;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_iter = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_iter = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 262;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_iter = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_iter = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 262;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_iter = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_iter = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 262;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_iter = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_iter = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a[\"Flag\"] = pred_test_a.apply(flag_df_baseline, axis=1)\n",
    "predictions_accepts_iter = [round(kickout_baseline(pred_test_a).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 263;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_iter = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_iter = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 263;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_iter = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_iter = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 263;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_iter = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_iter = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 263;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_iter = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_iter = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 263;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_iter = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_iter = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 263;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_iter = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_iter = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_r[\"Flag\"] = pred_test_r.apply(flag_df_baseline, axis=1)\n",
    "predictions_rejects_iter = [round(kickout_baseline(pred_test_r).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 264;\n",
       "                var nbb_unformatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_iter = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_iter = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 264;\n",
       "                var nbb_unformatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_iter = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_iter = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 264;\n",
       "                var nbb_unformatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_iter = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_iter = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 264;\n",
       "                var nbb_unformatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_iter = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_iter = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 264;\n",
       "                var nbb_unformatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_iter = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_iter = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 264;\n",
       "                var nbb_unformatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_iter = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_iter = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_combined[\"Flag\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\n",
    "predictions_combined_iter = [round(kickout_baseline(pred_test_combined).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.904]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"predictions_accepts_iter\";\n",
       "                var nbb_formatted_code = \"predictions_accepts_iter\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_accepts_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 265;\n",
       "                var nbb_unformatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_formatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 265;\n",
       "                var nbb_unformatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_formatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 265;\n",
       "                var nbb_unformatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_formatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 265;\n",
       "                var nbb_unformatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_formatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 265;\n",
       "                var nbb_unformatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_formatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 265;\n",
       "                var nbb_unformatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_formatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1, auc = standard_evaluation(pred_test_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6763028211336047"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 266;\n",
       "                var nbb_unformatted_code = \"auc\";\n",
       "                var nbb_formatted_code = \"auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 266;\n",
       "                var nbb_unformatted_code = \"auc\";\n",
       "                var nbb_formatted_code = \"auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 266;\n",
       "                var nbb_unformatted_code = \"auc\";\n",
       "                var nbb_formatted_code = \"auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 266;\n",
       "                var nbb_unformatted_code = \"auc\";\n",
       "                var nbb_formatted_code = \"auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 266;\n",
       "                var nbb_unformatted_code = \"auc\";\n",
       "                var nbb_formatted_code = \"auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 266;\n",
       "                var nbb_unformatted_code = \"auc\";\n",
       "                var nbb_formatted_code = \"auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. New model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: KGB Model ($m_{1}$)  <br>\n",
    "Step 2: Infer status of each reject <br> \n",
    "Step 3: Choose the most certain predictions (0.05q and 0.95q of the predicted probailities) <br>\n",
    "Step 4: Add the most certain predictions to the training sample <br>\n",
    "Step 5: Redevelop KGB Model ($m_{2}$)  <br>\n",
    "Step 6: Repeat Step 5 until convergence - best F1 score ($m_{i}$) <br> \n",
    "Step 7: Infer status of each reject with ($m_{i}$) <br> \n",
    "Step 8: Redevelop KGB mdoel with inferred rejects ($m_{final}$) <br> \n",
    "Step 9: Score Test Accepts and Test Rejects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 267;\n",
       "                var nbb_unformatted_code = \"KGB_baseline_new = predict_rejects(KGB_new, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)\";\n",
       "                var nbb_formatted_code = \"KGB_baseline_new = predict_rejects(KGB_new, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 267;\n",
       "                var nbb_unformatted_code = \"KGB_baseline_new = predict_rejects(KGB_new, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)\";\n",
       "                var nbb_formatted_code = \"KGB_baseline_new = predict_rejects(KGB_new, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 267;\n",
       "                var nbb_unformatted_code = \"KGB_baseline_new = predict_rejects(KGB_new, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)\";\n",
       "                var nbb_formatted_code = \"KGB_baseline_new = predict_rejects(KGB_new, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 267;\n",
       "                var nbb_unformatted_code = \"KGB_baseline_new = predict_rejects(KGB_new, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)\";\n",
       "                var nbb_formatted_code = \"KGB_baseline_new = predict_rejects(KGB_new, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 267;\n",
       "                var nbb_unformatted_code = \"KGB_baseline_new = predict_rejects(KGB_new, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)\";\n",
       "                var nbb_formatted_code = \"KGB_baseline_new = predict_rejects(KGB_new, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 267;\n",
       "                var nbb_unformatted_code = \"KGB_baseline_new = predict_rejects(KGB_new, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)\";\n",
       "                var nbb_formatted_code = \"KGB_baseline_new = predict_rejects(KGB_new, r_dev)\\npred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\\npred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\\npred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "KGB_baseline_new = predict_rejects(KGB_new, r_dev)\n",
    "pred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test)\n",
    "pred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test)\n",
    "pred_test_combined = evaluate_test_combined(KGB_baseline_new, X_test, r_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 268;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_new = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_new = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 268;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_new = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_new = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 268;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_new = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_new = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 268;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_new = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_new = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 268;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_new = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_new = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 268;\n",
       "                var nbb_unformatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_new = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_a[\\\"Flag\\\"] = pred_test_a.apply(flag_df_baseline, axis=1)\\npredictions_accepts_new = [round(kickout_baseline(pred_test_a).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_a[\"Flag\"] = pred_test_a.apply(flag_df_baseline, axis=1)\n",
    "predictions_accepts_new = [round(kickout_baseline(pred_test_a).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 269;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_new = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_new = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 269;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_new = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_new = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 269;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_new = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_new = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 269;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_new = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_new = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 269;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_new = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_new = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 269;\n",
       "                var nbb_unformatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_new = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_r[\\\"Flag\\\"] = pred_test_r.apply(flag_df_baseline, axis=1)\\npredictions_rejects_new = [round(kickout_baseline(pred_test_r).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_r[\"Flag\"] = pred_test_r.apply(flag_df_baseline, axis=1)\n",
    "predictions_rejects_new = [round(kickout_baseline(pred_test_r).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 270;\n",
       "                var nbb_unformatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_new = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_new = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 270;\n",
       "                var nbb_unformatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_new = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_new = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 270;\n",
       "                var nbb_unformatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_new = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_new = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 270;\n",
       "                var nbb_unformatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_new = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_new = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 270;\n",
       "                var nbb_unformatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_new = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_new = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 270;\n",
       "                var nbb_unformatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_new = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_formatted_code = \"pred_test_combined[\\\"Flag\\\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\\npredictions_combined_new = [round(kickout_baseline(pred_test_combined).tolist(), 3)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_test_combined[\"Flag\"] = pred_test_combined.apply(flag_df_baseline, axis=1)\n",
    "predictions_combined_new = [round(kickout_baseline(pred_test_combined).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.902]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"predictions_accepts_new\";\n",
       "                var nbb_formatted_code = \"predictions_accepts_new\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_accepts_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 271;\n",
       "                var nbb_unformatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_formatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 271;\n",
       "                var nbb_unformatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_formatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 271;\n",
       "                var nbb_unformatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_formatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 271;\n",
       "                var nbb_unformatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_formatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 271;\n",
       "                var nbb_unformatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_formatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 271;\n",
       "                var nbb_unformatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_formatted_code = \"f1, auc = standard_evaluation(pred_test_combined)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1, auc = standard_evaluation(pred_test_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6337196723844847"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 272;\n",
       "                var nbb_unformatted_code = \"auc\";\n",
       "                var nbb_formatted_code = \"auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 272;\n",
       "                var nbb_unformatted_code = \"auc\";\n",
       "                var nbb_formatted_code = \"auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 272;\n",
       "                var nbb_unformatted_code = \"auc\";\n",
       "                var nbb_formatted_code = \"auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 272;\n",
       "                var nbb_unformatted_code = \"auc\";\n",
       "                var nbb_formatted_code = \"auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 272;\n",
       "                var nbb_unformatted_code = \"auc\";\n",
       "                var nbb_formatted_code = \"auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 272;\n",
       "                var nbb_unformatted_code = \"auc\";\n",
       "                var nbb_formatted_code = \"auc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parcelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"significant_columns = [\\\"col_0\\\", \\\"col_1\\\"]\";\n",
       "                var nbb_formatted_code = \"significant_columns = [\\\"col_0\\\", \\\"col_1\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "significant_columns = [\"col_0\", \"col_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"# Create copies of the dataframes\\nX_train_parc = X_train2[significant_columns]\\ny_train_parc = y_train2\\nX_test = X_test2[significant_columns]\\nr_dev = r_dev2[significant_columns]\";\n",
       "                var nbb_formatted_code = \"# Create copies of the dataframes\\nX_train_parc = X_train2[significant_columns]\\ny_train_parc = y_train2\\nX_test = X_test2[significant_columns]\\nr_dev = r_dev2[significant_columns]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create copies of the dataframes\n",
    "X_train_parc = X_train2[significant_columns]\n",
    "y_train_parc = y_train2\n",
    "X_test = X_test2[significant_columns]\n",
    "r_dev = r_dev2[significant_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LinearRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-53916ec9740f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Build a model on the accepted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mKGB1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_parc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_parc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# Score the test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpred_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKGB1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m pred_test_acc = pd.DataFrame(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LinearRegression' is not defined"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# Build a model on the accepted\\nKGB1 = LinearRegression().fit(X_train_parc, y_train_parc)\\n# Score the test\\npred_test = KGB1.predict(X_test)\\npred_test_acc = pd.DataFrame(\\n    data=pred_test,\\n    columns=[\\\"pred\\\"],\\n    index=X_test.index.copy(),\\n)\";\n",
       "                var nbb_formatted_code = \"# Build a model on the accepted\\nKGB1 = LinearRegression().fit(X_train_parc, y_train_parc)\\n# Score the test\\npred_test = KGB1.predict(X_test)\\npred_test_acc = pd.DataFrame(\\n    data=pred_test,\\n    columns=[\\\"pred\\\"],\\n    index=X_test.index.copy(),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build a model on the accepted\n",
    "KGB1 = LinearRegression().fit(X_train_parc, y_train_parc)\n",
    "# Score the test\n",
    "pred_test = KGB1.predict(X_test)\n",
    "pred_test_acc = pd.DataFrame(\n",
    "    data=pred_test,\n",
    "    columns=[\"pred\"],\n",
    "    index=X_test.index.copy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 10 score bands\n",
    "pred_test_acc[\"score_band\"] = pd.qcut(pred_test_acc[\"pred\"].values, 10)\n",
    "pred_test_acc[\"nr_band\"] = pd.qcut(pred_test_acc[\"pred\"].values, 10, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach target\n",
    "df = pd.merge(\n",
    "    pred_test_acc,\n",
    "    y_test,\n",
    "    how=\"inner\",\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows with target = 1\n",
    "df_bad = df[df[\"target\"] == 1]\n",
    "# Select rows with target = 0\n",
    "df_good = df[df[\"target\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count nr of bads in each interval\n",
    "df_bad = df_bad.groupby(\"nr_band\").size().sort_values().reset_index(name=\"nr_bad\")\n",
    "df_good = df_good.groupby(\"nr_band\").size().sort_values().reset_index(name=\"nr_good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge counts with original data\n",
    "df = pd.merge(df, df_bad, on=\"nr_band\", how=\"outer\")\n",
    "df = pd.merge(df, df_good, on=\"nr_band\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN with 0.1\n",
    "df[\"nr_bad\"] = df[\"nr_bad\"].fillna(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate %good and %bads\n",
    "df[\"perc_good\"] = df[\"nr_good\"] / (df[\"nr_bad\"] + df[\"nr_good\"])\n",
    "df[\"perc_bad\"] = df[\"nr_bad\"] / (df[\"nr_bad\"] + df[\"nr_good\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get distinct score bands\n",
    "df.drop_duplicates(subset=[\"score_band\"]).sort_values(by=\"nr_band\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the r_dev data\n",
    "r_dev_parc = r_dev.copy()\n",
    "r_test_parc = r_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score test rejects\n",
    "pred_test_rej = KGB1.predict(r_test_parc)\n",
    "pred_test_rej = pd.DataFrame(\n",
    "    data=pred_test_rej,\n",
    "    columns=[\"pred\"],\n",
    "    index=r_test_parc.index.copy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rej_scoring(x):\n",
    "    if x <= -0.0938:\n",
    "        return 0\n",
    "    elif x > -0.0938 and x <= -0.0359:\n",
    "        return 1\n",
    "    elif x > -0.0359 and x <= -0.0158:\n",
    "        return 2\n",
    "    elif x > -0.0158 and x <= 0.0638:\n",
    "        return 3\n",
    "    elif x > 0.0638 and x <= 0.118:\n",
    "        return 4\n",
    "    elif x > 0.118 and x <= 0.164:\n",
    "        return 5\n",
    "    elif x > 0.164 and x <= 0.22:\n",
    "        return 6\n",
    "    elif x > 0.22 and x <= 0.28:\n",
    "        return 7\n",
    "    elif x > 0.28 and x <= 0.343:\n",
    "        return 8\n",
    "    elif x > 0.343 and x <= 0.448:\n",
    "        return 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply these scores to the rejects\n",
    "pred_test_rej[\"nr_band\"] = pred_test_rej[\"pred\"].apply(rej_scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_rej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_rej.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how well known_col_0 discriminates goods and bads. Use as \"score\"\n",
    "reg1 = LogisticRegression(fit_intercept=True, penalty=\"none\").fit(\n",
    "    X_train_parc[[\"col_0\"]], y_train_parc\n",
    ")\n",
    "f1_score(y_test, reg1.predict(X_test[[\"col_0\"]]), average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 10 score bands\n",
    "X_train_parc[\"score_band\"] = pd.qcut(X_train_parc[\"col_0\"].values, 10)\n",
    "X_train_parc[\"nr_band\"] = pd.qcut(X_train_parc[\"col_0\"].values, 10, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach target\n",
    "df = pd.merge(\n",
    "    X_train_parc,\n",
    "    y_train_parc,\n",
    "    how=\"inner\",\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows with target = 1\n",
    "df_bad = df[df[\"target\"] == 1]\n",
    "# Select rows with target = 0\n",
    "df_good = df[df[\"target\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count nr of bads in each interval\n",
    "df_bad = df_bad.groupby(\"nr_band\").size().sort_values().reset_index(name=\"nr_bad\")\n",
    "df_good = df_good.groupby(\"nr_band\").size().sort_values().reset_index(name=\"nr_good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge counts with original data\n",
    "df = pd.merge(df, df_bad, on=\"nr_band\")\n",
    "df = pd.merge(df, df_good, on=\"nr_band\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate %good and %bads\n",
    "df[\"perc_good\"] = df[\"nr_good\"] / (df[\"nr_bad\"] + df[\"nr_good\"])\n",
    "df[\"perc_bad\"] = df[\"nr_bad\"] / (df[\"nr_bad\"] + df[\"nr_good\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get distinct score bands\n",
    "df.drop_duplicates(subset=[\"score_band\"]).sort_values(by=\"nr_band\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the r_dev data\n",
    "r_dev_parc = r_dev.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rej_scoring(x):\n",
    "    if x <= 0.19:\n",
    "        return 0\n",
    "    elif x > 0.19 and x <= 0.361:\n",
    "        return 1\n",
    "    elif x > 0.361 and x <= 0.437:\n",
    "        return 2\n",
    "    elif x > 0.437 and x <= 0.509:\n",
    "        return 3\n",
    "    elif x > 0.509 and x <= 0.58:\n",
    "        return 4\n",
    "    elif x > 0.58 and x <= 0.648:\n",
    "        return 5\n",
    "    elif x > 0.648 and x <= 0.716:\n",
    "        return 6\n",
    "    elif x > 0.716 and x <= 0.789:\n",
    "        return 7\n",
    "    elif x > 0.789 and x <= 0.862:\n",
    "        return 8\n",
    "    elif x > 0.862 and x <= 0.929:\n",
    "        return 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply these scores to the rejects\n",
    "r_dev_parc[\"nr_band\"] = r_dev_parc[\"col_0\"].apply(rej_scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another copy of the rejects\n",
    "r_dev2 = r_dev_parc.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of rejects in each band\n",
    "r_dev_parc = (\n",
    "    r_dev_parc.groupby(\"nr_band\").size().sort_values().reset_index(name=\"nr_rejects\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach rej. counts to original data\n",
    "df = pd.merge(df, r_dev_parc, on=\"nr_band\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infer nr rejects\n",
    "df[\"inf_good\"] = round((df[\"nr_rejects\"] * df[\"perc_good\"]), 0)\n",
    "df[\"inf_bad\"] = round((df[\"nr_rejects\"] * df[\"perc_bad\"]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation factor\n",
    "# Drop duplicates\n",
    "df[\"aug_factor\"] = (df[\"nr_bad\"] + df[\"nr_good\"] + df[\"nr_rejects\"]) / (\n",
    "    df[\"nr_good\"] + df[\"nr_bad\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Augmented nr of good and bad\n",
    "df[\"inf_bad_aug\"] = round((df[\"inf_bad\"] * df[\"aug_factor\"]), 0)\n",
    "df[\"inf_good_aug\"] = round((df[\"nr_rejects\"] - df[\"inf_bad_aug\"]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inferred probabilities\n",
    "df[\"inf_p_good\"] = round((df[\"inf_good_aug\"] / df[\"nr_rejects\"]), 2)\n",
    "df[\"inf_p_bad\"] = round((df[\"inf_bad_aug\"] / df[\"nr_rejects\"]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = df.drop_duplicates(subset=[\"score_band\"]).sort_values(by=\"nr_band\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Random Parcelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign randomly given number of bads in each interval with a bad status with their given probabilities\n",
    "\n",
    "df_list = []\n",
    "for i in range(0, 2):\n",
    "    data = r_dev2[r_dev2[\"nr_band\"] == i]\n",
    "    data[\"target\"] = np.random.choice(\n",
    "        [0, 1],\n",
    "        len(data),\n",
    "        p=[float(df_n[[\"inf_p_good\"]].iloc[1]), float(df_n[[\"inf_p_bad\"]].iloc[1])],\n",
    "    )\n",
    "    df_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all dataframes\n",
    "new_rej = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_columns = [\"col_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new rows to df\n",
    "\n",
    "# Split X and y\n",
    "new_rej_X, new_rej_y = create_X_y(new_rej)\n",
    "new_rej_X = new_rej_X[significant_columns]\n",
    "\n",
    "# Extend training set\n",
    "y_train_new = pd.concat((y_train, new_rej_y))\n",
    "X_train_new = pd.concat((X_train, new_rej_X))\n",
    "\n",
    "# Fit new model\n",
    "KGB_baseline_new = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(\n",
    "    X_train_new, y_train_new\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_a = evaluate_test_accepts(KGB_baseline_new, X_test[significant_columns])\n",
    "pred_test_r = evaluate_test_rejects(KGB_baseline_new, r_test[significant_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_a[\"Flag\"] = pred_test_a.apply(flag_df_baseline, axis=1)\n",
    "predictions_accepts_rand_parc = [round(kickout_baseline(pred_test_a).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_r[\"Flag\"] = pred_test_r.apply(flag_df_baseline, axis=1)\n",
    "predictions_rejects_rand_parc = [round(kickout_baseline(pred_test_r).tolist(), 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Non-Random Parcelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Band 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_dev_iter0 = r_dev2[r_dev2[\"nr_band\"] == 0]\n",
    "# X_train_iter0 = X_train_parc[X_train_parc[\"nr_band\"] == 0]\n",
    "# y_train_iter0 = pd.merge(\n",
    "#     X_train_iter0[\"known_col_0\"],\n",
    "#     y_train_parc,\n",
    "#     how=\"inner\",\n",
    "#     left_index=True,\n",
    "#     right_index=True,\n",
    "# )\n",
    "# X_train_iter0 = X_train_iter0[significant_columns]\n",
    "# X_test = X_test[significant_columns]\n",
    "# # Drop unnecessary columns\n",
    "# y_train_iter0 = y_train_iter0.drop([\"known_col_0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mccs = []\n",
    "# for iteration in range(1, 10):  # Change to how many iterrations you like\n",
    "#     print(\"Iteration Nr {}\".format(iteration))\n",
    "#     # Build logistic regression\n",
    "#     KGB1 = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(\n",
    "#         X_train_iter0, y_train_iter0\n",
    "#     )\n",
    "\n",
    "#     # Scores\n",
    "#     #     f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\"weighted\")\n",
    "#     #     f1_scores.append(f1_stat)\n",
    "\n",
    "#     #     logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\n",
    "#     #     log_losses.append(logloss)\n",
    "\n",
    "#     #     print(\"F1: \", f1_stat)\n",
    "\n",
    "#     mcc = matthews_corrcoef(y_test, KGB1.predict(X_test))\n",
    "#     mccs.append(mcc)\n",
    "\n",
    "#     print(\"MCC: \", mcc)\n",
    "\n",
    "#     # Make predictions on the rejected data\n",
    "#     pred = KGB1.predict_proba(r_dev_iter0[significant_columns])[:, 1]\n",
    "#     pred = pd.DataFrame(\n",
    "#         data=pred,\n",
    "#         columns=[\"target\"],\n",
    "#         index=r_dev_iter0.index.copy(),\n",
    "#     )\n",
    "\n",
    "#     # Choose the most certain predictions\n",
    "#     lq = pred[\"target\"].quantile(q=0.05)\n",
    "#     uq = pred[\"target\"].quantile(q=0.95)\n",
    "#     pred[\"certain\"] = pred[\"target\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\n",
    "\n",
    "#     # If PD is high, apply default status\n",
    "#     pred[\"target\"] = pred[\"target\"].apply(lambda x: 1 if (x > uq) else 0)\n",
    "\n",
    "#     # Pick only the certain predictions and concatenate them to the dev set\n",
    "#     # Y TRAIN\n",
    "#     certain = pred[pred[\"certain\"] == 1]\n",
    "#     certain2 = certain[\"target\"].to_frame()\n",
    "#     y_train_iter0 = pd.concat((y_train_iter0, certain2))\n",
    "\n",
    "#     # Get significant columns of the rejects based on index\n",
    "#     certain_features = pd.merge(\n",
    "#         certain[\"target\"],\n",
    "#         r_dev_iter0[significant_columns],\n",
    "#         how=\"inner\",\n",
    "#         left_index=True,\n",
    "#         right_index=True,\n",
    "#     )\n",
    "\n",
    "#     # X TRAIN\n",
    "#     certain_features = certain_features.loc[:, certain_features.columns != \"target\"]\n",
    "#     X_train_iter0 = pd.concat((X_train_iter0, certain_features))\n",
    "\n",
    "#     # Remove certain columns from rejected data\n",
    "#     rows = certain_features.index\n",
    "#     r_dev_iter0 = r_dev_iter0.drop(rows, axis=\"index\")\n",
    "#     df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(mccs, label=\"MCCs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign non-randomly given number of bads in each interval with a bad status with their given probabilities\n",
    "\n",
    "df_list = []\n",
    "f1_scores = []\n",
    "mccs = []\n",
    "for i in range(0, 9):\n",
    "    # Prepare the data\n",
    "    r_dev_iter = r_dev2[r_dev2[\"nr_band\"] == i]\n",
    "    X_train_iter = X_train_parc[X_train_parc[\"nr_band\"] == 0]\n",
    "    y_train_iter = pd.merge(\n",
    "        X_train_iter[\"known_col_0\"],\n",
    "        y_train_parc,\n",
    "        how=\"inner\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "    X_train_iter = X_train_iter[significant_columns]\n",
    "    X_test = X_test[significant_columns]\n",
    "    # Drop unnecessary columns\n",
    "    y_train_iter = y_train_iter.drop([\"known_col_0\"], axis=1)\n",
    "\n",
    "    for iteration in range(1, 11):  # Change to how many iterrations you like\n",
    "        print(\"Iteration Nr {}\".format(iteration))\n",
    "        # Build logistic regression\n",
    "        KGB1 = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(\n",
    "            X_train_iter, y_train_iter\n",
    "        )\n",
    "\n",
    "        # Scores\n",
    "        #         f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\"weighted\")\n",
    "        #         f1_scores.append(f1_stat)\n",
    "\n",
    "        #         logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\n",
    "        #         log_losses.append(logloss)\n",
    "\n",
    "        #         print(\"F1: \", f1_stat)\n",
    "\n",
    "        mcc = matthews_corrcoef(y_test, KGB1.predict(X_test))\n",
    "        mccs.append(mcc)\n",
    "\n",
    "        print(\"MCC: \", mcc)\n",
    "\n",
    "        # Make predictions on the rejected data\n",
    "        pred = KGB1.predict_proba(r_dev_iter[significant_columns])[:, 1]\n",
    "        pred = pd.DataFrame(\n",
    "            data=pred,\n",
    "            columns=[\"target\"],\n",
    "            index=r_dev_iter.index.copy(),\n",
    "        )\n",
    "\n",
    "        # Choose the most certain predictions\n",
    "        lq = pred[\"target\"].quantile(q=0.05)\n",
    "        uq = pred[\"target\"].quantile(q=0.95)\n",
    "        #pred[\"certain\"] = pred[\"target\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\n",
    "        pred[\"certain\"] = pred[\"target\"].apply(lambda x: 1 if (x > uq) else 0)\n",
    "\n",
    "        # If PD is high, apply default status\n",
    "        pred[\"target\"] = pred[\"target\"].apply(lambda x: 1 if (x > uq) else 0)\n",
    "#         pred[\"target\"] = pred[\"target\"].apply(\n",
    "#             lambda x: 1 if (x > np.random.uniform()) else 0\n",
    "#         )\n",
    "\n",
    "        #If PD is low, be conservative and apply non-default status only to some examples\n",
    "        #pred[\"target\"] = pred[\"target\"].apply(lambda x: 0 if (x < np.random.uniform()) else 1)\n",
    "\n",
    "\n",
    "        # Pick only the certain predictions and concatenate them to the dev set\n",
    "        # Y TRAIN\n",
    "        certain = pred[pred[\"certain\"] == 1]\n",
    "        certain2 = certain[\"target\"].to_frame()\n",
    "        y_train_iter = pd.concat((y_train_iter, certain2))\n",
    "\n",
    "        # Get significant columns of the rejects based on index\n",
    "        certain_features = pd.merge(\n",
    "            certain[\"target\"],\n",
    "            r_dev_iter[significant_columns],\n",
    "            how=\"inner\",\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "        )\n",
    "\n",
    "        # X TRAIN\n",
    "        certain_features = certain_features.loc[:, certain_features.columns != \"target\"]\n",
    "        X_train_iter = pd.concat((X_train_iter, certain_features))\n",
    "\n",
    "        # Remove certain columns from rejected data\n",
    "        rows = certain_features.index\n",
    "        r_dev_iter = r_dev_iter.drop(rows, axis=\"index\")\n",
    "        df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign non-randomly given number of bads in each interval with a bad status with their given probabilities\n",
    "\n",
    "df_list = []\n",
    "f1_scores = []\n",
    "for i in range(0, 9):\n",
    "    r_dev_iter = r_dev2[r_dev2[\"nr_band\"] == i]\n",
    "    for iteration in range(1, 10):  # Change to how many iterrations you like\n",
    "        print(\"Iteration Nr {}\".format(iteration))\n",
    "        # Build logistic regression\n",
    "        # KGB1 = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(X_train_iter, y_train_iter)\n",
    "        KGB1 = RandomForestClassifier().fit(X_train_iter, y_train_iter)\n",
    "\n",
    "        # Scores\n",
    "        f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\"weighted\")\n",
    "        f1_scores.append(f1_stat)\n",
    "\n",
    "        logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\n",
    "        log_losses.append(logloss)\n",
    "\n",
    "        print(\"F1: \", f1_stat)\n",
    "\n",
    "        # Make predictions on the rejected data\n",
    "        pred = KGB1.predict_proba(r_dev_iter[significant_columns])[:, 1]\n",
    "        pred = pd.DataFrame(\n",
    "            data=pred,\n",
    "            columns=[\"target\"],\n",
    "            index=r_dev_iter.index.copy(),\n",
    "        )\n",
    "\n",
    "        # Choose the most certain predictions\n",
    "        lq = pred[\"target\"].quantile(q=0.05)\n",
    "        uq = pred[\"target\"].quantile(q=0.95)\n",
    "        #pred[\"certain\"] = pred[\"target\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\n",
    "        pred[\"certain\"] = pred[\"target\"].apply(lambda x: 1 if (x > uq) else 0)\n",
    "\n",
    "        # If PD is high, apply default status\n",
    "        pred[\"target\"] = pred[\"target\"].apply(lambda x: 1 if (x > uq) else 0)\n",
    "#         pred[\"target\"] = pred[\"target\"].apply(\n",
    "#             lambda x: 1 if (x > np.random.uniform()) else 0\n",
    "#         )\n",
    "\n",
    "        #If PD is low, be conservative and apply non-default status only to some examples\n",
    "        #pred[\"target\"] = pred[\"target\"].apply(lambda x: 0 if (x < np.random.uniform()) else 1)\n",
    "\n",
    "        # Pick only the certain predictions and concatenate them to the dev set\n",
    "        # Y TRAIN\n",
    "        certain = pred[pred[\"certain\"] == 1]\n",
    "        certain2 = certain[\"target\"].to_frame()\n",
    "        y_train_iter = pd.concat((y_train_iter, certain2))\n",
    "\n",
    "        # Get significant columns of the rejects based on index\n",
    "        certain_features = pd.merge(\n",
    "            certain[\"target\"],\n",
    "            r_dev_iter[significant_columns],\n",
    "            how=\"inner\",\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "        )\n",
    "\n",
    "        # X TRAIN\n",
    "        certain_features = certain_features.loc[:, certain_features.columns != \"target\"]\n",
    "        X_train_iter = pd.concat((X_train_iter, certain_features))\n",
    "\n",
    "        # Remove certain columns from rejected data\n",
    "        rows = certain_features.index\n",
    "        r_dev_iter = r_dev_iter.drop(rows, axis=\"index\")\n",
    "        df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the iteration of the model where max MCC score is reached\n",
    "max_value0 = max(mccs[0:9])\n",
    "max_index0 = mccs.index(max_value0)\n",
    "max_value1 = max(mccs[10:19])\n",
    "max_index1 = 10 + mccs.index(max_value1)\n",
    "max_value2 = max(mccs[20:29])\n",
    "max_index2 = 20 + mccs.index(max_value2)\n",
    "max_value3 = max(mccs[30:39])\n",
    "max_index3 = 30 + mccs.index(max_value3)\n",
    "max_value4 = max(mccs[40:49])\n",
    "max_index4 = 40 + mccs.index(max_value4)\n",
    "max_value5 = max(mccs[50:59])\n",
    "max_index5 = 50 + mccs.index(max_value5)\n",
    "max_value6 = max(mccs[60:69])\n",
    "max_index6 = 60 + mccs.index(max_value6)\n",
    "max_value7 = max(mccs[70:79])\n",
    "max_index7 = 70 + mccs.index(max_value7)\n",
    "max_value8 = max(mccs[80:89])\n",
    "max_index8 = 80 + mccs.index(max_value8)\n",
    "print(max_index7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### max_value1 = max(mccs[10:19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index1 = mccs.index(max_value1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = max(mccs[0:9])\n",
    "max_index = mccs.index(max_value)\n",
    "print(max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign non-randomly given number of bads in each interval with a bad status with their given probabilities\n",
    "\n",
    "df_list = []\n",
    "f1_scores = []\n",
    "for i in range(0, 9):\n",
    "    r_dev_iter = r_dev2[r_dev2[\"nr_band\"] == i]\n",
    "    for iteration in range(1, 10):  # Change to how many iterrations you like\n",
    "        print(\"Iteration Nr {}\".format(iteration))\n",
    "        # Build logistic regression\n",
    "        # KGB1 = LogisticRegression(fit_intercept=False, penalty=\"none\").fit(X_train_iter, y_train_iter)\n",
    "        KGB1 = RandomForestClassifier().fit(X_train_iter, y_train_iter)\n",
    "\n",
    "        # Scores\n",
    "        f1_stat = f1_score(y_test, KGB1.predict(X_test), average=\"weighted\")\n",
    "        f1_scores.append(f1_stat)\n",
    "\n",
    "        logloss = log_loss(y_test, KGB1.predict(X_test), eps=1e-15)\n",
    "        log_losses.append(logloss)\n",
    "\n",
    "        print(\"F1: \", f1_stat)\n",
    "\n",
    "        # Make predictions on the rejected data\n",
    "        pred = KGB1.predict_proba(r_dev_iter[significant_columns])[:, 1]\n",
    "        pred = pd.DataFrame(\n",
    "            data=pred,\n",
    "            columns=[\"target\"],\n",
    "            index=r_dev_iter.index.copy(),\n",
    "        )\n",
    "\n",
    "        # Choose the most certain predictions\n",
    "        lq = pred[\"target\"].quantile(q=0.05)\n",
    "        uq = pred[\"target\"].quantile(q=0.95)\n",
    "        #pred[\"certain\"] = pred[\"target\"].apply(lambda x: 1 if (x < lq or x > uq) else 0)\n",
    "        pred[\"certain\"] = pred[\"target\"].apply(lambda x: 1 if (x > uq) else 0)\n",
    "\n",
    "        # If PD is high, apply default status\n",
    "        pred[\"target\"] = pred[\"target\"].apply(lambda x: 1 if (x > uq) else 0)\n",
    "#         pred[\"target\"] = pred[\"target\"].apply(\n",
    "#             lambda x: 1 if (x > np.random.uniform()) else 0\n",
    "#         )\n",
    "\n",
    "        #If PD is low, be conservative and apply non-default status only to some examples\n",
    "        #pred[\"target\"] = pred[\"target\"].apply(lambda x: 0 if (x < np.random.uniform()) else 1)\n",
    "\n",
    "\n",
    "        # Pick only the certain predictions and concatenate them to the dev set\n",
    "        # Y TRAIN\n",
    "        certain = pred[pred[\"certain\"] == 1]\n",
    "        certain2 = certain[\"target\"].to_frame()\n",
    "        y_train_iter = pd.concat((y_train_iter, certain2))\n",
    "\n",
    "        # Get significant columns of the rejects based on index\n",
    "        certain_features = pd.merge(\n",
    "            certain[\"target\"],\n",
    "            r_dev_iter[significant_columns],\n",
    "            how=\"inner\",\n",
    "            left_index=True,\n",
    "            right_index=True,\n",
    "        )\n",
    "\n",
    "        # X TRAIN\n",
    "        certain_features = certain_features.loc[:, certain_features.columns != \"target\"]\n",
    "        X_train_iter = pd.concat((X_train_iter, certain_features))\n",
    "\n",
    "        # Remove certain columns from rejected data\n",
    "        rows = certain_features.index\n",
    "        r_dev_iter = r_dev_iter.drop(rows, axis=\"index\")\n",
    "        df_list.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list_accepts = [\n",
    "    predictions_accepts_beforeRI,\n",
    "    predictions_accepts_base,\n",
    "    predictions_accepts_iter,\n",
    "    predictions_accepts_new,\n",
    "    # predictions_accepts_rand_parc,\n",
    "]\n",
    "df_pred_accepts = pd.DataFrame(my_list_accepts).transpose()\n",
    "df_pred_accepts = df_pred_accepts.rename(\n",
    "    columns={\n",
    "        0: \"Before RI\",\n",
    "        1: \"Baseline\",\n",
    "        2: \"Iteration n\",\n",
    "        3: \"Self-Training\",\n",
    "        # 4: \"Rand Parcelling\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list_rejects = [\n",
    "    predictions_rejects_beforeRI,\n",
    "    predictions_rejects_base,\n",
    "    predictions_rejects_iter,\n",
    "    predictions_rejects_new,\n",
    "    # predictions_rejects_rand_parc,\n",
    "]\n",
    "df_pred_rejects = pd.DataFrame(my_list_rejects).transpose()\n",
    "df_pred_rejects = df_pred_rejects.rename(\n",
    "    columns={\n",
    "        0: \"Before RI\",\n",
    "        1: \"Baseline\",\n",
    "        2: \"Iteration n\",\n",
    "        3: \"Self-Training\",\n",
    "        # 4: \"Rand Parcelling\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list_combined = [\n",
    "    predictions_combined_beforeRI,\n",
    "    predictions_combined_base,\n",
    "    predictions_combined_iter,\n",
    "    predictions_combined_new,\n",
    "    # predictions_accepts_rand_parc,\n",
    "]\n",
    "df_pred_combined = pd.DataFrame(my_list_combined).transpose()\n",
    "df_pred_combined = df_pred_combined.rename(\n",
    "    columns={\n",
    "        0: \"Before RI\",\n",
    "        1: \"Baseline\",\n",
    "        2: \"Iteration n\",\n",
    "        3: \"Self-Training\",\n",
    "        # 4: \"Rand Parcelling\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_accepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_rejects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
